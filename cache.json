{
    "1781955550126997586": {
        "content": "Someone just dropped a dataset of 15 trillion tokens (as many as were used to train Llama 3)!!!\n\nDownload this now before it gets taken down for \u201ccopyright reasons\u201d\n\nBreakdown in thread \ud83e\uddf5 \ud83d\udc47\ud83d\udc47 https://t.co/9YRBLagSzm",
        "name": "Andrew Gao",
        "photo": "https://pbs.twimg.com/profile_images/1665531358851092485/qItXwa52_normal.jpg",
        "reply_count": 11,
        "retweet_count": 68,
        "view_count": 121438,
        "like_count": 610
    },
    "1782062852611662111": {
        "content": "Another @journalismfest has come to an end &amp; the journalism community owes so much to @_arianna, Chris, the festival staff &amp; volunteers who work tirelessly behind the scenes so that we can see wonderful panels between coffee, gelato &amp; aperol breaks. See you all next year #ijf24 https://t.co/iQxvoAUut3",
        "name": "Felix M. Simon",
        "photo": "https://pbs.twimg.com/profile_images/1458834024005308419/VtyAIj6r_normal.jpg",
        "reply_count": 1,
        "retweet_count": 1,
        "view_count": 417,
        "like_count": 11
    },
    "1781786744192414194": {
        "content": "Sincerely, fuck @elonmusk \n\nHe has made tech a more hostile environment for women because of his DEI crusade. \n\nIt has taken me a DECADE to get to where I am, just for Elons Incels to constantly harass and discredit me. \n\nIt\u2019s seriously become unbearable here.",
        "name": "shenetworks",
        "photo": "https://pbs.twimg.com/profile_images/1566424754231312384/amN1mYNr_normal.jpg",
        "reply_count": 1599,
        "retweet_count": 3486,
        "view_count": 3119879,
        "like_count": 50734
    },
    "1781985293039710238": {
        "content": "Geoffrey Hinton: it's possible that we still won't understand the brain at the point that AI is smarter than us https://t.co/Pd936DUODG",
        "name": "Tsarathustra",
        "photo": "https://pbs.twimg.com/profile_images/1690941803200208896/PRpYEDXP_normal.jpg",
        "reply_count": 34,
        "retweet_count": 28,
        "view_count": 16716,
        "like_count": 207
    },
    "1782061641179467983": {
        "content": "My 9-year-old just peeked at the example below and regaled me with further LLM stories like these.\n\nShe gets it. \n\nAstonishing how many adults in tech don\u2019t. https://t.co/pGDgyrVaS2",
        "name": "Gary Marcus",
        "photo": "https://pbs.twimg.com/profile_images/1749047536361586688/N1p9EZpc_normal.jpg",
        "reply_count": 2,
        "retweet_count": 0,
        "view_count": 3451,
        "like_count": 8
    },
    "1782040453266710551": {
        "content": "The more I use Llama 3 the more I think that Zuck may have just killed OpenAI and all other large proprietary AI vendors. The gap between latest GPT4 and Llama 70b is virtually non existent. Even if OpenAI releases GPT5 now, 400b Llama 3 is still training and will most likely be in the same ballpark, again closing the gap between open source and proprietary.\n\nOpenAI has $2b in revenue and is most likely very unprofitable. Meta makes over $100b gross profit. They likely can outspend OpenAI by a factor of at least 10 in terms of compute and talent -- speaking of which, a large majority of AI researchers find open source work a lot more appealing than closed for profit; so very likely top talent will end up at Meta. Google is still caught in the issue of AI killing their main revenue line, so most likely can never go as full in as Meta.\nI think the biggest winners from all of this will be application developers, because you can choose any API service that hosts Llama 3, or just host it yourself on your own terms.\n\nSo far the majority of AI products have just been glorified wrappers around API endpoints. But if you manage to integrate AI deeply into a product, where the user doesn't even have to think they're interacting with an AI (e.g. behind the scenes calls that adapt to user context, combined with RAG, feeding it your internal API format, multi step reasoning / planning etc), you likely have a very sustainable business that only improves the more advanced the base models become. \n\nBut vendor risk / dependency should no longer be a concern for AI developers. Added to that the fact that hardware is only going to get faster / cheaper; there really are endless opportunities to disrupt existing software domains, much of which we're probably not even able to conceive now, but that will seem obvious in hindsight.",
        "name": "Laura Wendel",
        "photo": "https://pbs.twimg.com/profile_images/1687033386244685824/wUW5LoLv_normal.jpg",
        "reply_count": 72,
        "retweet_count": 107,
        "view_count": 115029,
        "like_count": 895
    },
    "1781718226923290767": {
        "content": "\ud83d\udea8 Big news:\n\nGoogle just introduced ScreenAI, and it's wild.\n\nThis is going to transform the future of UX forever\n\nHere's everything you need to stay ahead of the curve: \ud83e\uddf5 \ud83d\udc47 https://t.co/rnM7CDWJKV",
        "name": "Madni Aghadi",
        "photo": "https://pbs.twimg.com/profile_images/1662329612658159616/k8YTK8tu_normal.jpg",
        "reply_count": 55,
        "retweet_count": 362,
        "view_count": 677737,
        "like_count": 2117
    },
    "1781145338759533016": {
        "content": "We have a new preprint out - your language model is not a reward, it\u2019s a Q function!\n1. The likelihood of the preferred answer must go down - it\u2019s a policy divergence\n2. MCTS guided decoding on language is equivalent to likelihood search on DPO\n3. DPO learns credit assignment https://t.co/NykcDMQ8nI",
        "name": "Rafael Rafailov",
        "photo": "https://pbs.twimg.com/profile_images/1663362227762774017/B3ezAxFz_normal.jpg",
        "reply_count": 12,
        "retweet_count": 139,
        "view_count": 82086,
        "like_count": 840
    },
    "1781310654559011159": {
        "content": "This is a great time to be a PhD student newly working on AI ethics/safety! With this Herculean undertaking @IasonGabriel and friends have built a springboard for dozens of research projects. Congratulations!",
        "name": "Seth Lazar",
        "photo": "https://pbs.twimg.com/profile_images/1652665632532451334/vXd40miU_normal.jpg",
        "reply_count": 3,
        "retweet_count": 13,
        "view_count": 8129,
        "like_count": 72
    },
    "1781262674711466483": {
        "content": "1. What are the ethical and societal implications of advanced AI assistants? What might change in a world with more agentic AI?\n\nOur new paper explores these questions:\nhttps://t.co/Z0jlSMBLxq\n\nIt\u2019s the result of a one year research collaboration involving 50+ researchers\u2026 a\ud83e\uddf5 https://t.co/cpWEkKL8kt",
        "name": "Iason Gabriel",
        "photo": "https://pbs.twimg.com/profile_images/1204695548697219072/x4mGc36X_normal.jpg",
        "reply_count": 15,
        "retweet_count": 147,
        "view_count": 122930,
        "like_count": 446
    },
    "1781352193259683849": {
        "content": "Yes! Another pytrees-based JAX library. This could be a big gift to researchers who mess around with model internals.",
        "name": "Matthew Finlayson",
        "photo": "https://pbs.twimg.com/profile_images/1413755625780121602/Krp10Rkr_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 632,
        "like_count": 6
    },
    "1781334421141934226": {
        "content": "Excited to share Penzai, a JAX research toolkit from @GoogleDeepMind for building, editing, and visualizing neural networks! Penzai makes it easy to see model internals and lets you inject custom logic anywhere.\n\nCheck it out on GitHub: https://t.co/mas2uiMqj9 https://t.co/HaiYlmOOix",
        "name": "Daniel Johnson",
        "photo": "https://pbs.twimg.com/profile_images/1491979688763445260/UTUSSRQB_normal.jpg",
        "reply_count": 37,
        "retweet_count": 374,
        "view_count": 279036,
        "like_count": 1861
    },
    "1781400080802779604": {
        "content": "Announcing a progress update from the @GoogleDeepMind mech interp team! Inspired by @AnthropicAI's excellent monthly updates, we share a range of updates on our work on Sparse Autoencoders, from signs of life on interpreting steering vectors with SAEs to improving ghost grads. https://t.co/Xj9IOj1vz8",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 4,
        "retweet_count": 38,
        "view_count": 27135,
        "like_count": 355
    },
    "1781402038124912871": {
        "content": "An update on our work on SAEs. Stay tuned for our upcoming SAE Pareto improvement too\u2026 :)",
        "name": "Arthur Conmy",
        "photo": "https://pbs.twimg.com/profile_images/1422332102486409218/dOEbifRB_normal.jpg",
        "reply_count": 1,
        "retweet_count": 3,
        "view_count": 4998,
        "like_count": 51
    },
    "1752648761719848975": {
        "content": "He\u2019s the fastest man in the world and a proud enhanced athlete. He has broken Usain Bolt\u2019s world record. The new Olympics are here, backed by VCs Christian Angermayer and Peter Thiel, where performance enhancements are allowed.  \n\nhttps://t.co/OydUh3J6uw https://t.co/P0zKpTzA4T",
        "name": "Enhanced Games",
        "photo": "https://pbs.twimg.com/profile_images/1670717382682181632/28VR2Xr3_normal.jpg",
        "reply_count": 2923,
        "retweet_count": 2137,
        "view_count": 34564513,
        "like_count": 15846
    },
    "1781306675476967583": {
        "content": "Big new paper on the Ethics of Advanced AI Assistants led by @IasonGabriel @Arianna_Manzini Geoff Keeling in collaboration with many authors! A broad study encompassing many aspects of AI ethics and safety. Was an honour to write the chapter on Safety, thanks to my co-authors 1/5",
        "name": "Zac Kenton",
        "photo": "https://pbs.twimg.com/profile_images/1736783430552113152/PZr_Rs_i_normal.jpg",
        "reply_count": 2,
        "retweet_count": 4,
        "view_count": 2137,
        "like_count": 26
    },
    "1640764857741111297": {
        "content": "@SAIA_Alignment @AnthropicAI Hopefully our manuscript using ordinary linear regression complement\u2019s @daniela_witten  awesome explanation using splines:\n\nhttps://t.co/gelbI0Zctu\n\n7/8",
        "name": "Rylan Schaeffer",
        "photo": "https://pbs.twimg.com/profile_images/1733557514338471936/uXIn8yUI_normal.jpg",
        "reply_count": 1,
        "retweet_count": 0,
        "view_count": 1609,
        "like_count": 5
    },
    "1292293102103748609": {
        "content": "The Bias-Variance Trade-Off &amp; \"DOUBLE DESCENT\" \ud83e\uddf5\n\nRemember the bias-variance trade-off? It says that models  perform well for an \"intermediate level of flexibility\".  You've seen the picture of the U-shape test error curve.\n\nWe try to hit the \"sweet spot\" of flexibility.\n\n1/\ud83e\uddf5 https://t.co/HPk05izkZh",
        "name": "Daniela Witten",
        "photo": "https://pbs.twimg.com/profile_images/1420495797062230016/1NLOoJ_h_normal.jpg",
        "reply_count": 59,
        "retweet_count": 1420,
        "view_count": null,
        "like_count": 5097
    },
    "1732824267535118469": {
        "content": "Interested in mech interp of representations that deep networks learn? \n\nIf so, check out a new type of polysemanticity we call:\n\n\ud83d\udca5\ud83d\udca5Incidental Polysemanticity \ud83d\udca5\ud83d\udca5\n\nLed by @vclecomte @kushal1t @tmychow @sanmikoyejo at @stai_research @StanfordAILab \n\nhttps://t.co/6uTzEj15Ev\n\n1/N",
        "name": "Rylan Schaeffer",
        "photo": "https://pbs.twimg.com/profile_images/1733557514338471936/uXIn8yUI_normal.jpg",
        "reply_count": 3,
        "retweet_count": 21,
        "view_count": 29470,
        "like_count": 106
    },
    "1736891543045411218": {
        "content": "I had a wonderful but exhausting #NeurIPS2023 . On the flight home, I watched @srush_nlp 's lecture on linear RNNs &amp; state space models\n\nhttps://t.co/jURt2Cq7G0\n\nCan't recommend highly enough. Dense with information plus references to know where to dig deeper\ud83d\udcaf\ud83d\udcaf",
        "name": "Rylan Schaeffer",
        "photo": "https://pbs.twimg.com/profile_images/1733557514338471936/uXIn8yUI_normal.jpg",
        "reply_count": 2,
        "retweet_count": 60,
        "view_count": 62398,
        "like_count": 538
    },
    "1616590887873839104": {
        "content": "Excited to announce that our work, Progress Measures for Grokking via Mechanistic Interpretability, has been accepted as a spotlight at ICLR 23! (despite being rejected from Arxiv twice!)\nThis was significantly refined from my prior work, thoughts in \ud83e\uddf5\nhttps://t.co/fHDcoRPpwz https://t.co/wL2G5mOn2u",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 9,
        "retweet_count": 85,
        "view_count": 257610,
        "like_count": 537
    },
    "1559060507524403200": {
        "content": "I've spent the past few months exploring @OpenAI's grokking result through the lens of mechanistic interpretability. I fully reverse engineered the modular addition model, and looked at what it does when training. So what's up with grokking? A \ud83e\uddf5... (1/17) https://t.co/AutzPTjz6g",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 24,
        "retweet_count": 241,
        "view_count": null,
        "like_count": 1519
    },
    "1616590988407111680": {
        "content": "@AnthropicAI recently applied a similar mindset to understanding memorisation and double descent. Some great work from Tom Henighan, @shancarter, @trishume, @nelhage and @ch402!",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 3,
        "view_count": 3169,
        "like_count": 24
    },
    "1611045993516249088": {
        "content": "We have little mechanistic understanding of how deep learning models overfit to their training data, despite it being a central problem. Here we extend our previous work on toy models to shed light on how models generalize beyond their training data.\nhttps://t.co/0bYUToop3m https://t.co/88KGnM3CsL",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 15,
        "retweet_count": 145,
        "view_count": 370350,
        "like_count": 841
    },
    "1781139694052343829": {
        "content": "Introducing v0.5 of the AI Safety Benchmark from MLCommons\n\nThis paper introduces v0.5 of the AI Safety Benchmark, which has been created by the MLCommons AI Safety Working Group. The AI Safety Benchmark has been designed to assess the safety risks of AI systems that use https://t.co/js8b1qZ8TM",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 4,
        "retweet_count": 36,
        "view_count": 19517,
        "like_count": 109
    },
    "1781150621439058064": {
        "content": "Google presents Reuse Your Rewards\n\nReward Model Transfer for Zero-Shot Cross-Lingual Alignment\n\nAligning language models (LMs) based on human-annotated preference data is a crucial step in obtaining practical and performant LM-based systems. However, multilingual human https://t.co/5XcPu6h0q4",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 2,
        "retweet_count": 40,
        "view_count": 24658,
        "like_count": 179
    },
    "1781023016895623587": {
        "content": "Don't fall into the chinchilla trap if you want your model to be used by billions of people :)",
        "name": "Thomas Scialom",
        "photo": "https://pbs.twimg.com/profile_images/942697848210120704/0AgZtq_o_normal.jpg",
        "reply_count": 0,
        "retweet_count": 6,
        "view_count": 6934,
        "like_count": 75
    },
    "1781004253718307271": {
        "content": "Llama3 8B is trained on almost 100 times the Chinchilla optimal number of tokens https://t.co/lukU8FPR7F",
        "name": "Felix",
        "photo": "https://pbs.twimg.com/profile_images/1315698428035334144/gFRG5rJg_normal.jpg",
        "reply_count": 8,
        "retweet_count": 7,
        "view_count": 66606,
        "like_count": 186
    },
    "1780974841342128467": {
        "content": "How the Navy Seal fall asleep within 2 minutes.\n\n\u2022 No pills.\n\u2022 No cold shower.\n\u2022 No bluelight blocking glasses.\n\nThe 4-7-8 Method (backed by science): https://t.co/yaaKxu068o",
        "name": "Fernando Cao Zheng",
        "photo": "https://pbs.twimg.com/profile_images/1621568541186035719/gzm_ZAC7_normal.jpg",
        "reply_count": 651,
        "retweet_count": 3420,
        "view_count": 10517724,
        "like_count": 31093
    },
    "1781008093121245642": {
        "content": "https://t.co/fgjsd9l3Y0",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 4,
        "retweet_count": 24,
        "view_count": 29434,
        "like_count": 222
    },
    "1780698231787434390": {
        "content": "forgot about this gem from Noam https://t.co/0egPdc6yNj",
        "name": "david rein",
        "photo": "https://pbs.twimg.com/profile_images/1375548507621257220/OOUh4_Yz_normal.jpg",
        "reply_count": 5,
        "retweet_count": 7,
        "view_count": 8021,
        "like_count": 85
    },
    "1780642402685882596": {
        "content": "The next generation of models seem to mostly target infinite context and adaptive compute per token.\n\nBasically, these two papers:\nGoogle: Mixture of Depths\nGoogle: Infini-Attention",
        "name": "Casper Hansen",
        "photo": "https://pbs.twimg.com/profile_images/1463225585799467013/ndVxzFtj_normal.jpg",
        "reply_count": 5,
        "retweet_count": 11,
        "view_count": 9082,
        "like_count": 96
    },
    "1780990840179187715": {
        "content": "Zuck on:\n\n- Llama 3\n- open sourcing towards AGI\n- custom silicon, synthetic data, &amp; energy constraints on scaling\n- Caeser Augustus, intelligence explosion, bioweapons, $10b models, &amp; much more\n\nEnjoy!\n\nLinks below https://t.co/VYIadc3Jlo",
        "name": "Dwarkesh Patel",
        "photo": "https://pbs.twimg.com/profile_images/1516990544165150721/gkmNmTig_normal.jpg",
        "reply_count": 133,
        "retweet_count": 368,
        "view_count": 798054,
        "like_count": 3401
    },
    "1780598536125735355": {
        "content": "\ud83d\udea8 New LLM Reasoning Paper \ud83d\udea8\n\nQ. How can LLMs self-improve their reasoning ability?\n\n\u21d2 Introducing Self-Explore\u26f0\ufe0f\ud83e\udded, a training method specifically designed to help LLMs avoid reasoning pits by learning from their own outputs! [1/N] https://t.co/iGikGQcAzd",
        "name": "Hyeonbin Hwang",
        "photo": "https://pbs.twimg.com/profile_images/1743177424341528576/bXAWRq_r_normal.jpg",
        "reply_count": 7,
        "retweet_count": 55,
        "view_count": 34818,
        "like_count": 294
    },
    "1780774821204291721": {
        "content": "Google presents Many-Shot In-Context Learning\n\n- Proposes many-shot ICL, i.e., adding up to thousands of examples in context with Gemini 1.5, which boosts the perf significantly\n- Using synthetic CoT is very effect in this setting.\n\nhttps://t.co/wHmJKK3ZHw https://t.co/PFGs2VJ84e",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 7,
        "retweet_count": 83,
        "view_count": 82006,
        "like_count": 441
    },
    "1780728376283521191": {
        "content": "Nick Bostrom's Future of Humanity Institute at Oxford is shutting down.\nIt seems that humanity's future is no longer in doubt, in case anyone was worried.\n\nhttps://t.co/RG9INOAFVk",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 74,
        "retweet_count": 130,
        "view_count": 144030,
        "like_count": 907
    },
    "1780753750254375200": {
        "content": "Good news for the future of humanity! https://t.co/Mye7jXMX6v",
        "name": "Christopher Manning",
        "photo": "https://pbs.twimg.com/profile_images/512256295542333440/8Jo4w8kV_normal.jpeg",
        "reply_count": 8,
        "retweet_count": 10,
        "view_count": 38600,
        "like_count": 240
    },
    "1780324687496511766": {
        "content": "Are LLMs biased toward themselves?\n\nFrontier LLMs give higher scores to their own outputs in self-eval. We find evidence that this bias is caused by LLM's ability to recognize their own outputs\n\nThis could interfere with safety techniques like reward modeling &amp; constitutional AI https://t.co/z40T7yCwLR",
        "name": "Arjun Panickssery is in London",
        "photo": "https://pbs.twimg.com/profile_images/1632229521683513344/_kSyjhE3_normal.jpg",
        "reply_count": 8,
        "retweet_count": 45,
        "view_count": 61610,
        "like_count": 316
    },
    "1780687271542333630": {
        "content": "We are still so early in understanding how LLMs will scale",
        "name": "Ian Hogarth",
        "photo": "https://pbs.twimg.com/profile_images/1728782716731105280/nVAiafUn_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 3110,
        "like_count": 12
    },
    "1780639257389904013": {
        "content": "The Chinchilla scaling paper by Hoffmann et al. has been highly influential in the language modeling community. We tried to replicate a key part of their work and discovered discrepancies. Here's what we found. (1/9) https://t.co/BFOP70Aj0W",
        "name": "Tamay Besiroglu",
        "photo": "https://pbs.twimg.com/profile_images/1650539413649207299/sDhZcngm_normal.jpg",
        "reply_count": 13,
        "retweet_count": 124,
        "view_count": 300489,
        "like_count": 845
    },
    "1780657759865786612": {
        "content": "Learning Transformer Programs (https://t.co/FUC6rODerf from Princeton NLP) - \n\nThis paper is neat. Modify transformer arch to be disentangled (concat not add, -residuals), anneal training to be discrete, convert to python code.  Doesn't really scale yet but very fun. https://t.co/Lez6XORZsv",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 2,
        "retweet_count": 58,
        "view_count": 50653,
        "like_count": 341
    },
    "1780604061374726462": {
        "content": "Our new position paper showing how social choice theory can give us tools to answer many vexing questions around the preference collection and learning in rlhf!",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 0,
        "retweet_count": 5,
        "view_count": 3138,
        "like_count": 10
    },
    "1780556706696626338": {
        "content": "Our social choice for AI alignment position paper is now available on arXiv! https://t.co/2OUd17V3pn",
        "name": "Vincent Conitzer",
        "photo": "https://pbs.twimg.com/profile_images/748512518054748161/nrIu2CIi_normal.jpg",
        "reply_count": 8,
        "retweet_count": 15,
        "view_count": 10035,
        "like_count": 83
    },
    "1780588369505902879": {
        "content": "(5/5) Event pages with talk details:\n- UCL: https://t.co/X1Wutm76WD\n- King's: https://t.co/3r6b97DR0c\n- Imperial: https://t.co/iC4nK5oX6S",
        "name": "Stefano Albrecht (UoE Agents Group)",
        "photo": "https://pbs.twimg.com/profile_images/1403050958129668098/lELq0PGa_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 248,
        "like_count": 3
    },
    "1780609317906854296": {
        "content": "Is DPO Superior to PPO for LLM Alignment? No.\n\nA comprehensive study shows that PPO is better (except for time and complexity of running wise)\nTheoretically and empirically \n\nhttps://t.co/uGPlquMj3A",
        "name": "\u267b\ufe0f Leshem Choshen \u267b\ufe0f",
        "photo": "https://pbs.twimg.com/profile_images/1018975836135780352/cO2xsypb_normal.jpg",
        "reply_count": 5,
        "retweet_count": 11,
        "view_count": 4829,
        "like_count": 62
    },
    "1780603212359205323": {
        "content": "We promise this is not a person in a bodysuit. https://t.co/S9FgfpqvrW https://t.co/G30sXHQ93C",
        "name": "Boston Dynamics",
        "photo": "https://pbs.twimg.com/profile_images/1156978210783019009/AbgIujGu_normal.jpg",
        "reply_count": 3131,
        "retweet_count": 10450,
        "view_count": 10091833,
        "like_count": 54430
    },
    "1780609171358118083": {
        "content": "@bryancsk Naive Bayes &amp; logistic regression are still taught in cs124 but not cs224n.\n\nCs224n isn\u2019t all LLMs. We teach word vectors, recurrent NNs, dependency parsing, etc. But we do teach more and more LLMs!\n\nYou can see it all online:\nhttps://t.co/sf3xlHpX5F\nhttps://t.co/0pDNV2NCpe",
        "name": "Christopher Manning",
        "photo": "https://pbs.twimg.com/profile_images/512256295542333440/8Jo4w8kV_normal.jpeg",
        "reply_count": 0,
        "retweet_count": 2,
        "view_count": 2686,
        "like_count": 24
    },
    "1780608162644811783": {
        "content": "Announcing our latest addition to the OLMo family, OLMo 1.7!\ud83c\udf89Our team's efforts to improve data quality, training procedures and model architecture have led to a leap in performance. See how OLMo 1.7 stacks up against its peers and peek into the technical details on the blog: https://t.co/6X0GXOlDHi",
        "name": "Allen Institute for AI",
        "photo": "https://pbs.twimg.com/profile_images/1191417163648626688/Ylny0kyT_normal.jpg",
        "reply_count": 13,
        "retweet_count": 43,
        "view_count": 63359,
        "like_count": 167
    },
    "1780245764331212994": {
        "content": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models\n\n\"Identifies 18 foundational challenges in assuring the alignment and safety of large language models (LLMs)... we pose 200+ concrete research questions.\"\nhttps://t.co/Yx8pNOyKkF https://t.co/F19y45jgyh",
        "name": "ML Safety Daily",
        "photo": "https://pbs.twimg.com/profile_images/1548772139334979584/TQ1C6FwS_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 659,
        "like_count": 12
    },
    "1780237500662923750": {
        "content": "wow this must feel good when training \n\n(from Megalodon https://t.co/sfLfU16b5t ) https://t.co/s7sriUGvkm",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 16,
        "retweet_count": 29,
        "view_count": 49596,
        "like_count": 417
    },
    "1780083267888107546": {
        "content": "Meta announces Megalodon\n\nEfficient LLM Pretraining and Inference with Unlimited Context Length\n\nThe quadratic complexity and weak length extrapolation of Transformers limits their ability to scale to long sequences, and while sub-quadratic solutions like linear attention and https://t.co/uTAbRnkVDD",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 16,
        "retweet_count": 230,
        "view_count": 174157,
        "like_count": 1191
    },
    "1779962865518260625": {
        "content": "Our @RekaAILabs Tech Report / Paper is out! \ud83d\udd25 \n\nTech reports with completely no information are kinda boring so we\u2019re revealing some interesting information on how we train our series of Reka models including tokens, architecture, data & human evaluation workflows. \ud83d\ude03\n\nWe tried our best to give a behind-the-scenes experience \ud83d\ude0a. In particular, if you enjoyed my previous blog post about training LLMs in the wilderness, there\u2019s a dedicated section on that in this report! \ud83c\udf34\n\nWe can\u2019t disclose literally everything but we tried our best to make it interesting, I promise. \ud83d\ude4f\n\nHere\u2019s a rundown summary of some of the highlights.\n\ud83d\udd39Edge and Flash are outrageously strong 7B and 21B models. They are trained on 4.5-5T tokens in total. Also, they have been improved significantly since their first public appearance! They outperform many popular faces. Some data mixture information is in the report.\n\ud83d\udd39We discuss our internal human evaluation workflow, prompt distribution, and how we use Core for model development and automatic evaluation.\n\ud83d\udd39We describe our infrastructure setup for training large models, quantifying node failures, and report loss curves for training our models.\n\ud83d\udd39Aside from the hardware lottery, we also show how this affects node stability across time. Once we were told our cluster became less stable because there were \"big guys\" moving things around the data center. \ud83d\ude05\n\nOn performance which you might have already seen on other threads. \n\ud83d\udd39Core approaches frontier-class models like Claude3 Opus and GPT4-V. It outperforms Claude3 Opus on third-party blind human evaluation for multimodal chat, outperforms Gemini Ultra on video QA, and is quite competitive to other frontier models on core text metrics. It also matches GPT4-V on MMMU!\n\ud83d\udd39Core ranks #2 on our internal multimodal chat leaderboard, right after GPT4-V. On text, it ranks #3 just behind Claude Opus and GPT4 Turbo. Core outperforms GPT-4 (0613) on this ranking.\n\nThis has been a focused and concentrated effort of a small team of ~20 people in the past 4 months (yes, we got access to 90%+ of our compute only late December last year! \ud83d\ude80).\n\nThis tech report tells our story. Enjoy! Happy to answer any questions in replies or DM!\n\nPS: it was nice writing in latex after one whole year!\n\nPPS: I had quite some fun writing this \ud83d\ude0a. There's some puns and easter eggs and interesting tidbits in there. Trust me. \ud83d\ude0f\n\nLink: https://t.co/Zve6RtRRGR",
        "name": "Yi Tay",
        "photo": "https://pbs.twimg.com/profile_images/1676934464159756291/1lM4joGC_normal.jpg",
        "reply_count": 11,
        "retweet_count": 56,
        "view_count": 46923,
        "like_count": 412
    },
    "1780017397807649005": {
        "content": "Drum roll\u2026 this is worth reading cover to cover!\ud83d\ude0d\ud83e\udd29\ud83c\udf8a",
        "name": "Fei-Fei Li",
        "photo": "https://pbs.twimg.com/profile_images/841385099799085056/R1iX4QGX_normal.jpg",
        "reply_count": 9,
        "retweet_count": 81,
        "view_count": 108147,
        "like_count": 461
    },
    "1779857508837814409": {
        "content": "\ud83d\udce2 The #AIIndex2024 is now live! This year\u2019s report presents new estimates on AI training costs, a thorough analysis of the responsible AI landscape, and a new chapter about AI's impact on medicine and scientific discovery. Read the full report here: https://t.co/NHWDCyuzm3 https://t.co/2a31hhHAGG",
        "name": "Stanford HAI",
        "photo": "https://pbs.twimg.com/profile_images/1633221221642010624/2gkqnAOS_normal.jpg",
        "reply_count": 4,
        "retweet_count": 325,
        "view_count": 182665,
        "like_count": 653
    },
    "1779906827624308976": {
        "content": "Interpretability methods could be an incredibly powerful tool for assuring the alignment of AI systems, but they currently have a long way to go. \n\nWe outline *11 open challenges* for interpretability research and propose actionable research questions to tackle them. \ud83e\uddf5\u2b07\ufe0f",
        "name": "Miles Turpin",
        "photo": "https://pbs.twimg.com/profile_images/1465462208901566468/h6XBKbBv_normal.jpg",
        "reply_count": 1,
        "retweet_count": 6,
        "view_count": 4660,
        "like_count": 47
    },
    "1779900511627452467": {
        "content": "I\u2019m super excited to release our 100+ page collaborative agenda - led by @usmananwar391 - on \u201cFoundational Challenges In Assuring Alignment and Safety of LLMs\u201d alongside 35+ co-authors from NLP, ML, and AI Safety communities! \n\nSome highlights below... https://t.co/08MSLsj6Pa",
        "name": "David Krueger",
        "photo": "https://pbs.twimg.com/profile_images/833081523213438976/DeIwiR-6_normal.jpg",
        "reply_count": 5,
        "retweet_count": 140,
        "view_count": 120754,
        "like_count": 397
    },
    "1779902263105888436": {
        "content": "\ud83d\udea8 Data poisoning attacks are a challenge for LLM Safety! \ud83d\udea8\n\nLLMs are trained on data from untrusted sources that can be manipulated to inject vulnerabilities.\n\nResearch on data poisoning on LLMs is limited. We summarize the key challenges \ud83e\uddf5\u2b07\ufe0f\n\nhttps://t.co/ke7i41grFK",
        "name": "Javier Rando",
        "photo": "https://pbs.twimg.com/profile_images/1725657467277692928/b_gVOsCQ_normal.jpg",
        "reply_count": 1,
        "retweet_count": 4,
        "view_count": 3188,
        "like_count": 36
    },
    "1779918965718049216": {
        "content": "For Mathpresso, making 1:1 personalized education available for everyone through an AI tutor has been a long-standing goal. MathGPT uses Llama 2 to create a platform for highly personalized learning.",
        "name": "AI at Meta",
        "photo": "https://pbs.twimg.com/profile_images/1454145678075117568/2qXqM_Cu_normal.png",
        "reply_count": 8,
        "retweet_count": 57,
        "view_count": 66117,
        "like_count": 367
    },
    "1779917676133105732": {
        "content": "I\u2019ll be sharing more on Llama 3 very soon. It\u2019s so cool to see what the community is already building with Llama 2 though. One of my favorites: @team_qanda &amp; @UpstageAI used it to build a math-specific LLM to make personalized learning more accessible! https://t.co/llYRj9xoOB https://t.co/AyFoYLoNm6",
        "name": "Ahmad Al-Dahle",
        "photo": "https://pbs.twimg.com/profile_images/1776395576726454272/aWZG8kr4_normal.jpg",
        "reply_count": 20,
        "retweet_count": 51,
        "view_count": 223502,
        "like_count": 350
    },
    "1779845304788955292": {
        "content": "There is no question that AI will eventually reach and surpass human intelligence in all domains.\nBut it won't happen next year.\nAnd it won't happen with the kind of Auto-Regressive LLMs currently in fashion (although they may constitute a component of it).\nhttps://t.co/ohg9y6qV37",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 233,
        "retweet_count": 329,
        "view_count": 622448,
        "like_count": 2548
    },
    "1779866409784496436": {
        "content": "Announcing the private beta of our newest foundation embedding model, Cohere Compass: designed specifically for multi-aspect data like emails, invoices, CVs, and support tickets to offer superior enterprise search capabilities.\n\nSign up to try it out!\n\nhttps://t.co/CO6OIrnpDg",
        "name": "cohere",
        "photo": "https://pbs.twimg.com/profile_images/1650250832909152260/760DZ0cv_normal.png",
        "reply_count": 5,
        "retweet_count": 52,
        "view_count": 42000,
        "like_count": 233
    },
    "1779754674242892014": {
        "content": "Introducing OpenAI Japan, our first office in Asia, along with a new GPT-4 custom model specifically optimized for \u65e5\u672c\u8a9e (the Japanese language). https://t.co/mIcCpbC18m https://t.co/UJjQpBjKsO",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 340,
        "retweet_count": 2371,
        "view_count": 3489542,
        "like_count": 8709
    },
    "1778868449349185978": {
        "content": "How can we hope to understand neural nets?\n\nThere are so many architectures. Understanding any single one won't help understand a different one - right?\n\n@arnab_api's new research tests this, applying transformer interpretation methods to Mamba.\n\nHis \ud83e\uddf5discusses what he sees\u27a1\ufe0f",
        "name": "David Bau",
        "photo": "https://pbs.twimg.com/profile_images/1591452247417831424/nZA7ZHTB_normal.jpg",
        "reply_count": 0,
        "retweet_count": 2,
        "view_count": 4458,
        "like_count": 38
    },
    "1778847401773871621": {
        "content": "How does Mamba store knowledge? Is it very different from transformers?\n\nNew pre-print with @diatkinson and @davidbau, where we investigate the mechanisms of factual recall within Mamba. https://t.co/M0vE9S7L6m",
        "name": "Arnab Sen Sharma",
        "photo": "https://pbs.twimg.com/profile_images/1588009776562176005/HhbppOUb_normal.jpg",
        "reply_count": 2,
        "retweet_count": 29,
        "view_count": 28466,
        "like_count": 164
    },
    "1778808625626247409": {
        "content": "Watch my @stanford CS 25 lecture next week, \"aligning open language models,\" it'll be good, v excited https://t.co/oKbe0T9KeV",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 25,
        "retweet_count": 98,
        "view_count": 136332,
        "like_count": 623
    },
    "1778796212768088469": {
        "content": "Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning\n\nMethod for LLM unlearning that outperforms existing gradient ascent methods on a synthetic benchmark, avoiding catastrophic collapse.\nhttps://t.co/hJjmFw9TUt https://t.co/HSjxUjyczU",
        "name": "ML Safety Daily",
        "photo": "https://pbs.twimg.com/profile_images/1548772139334979584/TQ1C6FwS_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 587,
        "like_count": 10
    },
    "1778503607199150303": {
        "content": "Being able to interpret an #ML model\u2019s hidden representations is key to understanding its behavior. Today we introduce Patchscopes, an approach that trains #LLMs to provide natural language explanations of their own hidden representations. Learn more \u2192 https://t.co/WfY1FYa1Wt https://t.co/M3RajdZsh4",
        "name": "Google AI",
        "photo": "https://pbs.twimg.com/profile_images/993649592422907904/yD7LkqU2_normal.jpg",
        "reply_count": 30,
        "retweet_count": 362,
        "view_count": 154146,
        "like_count": 1372
    },
    "1778600051863929153": {
        "content": "Microsoft presents Rho-1: Not All Tokens Are What You Need\n\nRHO-1-1B and 7B achieves SotA results of 40.6% and 51.8% on MATH dataset, respectively \u2014 matching DeepSeekMath with only 3% of the pretraining tokens.\n\nrepo: https://t.co/GEma1XKOlz\nabs: https://t.co/p4wKoXopGs https://t.co/tJgBNtLcCP",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 5,
        "retweet_count": 43,
        "view_count": 29700,
        "like_count": 313
    },
    "1778233527592448444": {
        "content": "Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?\n\nrepo: https://t.co/LGFbgPXT8J\nabs: https://t.co/RhEInG4y8I https://t.co/Z8x4FQyzdY",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 4,
        "retweet_count": 28,
        "view_count": 14852,
        "like_count": 131
    },
    "1778230430090592454": {
        "content": "Google presents Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention\n\n1B model that was fine-tuned on up to 5K sequence length passkey instances solves the 1M length problem\n\nhttps://t.co/zyHMt3inhi https://t.co/ySYEMET9Ef",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 28,
        "retweet_count": 264,
        "view_count": 200627,
        "like_count": 1204
    },
    "1778139049808507073": {
        "content": "Our new work in @NatureMedicine \n\nUsing generative models in path, radiology and derm - we can create synthetic training data to \u2b06\ufe0f AI fairness &amp; robustness, including underrepresented groups. Work w/ a great team @GoogleDeepMind @GoogleAI @GoogleHealth \n\nhttps://t.co/7uGXXloQfY",
        "name": "Alan Karthikesalingam",
        "photo": "https://pbs.twimg.com/profile_images/1028576902594932736/7biCF3Sb_normal.jpg",
        "reply_count": 5,
        "retweet_count": 52,
        "view_count": 40401,
        "like_count": 255
    },
    "1777871889345524220": {
        "content": "Finger on the pulseeeee, new (130b? not sure) mixtral 8expert MoE out. \n\nhttps://t.co/pSX0HmJyRz https://t.co/RE3atWekdC",
        "name": "nisten",
        "photo": "https://pbs.twimg.com/profile_images/1661945893782802432/e7yLoESw_normal.jpg",
        "reply_count": 5,
        "retweet_count": 12,
        "view_count": 35745,
        "like_count": 141
    },
    "1777869263778291896": {
        "content": "magnet:?xt=urn:btih:9238b09245d0d8cd915be09927769d5f7584c1c9&amp;dn=mixtral-8x22b&amp;tr=udp%3A%2F%https://t.co/2UepcMGLGd%3A1337%2Fannounce&amp;tr=http%3A%2F%https://t.co/OdtBUsbeV5%3A1337%2Fannounce",
        "name": "Mistral AI",
        "photo": "https://pbs.twimg.com/profile_images/1670141874328174596/iWMnioc__normal.jpg",
        "reply_count": 277,
        "retweet_count": 852,
        "view_count": 1704258,
        "like_count": 5936
    },
    "1777740670129631243": {
        "content": "This is by far the best non-technical Natural and Artificial Intelligence book anyone could read. This comprehensive, well-researched, crisply clear, sharply focused and illuminating book is a thing of beauty. It is the book I wish I had had when I started my AI career 30 years ago.\n\nThe book tells the story of steering, emotions, reinforcement, world models, generative intelligence, counter factual thinking, planning, awareness, theory of mind, tool use, language, GPT4 and more. It is not only a history of intelligence but also a beacon for the future of AI.\n\nThank you @maxsbennett for this jewel. Thanks @serkancabi for sharing it. \n\nhttps://t.co/xf8tEmYHEF",
        "name": "Nando de Freitas \ud83c\udff3\ufe0f\u200d\ud83c\udf08",
        "photo": "https://pbs.twimg.com/profile_images/1758949305904222208/3IxvxTkp_normal.jpg",
        "reply_count": 17,
        "retweet_count": 89,
        "view_count": 79736,
        "like_count": 646
    },
    "1777728366101119101": {
        "content": "New Anthropic research: Measuring Model Persuasiveness\n\nWe developed a way to test how persuasive language models (LMs) are, and analyzed how persuasiveness scales across different versions of Claude.\n\nRead our blog post here: https://t.co/gqwoigSAGY https://t.co/ZqjpoWbrDO",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 57,
        "retweet_count": 117,
        "view_count": 178169,
        "like_count": 714
    },
    "1775471271901630970": {
        "content": "Have any folks done extensive comparisons of the Sophia optimizer against a well-tuned AdamW benchmark on causal auto-regressive models (outside of what's reported in paper)? Something along the lines of what lucidrains did with lion optimizer.",
        "name": "Armen Aghajanyan",
        "photo": "https://pbs.twimg.com/profile_images/1468810975063072769/eUl8sFBE_normal.jpg",
        "reply_count": 1,
        "retweet_count": 1,
        "view_count": 45278,
        "like_count": 29
    },
    "1777589222519501049": {
        "content": "Thanks for trying our optimizer! hope that Sophia can save some compute for FAIR and others :)",
        "name": "Tengyu Ma",
        "photo": "https://pbs.twimg.com/profile_images/993271556116701184/3TQPReTL_normal.jpg",
        "reply_count": 1,
        "retweet_count": 3,
        "view_count": 32926,
        "like_count": 65
    },
    "1776876799710093758": {
        "content": "No replies here. Decided to try out on our own benchmarks, consisting of an auto-regressive, multi-modal pre-training at scale. Pretty complex setting.\n\nYellow: Tuned (LR) AdamW\nPurple: Tuned (LR) Sophia\n\nAverage Loss: https://t.co/YMlZ1FbqXP",
        "name": "Armen Aghajanyan",
        "photo": "https://pbs.twimg.com/profile_images/1468810975063072769/eUl8sFBE_normal.jpg",
        "reply_count": 10,
        "retweet_count": 13,
        "view_count": 103588,
        "like_count": 192
    },
    "1777427944971083809": {
        "content": "Have you ever wanted to train LLMs in pure C without 245MB of PyTorch and 107MB of cPython? No? Well now you can! With llm.c:\nhttps://t.co/PoGTZIwASL\n\nTo start, implements GPT-2 training on CPU/fp32 in only ~1,000 lines of clean code. It compiles and runs instantly, and exactly matches the PyTorch reference implementation.\n\nI chose GPT-2 to start because it is the grand-daddy of LLMs, the first time the LLM stack was put together in a recognizably modern form, and with model weights available.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 302,
        "retweet_count": 1936,
        "view_count": 1585747,
        "like_count": 13316
    },
    "1777481372636246491": {
        "content": "I added a quick crappy tutorial on how PyTorch layers are moved to C, with a few possibly helpful pointers:\nhttps://t.co/SOrp7j1uCj",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 45,
        "retweet_count": 244,
        "view_count": 275133,
        "like_count": 2693
    },
    "1777331313714024890": {
        "content": "New versions of Gemma models with a bunch of improvements to instruction following, factuality, reasoning and more are now out. \n\n\u2b07\ufe0f",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 16,
        "retweet_count": 86,
        "view_count": 184729,
        "like_count": 583
    },
    "1777317210836312233": {
        "content": "I am very happy to announce that Gemma 1.1 Instruct 2B and \u201c7B\u201d are out! Here are a few details about the new models:\n1/11",
        "name": "Robert Dadashi",
        "photo": "https://pbs.twimg.com/profile_images/1091119652296519680/DmnpSDaS_normal.jpg",
        "reply_count": 13,
        "retweet_count": 71,
        "view_count": 310726,
        "like_count": 378
    },
    "1776077775180575093": {
        "content": "thanks @arankomatsuzaki for sharing!\n\nwant to mention that, there is **very little cost** switching from PEFT to ReFT. You can instruct-tune 7B LMs with our ReFT library under 20 mins with a single GPU, and model artifact is &lt; 1MB.\n\nhttps://t.co/D2GXYH9bxi",
        "name": "Zhengxuan Wu",
        "photo": "https://pbs.twimg.com/profile_images/1641146001938616321/Th2IWKmh_normal.jpg",
        "reply_count": 3,
        "retweet_count": 10,
        "view_count": 18363,
        "like_count": 72
    },
    "1776057023697731913": {
        "content": "ReFT: Representation Finetuning for Language Models\n\n10x-50x more parameter-efficient than prior state-of-the-art parameter-efficient fine-tuning methods\n\nrepo: https://t.co/dMg24slcT6\nabs: https://t.co/BztZfSUf0Y https://t.co/IitiJOe05r",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 6,
        "retweet_count": 100,
        "view_count": 175599,
        "like_count": 504
    },
    "1775534721986077002": {
        "content": "JailbreakBench is an LLM jailbreak benchmark with a dataset for jailbreaking behaviors, collection of adversarial prompts, and a leaderboard for tracking the  performance of attacks and defenses on language models.\nhttps://t.co/6yTb63DeqG https://t.co/oHFaK4grJQ",
        "name": "ML Safety Daily",
        "photo": "https://pbs.twimg.com/profile_images/1548772139334979584/TQ1C6FwS_normal.jpg",
        "reply_count": 0,
        "retweet_count": 7,
        "view_count": 2281,
        "like_count": 21
    },
    "1775570158964138268": {
        "content": "Extremely cool work from @Saprmarks! I think this is one of my favourite SAE papers since Towards Monosemanticity. I'm particularly excited about the use of error nodes, without which SAEs are a bit too janky to do reliable circuit analysis with",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 0,
        "retweet_count": 4,
        "view_count": 9237,
        "like_count": 83
    },
    "1775513423402692685": {
        "content": "Can we understand &amp; edit unanticipated mechanisms in LMs?\n\nWe introduce sparse feature circuits, &amp; use them to explain LM behaviors, discover &amp; fix LM bugs, &amp; build an automated interpretability pipeline! Preprint w/ @can_rager, @ericjmichaud_, @boknilev, @davidbau, @amuuueller https://t.co/Sy2q1s2nBQ",
        "name": "Samuel Marks",
        "photo": "https://pbs.twimg.com/profile_images/1712236109009416192/BFtcSlgC_normal.jpg",
        "reply_count": 5,
        "retweet_count": 59,
        "view_count": 46662,
        "like_count": 286
    },
    "1775346771662704762": {
        "content": "Long-context LLMs Struggle with Long In-context Learning\n\nLarge Language Models (LLMs) have made significant strides in handling long sequences exceeding 32K tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, https://t.co/5lYSqk34CA",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 3,
        "retweet_count": 32,
        "view_count": 22304,
        "like_count": 176
    },
    "1775381860371333419": {
        "content": "Highly recommend cs231n! Although its vision focused, I found the entire course + the tricks to training NNs to be awesome! Plus there's Youtube recordings for 2016/2017! https://t.co/MyfjSUtaxj",
        "name": "Daniel Han",
        "photo": "https://pbs.twimg.com/profile_images/1624054272676532224/UNv4ONME_normal.jpg",
        "reply_count": 4,
        "retweet_count": 7,
        "view_count": 11864,
        "like_count": 96
    },
    "1775313584542879921": {
        "content": "It\u2019s that time of the year - first lecture of @cs231n !! It\u2019s the 9th year since @karpathy and I started this journey in 2015, what an incredible decade of AI and computer vision! Am so excited to this new crop of students in CS231n! (Co-instructing with @eadeli this year \ud83d\ude0d\ud83e\udd29) https://t.co/syPbj4O0zS",
        "name": "Fei-Fei Li",
        "photo": "https://pbs.twimg.com/profile_images/841385099799085056/R1iX4QGX_normal.jpg",
        "reply_count": 19,
        "retweet_count": 79,
        "view_count": 154018,
        "like_count": 975
    },
    "1775230994087543155": {
        "content": "This is the most effective, reliable, and hard to train away jailbreak I know of. It's also principled (based on in-context learning) and predictably gets worse with model scale and context length.",
        "name": "Ethan Perez",
        "photo": "https://pbs.twimg.com/profile_images/1718732845936680960/AVc5Imq6_normal.jpg",
        "reply_count": 2,
        "retweet_count": 10,
        "view_count": 15806,
        "like_count": 144
    },
    "1775211248239464837": {
        "content": "New Anthropic research paper: Many-shot jailbreaking.\n\nWe study a long-context jailbreaking technique that is effective on most large language models, including those developed by Anthropic and many of our peers.\n\nRead our blog post and the paper here: https://t.co/6F03M8AgcA https://t.co/wlcWYsrfg8",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 83,
        "retweet_count": 349,
        "view_count": 495508,
        "like_count": 1796
    },
    "1774833586736189911": {
        "content": "Just dropped a 4 hour lecture on \"Large Language Models\": https://t.co/KI5CJ6OksI\n\n0:00 Basics of language models \n2:30 Word2vec \n16:27 Transfer Learning \n19:23 BERT \n1:00:39 T5 \n1:31:14 GPT1-3 \n1:53:05 ChatGPT \n2:20:03 LLMs as Deep RL \n2:53:00 Policy Gradient \n3:32:50 Train your own LLM",
        "name": "Soheil Feizi",
        "photo": "https://pbs.twimg.com/profile_images/1330915304512294917/IDavUi_P_normal.jpg",
        "reply_count": 22,
        "retweet_count": 394,
        "view_count": 205783,
        "like_count": 2070
    },
    "1679957043653021698": {
        "content": "If you\u2019re a student and want to read paid posts, contact @natolambert by email or DM. Happy to provide a base 80%+ discount.",
        "name": "Interconnects",
        "photo": "https://pbs.twimg.com/profile_images/1674788478813618176/Ap6k4hCJ_normal.jpg",
        "reply_count": 2,
        "retweet_count": 1,
        "view_count": 7128,
        "like_count": 6
    },
    "1774809946447585783": {
        "content": "\"We introduce methods for discovering and applying sparse feature circuits. These are causally implicated subnetworks of human-interpretable features for explaining language model behaviors.\"\nhttps://t.co/bwc8YMrC2g https://t.co/bdXieXI7CL",
        "name": "ML Safety Daily",
        "photo": "https://pbs.twimg.com/profile_images/1548772139334979584/TQ1C6FwS_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 1071,
        "like_count": 13
    },
    "1774771291859673591": {
        "content": "Great work from my MATS scholars @calsmcdougall and @JBloomAus, in honour of today's special occasion!\n\nTurns out SAEs contain wild features, like a Neel Nanda feature, and this perseverance feature:\nhttps://t.co/qWr143w73C https://t.co/SfDM4THim3",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 10,
        "view_count": 7628,
        "like_count": 95
    },
    "1774611474364739742": {
        "content": "Google presents Gecko\n\nVersatile Text Embeddings Distilled from Large Language Models\n\nGecko with 768 emb dim competes with 7x larger models and 5x higher dimensional embeddings\n\nhttps://t.co/R9sQ8hpTGb https://t.co/wbjfsiGy4r",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 6,
        "retweet_count": 89,
        "view_count": 43087,
        "like_count": 474
    },
    "1774653027712139657": {
        "content": "New preprint is out on interplay between DPO and verbosity. Some of the first feedback we got on DPO was that training on LARGE scale the model becomes increasingly verbose until it diverges. Verbosity effects have also been observed in the OS community. Credit to @peterjliu https://t.co/Y0LdDAU8nO",
        "name": "Rafael Rafailov",
        "photo": "https://pbs.twimg.com/profile_images/1663362227762774017/B3ezAxFz_normal.jpg",
        "reply_count": 4,
        "retweet_count": 26,
        "view_count": 30643,
        "like_count": 140
    },
    "1774614763785314446": {
        "content": "The Jamba paper was just dropped\n\nhttps://t.co/ULNuTEcFfn https://t.co/rJ3900Yxm8",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 7,
        "retweet_count": 132,
        "view_count": 106555,
        "like_count": 724
    },
    "1773863558482202986": {
        "content": "@jxmnop It was adobe illustrator",
        "name": "Aidan Gomez",
        "photo": "https://pbs.twimg.com/profile_images/1621227750202679311/GpYknfyR_normal.jpg",
        "reply_count": 16,
        "retweet_count": 20,
        "view_count": 86730,
        "like_count": 788
    },
    "1773757499709042771": {
        "content": "Cool post! I was very surprised by this result. My guess is that \"adding noise with the same norm as the SAE error\" isn't a fair baseline, but I don't have a great story for why. I think better understanding WTF is going on here might help me understand SAEs better!",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 2,
        "view_count": 6328,
        "like_count": 53
    },
    "1773756298531918268": {
        "content": "Short research post on a potential issue arising in Sparse Autoencoders (SAEs): the reconstruction errors change model predictions much more than a random error of the same magnitude!\nhttps://t.co/vjCX2jHJLs",
        "name": "Wes Gurnee",
        "photo": "https://pbs.twimg.com/profile_images/1534617263667564550/G6E__cr__normal.jpg",
        "reply_count": 1,
        "retweet_count": 7,
        "view_count": 11780,
        "like_count": 72
    },
    "1773665533423923631": {
        "content": "Circuits are a hot topic in interpretability, but how do you find a circuit and guarantee it reflects how your model works?\n\nWe (@sandropezzelle, @boknilev, and I) introduce a new circuit-finding method, EAP-IG, and show it finds more faithful circuits https://t.co/P1ZlOH2O9n 1/8",
        "name": "Michael Hanna",
        "photo": "https://pbs.twimg.com/profile_images/1163241415494840321/J3GyxJu2_normal.jpg",
        "reply_count": 1,
        "retweet_count": 20,
        "view_count": 9438,
        "like_count": 113
    },
    "1773655245769330757": {
        "content": "Should be available on \ud835\udd4f next week. \n\nGrok 2 should exceed current AI on all metrics. In training now.",
        "name": "Elon Musk",
        "photo": "https://pbs.twimg.com/profile_images/1780044485541699584/p78MCn3B_normal.jpg",
        "reply_count": 4718,
        "retweet_count": 5094,
        "view_count": 20075161,
        "like_count": 34339
    },
    "1773510159740063860": {
        "content": "https://t.co/A12vgTpnTb",
        "name": "xAI",
        "photo": "https://pbs.twimg.com/profile_images/1769430779845611520/lIgjSJGU_normal.jpg",
        "reply_count": 684,
        "retweet_count": 1127,
        "view_count": 20672934,
        "like_count": 6990
    },
    "1773370168929825073": {
        "content": "\ud83d\udce2New research on mechanistic architecture design and scaling laws.\n\n- We perform the largest scaling laws analysis (500+ models, up to 7B) of beyond Transformer architectures to date\n\n- For the first time, we show that architecture performance on a set of isolated token manipulation tasks is correlated with metrics of interest at scale, such as compute-optimal loss. Say hello to fast architecture improvement!\n\n- Striped architectures consistently outperform homogeneous architectures, as they benefit from specialization of each layer type to particular subtasks\n\nAn avalanche of other findings in the paper:\n\n\ud83d\udcddPaper: https://t.co/mtZ2HVSpv9\n\ud83d\udda5\ufe0fRepo: https://t.co/7mt1GogBgQ",
        "name": "Michael Poli",
        "photo": "https://pbs.twimg.com/profile_images/1172515876815327233/OGPG3U_9_normal.jpg",
        "reply_count": 13,
        "retweet_count": 90,
        "view_count": 118896,
        "like_count": 454
    },
    "1773579998118478267": {
        "content": "want one now \n\n https://t.co/BIfKu0Odgl",
        "name": "Linus \u25cf\u1d17\u25cf Ekenstam",
        "photo": "https://pbs.twimg.com/profile_images/1584806710769762304/qCu_Jaox_normal.jpg",
        "reply_count": 422,
        "retweet_count": 2541,
        "view_count": 2261505,
        "like_count": 13817
    },
    "1773500332628492375": {
        "content": "incredibly impressed by @AI21Labs' Jamba today. This is the first legitimate Mixtral-killer we've seen and it came out of \"nowhere\":\n\nhttps://t.co/dGf5kXNFTl\n\nThey've helped me redefine my idea of a model \"weight class\" from \"number of parameters\" (increasingly outdated with MoEs and mixed arches) to \"default system requirements\".  It ~matches Mixtral on every benchmark, but every architecture choice seems ideal to max out a single 80GB A100 GPU, which makes it WAY better (like, 2-3x better in every efficiency/speed dimension you care about) for long context usecases. \n\nThis efficient long context stuff is what Mamba promised but it wasn't as clear until now and has again shifted my timelines on when/if Mamba dethrones Transformers (more likely they mix layers just like Jamba and StripedHyena show). Also dont miss Cobra - https://t.co/WhCN06VO9D Mamba may also just crush in multimodal applications as well.\n\nLastly - i think releasing only base model is kinda genius. Jamba has PEFT support OOTB. AI21 is asking you not to judge them on their instruct tuning - surely armies of cracked eastern european alpha coders will do that for them - and they surely will given the very strong base metrics. \n\nLet a thousand Jambas bloom.\n\nWhat a time to be alive.",
        "name": "swyx",
        "photo": "https://pbs.twimg.com/profile_images/1510319731466993664/tGoqnzGK_normal.jpg",
        "reply_count": 5,
        "retweet_count": 40,
        "view_count": 38726,
        "like_count": 341
    },
    "1773496682011107764": {
        "content": "Sparse autoencoders are currently a big deal in mech interp, but there's not a good, concise intro to what they are. I'm currently taking a stab at writing one! Here's the draft TLDR: https://t.co/fzdUDu2QGN",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 7,
        "retweet_count": 30,
        "view_count": 16605,
        "like_count": 346
    },
    "1773432235565420689": {
        "content": "I'm really excited about Neuronpedia's pivot to helping with sparse autoencoder research! Johnny has made a gorgeous UI for poking around inside models and I'm excited to see what new mech interp research this can enable/accelerate!",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 0,
        "retweet_count": 9,
        "view_count": 7058,
        "like_count": 105
    },
    "1773403396130885844": {
        "content": "1/ Introducing Neuronpedia: an open platform for interpretability research with hosting, visualizations, and tooling for Sparse Autoencoders (SAEs).\n\nLet's try it out! \u27a1\ufe0f\n\nNeuronpedia lets us instantly test activations of SAE features with custom text. Here's a Star Wars feature: https://t.co/hKi0ij5ke1",
        "name": "johnny",
        "photo": "https://pbs.twimg.com/profile_images/693545754053337089/2MoB8uh8_normal.jpg",
        "reply_count": 4,
        "retweet_count": 24,
        "view_count": 14137,
        "like_count": 155
    },
    "1772992930866745619": {
        "content": "10 years ago we published a paper estimating the exposure of jobs to automation. In this paper, reassess what AI can and cannot do in the era of Gen AI. Finally out in the @BrownJournal @maosbot \n\nhttps://t.co/HT6U5kQbiV https://t.co/yHimDFUhl9",
        "name": "Carl Benedikt Frey",
        "photo": "https://pbs.twimg.com/profile_images/990923915940769792/zTodQNnc_normal.jpg",
        "reply_count": 5,
        "retweet_count": 68,
        "view_count": 37237,
        "like_count": 177
    },
    "1773340316835131757": {
        "content": "[75min talk] i finally recorded this lecture I gave two weeks ago because people kept asking me for a video\n\nso here it is, enjoy \"The Little guide to building Large Language Models in 2024\"\n\ntried to keep it short and comprehensive \u2013 focusing on concepts that are crucial for training good LLM but often hidden in tech reports",
        "name": "Thomas Wolf",
        "photo": "https://pbs.twimg.com/profile_images/1629469939860946946/WUyBolSu_normal.jpg",
        "reply_count": 12,
        "retweet_count": 241,
        "view_count": 121113,
        "like_count": 1378
    },
    "1773172911282544989": {
        "content": "BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text\n\nweights: https://t.co/rDh7qrdJDV\nabs: https://t.co/DTsCerSnzi https://t.co/cFWqoY2NqR",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 7,
        "retweet_count": 47,
        "view_count": 20385,
        "like_count": 169
    },
    "1773149061274562737": {
        "content": "https://t.co/SsUx7EQf44",
        "name": "Arda Gitmez",
        "photo": "https://pbs.twimg.com/profile_images/1531844970323357696/TYFFdftL_normal.jpg",
        "reply_count": 18,
        "retweet_count": 337,
        "view_count": 165759,
        "like_count": 2117
    },
    "1773023384344904120": {
        "content": "Interesting point by richard Werner. The joint probability that all assumptions of neoclassical theory would hold is less than 1% https://t.co/s010Bgt5p9",
        "name": "Louis-Philippe Rochon",
        "photo": "https://pbs.twimg.com/profile_images/1745308111743647744/jHXg3yeX_normal.jpg",
        "reply_count": 73,
        "retweet_count": 170,
        "view_count": 809579,
        "like_count": 721
    },
    "1773166015716683890": {
        "content": "Daniel Kahneman: happiness is in the remembering, not in the experiencing, of events https://t.co/AidpKq7D12",
        "name": "Tsarathustra",
        "photo": "https://pbs.twimg.com/profile_images/1690941803200208896/PRpYEDXP_normal.jpg",
        "reply_count": 67,
        "retweet_count": 423,
        "view_count": 241478,
        "like_count": 2771
    },
    "1773017055974789176": {
        "content": "Meet Hume\u2019s Empathic Voice Interface (EVI), the first conversational AI with emotional intelligence.",
        "name": "Hume",
        "photo": "https://pbs.twimg.com/profile_images/1460663084788420623/0X8Dn5F8_normal.jpg",
        "reply_count": 159,
        "retweet_count": 485,
        "view_count": 801782,
        "like_count": 2656
    },
    "1773166299717255380": {
        "content": "Google presents Long-form factuality in large language models\n\n- Proposes that LLM agents can be used as automated evaluators for longform factuality\n- Shows that LLM agents can achieve superhuman rating performance\n\nrepo: https://t.co/rlAIFSqfTU\nabs: https://t.co/L3CpeLaFpQ https://t.co/OSNpnr1BmP",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 6,
        "retweet_count": 86,
        "view_count": 45170,
        "like_count": 472
    },
    "1772776784284524853": {
        "content": "Jeff Bezos on how to deal with stress. https://t.co/aZrDcSEjOI",
        "name": "Jon Erlichman",
        "photo": "https://pbs.twimg.com/profile_images/1608140927112970244/f45SMuqJ_normal.jpg",
        "reply_count": 102,
        "retweet_count": 2246,
        "view_count": 1465351,
        "like_count": 11476
    },
    "1773002542777045277": {
        "content": "Today we\u2019ve lost a giant and a visionary: Prof. Daniel Kahneman has passed at the age of 90. The Princeton SPIA community shares our condolences with his family and all who knew him, learned from him, and loved him. https://t.co/JbTXQSuzlw",
        "name": "Princeton School of Public & International Affairs",
        "photo": "https://pbs.twimg.com/profile_images/1506998896576405517/P7vCtlf9_normal.jpg",
        "reply_count": 113,
        "retweet_count": 1471,
        "view_count": 1084103,
        "like_count": 4348
    },
    "1773029004204814546": {
        "content": "Lumiere is a space-time diffusion research model from Google Research. Using a single reference image, Lumiere can generate videos in the target style by utilizing fine-tuned text-to-image model weights.\n\nLearn more about Lumiere \u2192 https://t.co/QAMgC4SOMd https://t.co/qb0ooRJCuj",
        "name": "Google AI",
        "photo": "https://pbs.twimg.com/profile_images/993649592422907904/yD7LkqU2_normal.jpg",
        "reply_count": 49,
        "retweet_count": 139,
        "view_count": 70375,
        "like_count": 595
    },
    "1772969101037576325": {
        "content": "There's been lots of coverage about the NHS today - all of it focused on England.\n\nYou\u2019d think it was brilliant in Labour-run Wales.\n\nYou\u2019d be wrong.\n\nHere\u2019s the truth about the NHS with the Conservatives vs. under Labour \ud83d\udc47 \ud83e\uddf5 https://t.co/llUps0BVkz",
        "name": "Conservatives",
        "photo": "https://pbs.twimg.com/profile_images/1726550468191469568/lsMFt5-G_normal.jpg",
        "reply_count": 1730,
        "retweet_count": 202,
        "view_count": 210604,
        "like_count": 448
    },
    "1772764680639148285": {
        "content": "The king is dead\n\nRIP GPT-4\nClaude opus #1 ELo\n\nHaiku beats GPT-4 0613 &amp; Mistral large\nThat\u2019s insane for how cheap &amp; fast it is https://t.co/fAwzJScLTH",
        "name": "Nick Dobos",
        "photo": "https://pbs.twimg.com/profile_images/1489416790316748804/iXxGy6-B_normal.png",
        "reply_count": 64,
        "retweet_count": 217,
        "view_count": 673173,
        "like_count": 1536
    },
    "1772759835714728217": {
        "content": "[Arena Update]\n\n70K+ new Arena votes\ud83d\uddf3\ufe0f are in!\n\nClaude-3 Haiku has impressed all, even reaching GPT-4 level by our user preference! Its speed, capabilities & context length are unmatched now in the market\ud83d\udd25\n\nCongrats @AnthropicAI on the incredible Claude-3 launch!\n\nMore exciting updates:\n- Starling-LM-7B-beta, PPO'd with 34B reward model, climbing fast on the leaderboard. Now the best 7B open model!\n- @cohere's Command-R now joins Arena\ud83e\udd16 result coming soon.",
        "name": "lmsys.org",
        "photo": "https://pbs.twimg.com/profile_images/1641380096778055681/xRrCcdkf_normal.jpg",
        "reply_count": 30,
        "retweet_count": 238,
        "view_count": 913530,
        "like_count": 1098
    },
    "1772726585822421077": {
        "content": "This is AI. \n\nIt\u2019s actually so over. \n\n https://t.co/ZgsMAzLTTK",
        "name": "Ate-a-Pi",
        "photo": "https://pbs.twimg.com/profile_images/1741356225261142016/NMKAoAr-_normal.jpg",
        "reply_count": 870,
        "retweet_count": 1076,
        "view_count": 4717796,
        "like_count": 9699
    },
    "1772599492522475796": {
        "content": "This is an older (2002) study that compares year of \u201cretirement\u201d vs years left to live. https://t.co/ZNN3p0m2qY",
        "name": "Jack",
        "photo": "https://pbs.twimg.com/profile_images/950164381429633025/N3n1snsI_normal.jpg",
        "reply_count": 569,
        "retweet_count": 1559,
        "view_count": 2191631,
        "like_count": 9191
    },
    "1772663653843530006": {
        "content": "Politico profile on AI lobbying has HILARIOUS anecdote:\n\nTristan Harris showed lawmakers  META chatbot could give instructions to make bio-weapon\n\nMark Zuckerberg was present, took out phone &amp; got same instructions using Google\n\nRoom erupted into laughter! https://t.co/Lx1Dz6B75E https://t.co/MYbiPhwhWn",
        "name": "Louis Anslow",
        "photo": "https://pbs.twimg.com/profile_images/1728772005535641600/togP0BUm_normal.jpg",
        "reply_count": 33,
        "retweet_count": 236,
        "view_count": 432625,
        "like_count": 1422
    },
    "1772729572330471674": {
        "content": "Reviewers gotta stop with the whole \"you didn't cite [this work] ergo I'm rejecting your submission\".\nMissing the citation of a single paper (even if it's your paper/your friend's paper/your favorite paper of all time) shouldn't be the sole reason for rejection.",
        "name": "Sasha Luccioni, PhD \ud83e\udd8b\ud83d\udcbb\ud83c\udf0e\u2728\ud83e\udd17",
        "photo": "https://pbs.twimg.com/profile_images/1704612826797498368/OSpePMlj_normal.jpg",
        "reply_count": 4,
        "retweet_count": 4,
        "view_count": 6661,
        "like_count": 56
    },
    "1772635619304390988": {
        "content": "Jailbreaking is Best Solved by Definition\n\nExisting defenses against LLM jailbreaks fail; a successful defense must accurately define what constitutes unsafe outputs, with post-processing emerging as a robust solution given a good definition.\nhttps://t.co/6PjbjPYnjC https://t.co/Kq2aAwOP1i",
        "name": "ML Safety Daily",
        "photo": "https://pbs.twimg.com/profile_images/1548772139334979584/TQ1C6FwS_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 779,
        "like_count": 6
    },
    "1772348624472563963": {
        "content": "Love to see this in @anthropic 's recent blog. \nAlso a great opportunity to recognize ppl such as @jovialjoy @AJLUnited @schock and @rajiinio (it's some of her life's work!) in articulating what this is, how it works, and why it's important.\nhttps://t.co/zXTWscph37 https://t.co/8hbDrCNxoT",
        "name": "MMitchell",
        "photo": "https://pbs.twimg.com/profile_images/759051761487187968/24OG0RCC_normal.jpg",
        "reply_count": 4,
        "retweet_count": 23,
        "view_count": 16170,
        "like_count": 153
    },
    "1772311389857571157": {
        "content": "A glimpse of our early work with artists and filmmakers to see how Sora can help bring ideas into reality:\u00a0https://t.co/kIowcqry0d",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 469,
        "retweet_count": 952,
        "view_count": 1946874,
        "like_count": 4803
    },
    "1772075066143990247": {
        "content": "Microsoft presents Can large language models explore in-context?\n\nWhile SotA LLMs may explore simple RL environments with careful prompting, training interventions like fine-tuning may be needed for more complex exploration capabilities\n\nhttps://t.co/cbEYeWaAMa https://t.co/BTGlTUQLMp",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 3,
        "retweet_count": 47,
        "view_count": 17392,
        "like_count": 219
    },
    "1771609042542039421": {
        "content": "Mistral just announced at @SHACK15sf that they will release a new model today:\n\nMistral 7B v0.2 Base Model\n\n- 32k instead of 8k context window\n- Rope Theta = 1e6\n- No sliding window https://t.co/iAuEUEOw5K",
        "name": "Marvin von Hagen",
        "photo": "https://pbs.twimg.com/profile_images/1755124632079011840/ZTwsU5wj_normal.jpg",
        "reply_count": 27,
        "retweet_count": 128,
        "view_count": 263576,
        "like_count": 811
    },
    "1770955024367284453": {
        "content": "Next our series of small monthly updates from the interpretability team, including a few fun things:\n\n1. We use do feature attribution to find features related to specific completions (following the athlete-sport association example of @NeelNanda5 ) https://t.co/kSV0JokwiO",
        "name": "Joshua Batson",
        "photo": "https://pbs.twimg.com/profile_images/1251741215415885829/6kDbML8z_normal.jpg",
        "reply_count": 1,
        "retweet_count": 16,
        "view_count": 19062,
        "like_count": 72
    },
    "1770921128606789883": {
        "content": "Another small update from us, including some fun results about circuit analysis with SAEs.",
        "name": "Chris Olah",
        "photo": "https://pbs.twimg.com/profile_images/1422800200146378753/TdaSuRIB_normal.jpg",
        "reply_count": 0,
        "retweet_count": 8,
        "view_count": 16577,
        "like_count": 88
    },
    "1770915140990369932": {
        "content": "A small update from the Anthropic interpretability team:\nhttps://t.co/0TXHAAhqQQ",
        "name": "Adam Jermyn",
        "photo": "https://pbs.twimg.com/profile_images/1046124191068577797/tqQ72nrh_normal.jpg",
        "reply_count": 2,
        "retweet_count": 11,
        "view_count": 48628,
        "like_count": 144
    },
    "1770928043537600645": {
        "content": "I love reading these regular research updates! The Anthropic interp team is killing it, both in research output and comms!",
        "name": "Tom Lieberum",
        "photo": "https://pbs.twimg.com/profile_images/1263043897162432513/n882SZGG_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 557,
        "like_count": 9
    },
    "1770845268721684791": {
        "content": "New from our team @GoogleAI @GoogleHealth - a toolbox for Health Equity evaluations in LLMs. Includes a multifaceted human assessment framework, \ud83d\udc407 newly-released adversarial datasets\ud83d\udc40, and the largest human eval of equity-related harms/biases to date, feat. 17000+ ratings \ud83d\udc47",
        "name": "Alan Karthikesalingam",
        "photo": "https://pbs.twimg.com/profile_images/1028576902594932736/7biCF3Sb_normal.jpg",
        "reply_count": 3,
        "retweet_count": 20,
        "view_count": 31224,
        "like_count": 117
    },
    "1770156542282637823": {
        "content": "Excited to share our newest work! \ud83d\udcdd Evaluation of LLMs is hard, especially for health equity. We provide a multifaceted human assessment framework, 7 newly-released adversarial datasets, and perform the largest human eval study on this topic to date. \ud83e\uddf5:\n\nhttps://t.co/8yBo2q9wMT https://t.co/9qes6c6Pof",
        "name": "Karan Singhal",
        "photo": "https://pbs.twimg.com/profile_images/1574418065642733568/lilstQIT_normal.jpg",
        "reply_count": 5,
        "retweet_count": 27,
        "view_count": 40139,
        "like_count": 115
    },
    "1770618237782307075": {
        "content": "This remains one of the most consequential experiments in AI: Bloomberg trained a GPT-3.5 class AI on their own financial data last year\u2026\n\n\u2026only to find that GPT-4 8k, without specialized finance training, beat it on almost all finance tasks.\n\nHard to beat the frontier models. https://t.co/I86UiGchnP",
        "name": "Ethan Mollick",
        "photo": "https://pbs.twimg.com/profile_images/1601382188712398850/3AAOlqrX_normal.jpg",
        "reply_count": 58,
        "retweet_count": 402,
        "view_count": 621930,
        "like_count": 2756
    },
    "1641974170945814529": {
        "content": "The new BloombergGPT AI may be harbinger of the next wave of corporate AI. Current AIs are trained on web data (though firms can add their own training)\n\nBloombergGPT is 52% either proprietary data or cleaned financial data. And it shows signs of being better at financial tasks. https://t.co/VmDKjg6ztX",
        "name": "Ethan Mollick",
        "photo": "https://pbs.twimg.com/profile_images/1601382188712398850/3AAOlqrX_normal.jpg",
        "reply_count": 62,
        "retweet_count": 640,
        "view_count": 2379086,
        "like_count": 4199
    },
    "1770641614718833050": {
        "content": "Meta announces Reverse Training to Nurse the Reversal Curse\n\nLarge language models (LLMs) have a surprising failure: when trained on \"A has a feature B\", they do not generalize to \"B is a feature of A\", which is termed the Reversal Curse. Even when training with trillions of https://t.co/HumuA6CCHX",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 5,
        "retweet_count": 31,
        "view_count": 19948,
        "like_count": 162
    },
    "1770741030704353686": {
        "content": "Great new Google DeepMind paper on evaluating frontier models for dangerous capabilities. The evals cover four areas: persuasion and deception; cyber-security; self-proliferation; and self-reasoning. They test agents, comprised of the model + scaffolding. https://t.co/MjfaYz6qTq https://t.co/4Va1uWd8IR",
        "name": "S\u00e9b Krier",
        "photo": "https://pbs.twimg.com/profile_images/1638328586351386626/K82oZLUM_normal.jpg",
        "reply_count": 9,
        "retweet_count": 42,
        "view_count": 27118,
        "like_count": 275
    },
    "1770536456416571699": {
        "content": "Real-time medical advice from a type of AI known to hallucinate while being very persuasive?  This is both stupid and dangerous.\nhttps://t.co/Z664zVBBoC",
        "name": "CK",
        "photo": "https://pbs.twimg.com/profile_images/1228649239/sea-250_normal.jpg",
        "reply_count": 10,
        "retweet_count": 7,
        "view_count": 18818,
        "like_count": 38
    },
    "1770665002309161336": {
        "content": "Great to see this new @GoogleResearch work on improved AI methods for flood forecasting published in @Nature today.\n\nFloods are the most common natural disaster, and are responsible for roughly $50B in annual financial damages.  The flood-related disaster rate has more than doubled since the year 2000 partly due to climate change.  Nearly 1.5B people, making up 19% of the world\u2019s population, are exposed to substantial risks from severe flood events.\n\nOur earliest work in this area in India in 2018 relied on stream gauge measurements (essentially water depth measurements in different points in rivers and streams).  This worked well, but relied on having stream gauges and getting those measurements into an ML-based prediction system.\n\nThis work is able to make flood forecasts without the need for these stream gauge measurements, enabling us to do global flood forecasting, rather than only in a small number of countries where we were able to get stream gauge measurements.\n\nArticle: \"Global prediction of extreme floods in ungauged watersheds\u201d\nhttps://t.co/Ix0AKqgsZ2\n\nhttps://t.co/1DmOllDYyf",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 10,
        "retweet_count": 19,
        "view_count": 33214,
        "like_count": 232
    },
    "1753316648680038643": {
        "content": "Just published a set of Sparse AutoEncoders GPT2-Small residual stream all layers. https://t.co/X9KH01w3y3. Thanks @NeelNanda5 and @ArthurConmy for the support!",
        "name": "Joseph Bloom",
        "photo": "https://pbs.twimg.com/profile_images/1364675869323759619/k25rpOdf_normal.jpg",
        "reply_count": 0,
        "retweet_count": 8,
        "view_count": 8574,
        "like_count": 58
    },
    "1770639633766121797": {
        "content": "When Do We Not Need Larger Vision Models?\n\nrepo: https://t.co/T2WVGL4HQd\nabs: https://t.co/FTNsiDJN5C\n\n**Abstract:**\n\nIn this work, we explore the necessity of larger models for enhanced visual understanding. Our findings suggest that scaling based on the dimension of image scales\u2014termed as **Scaling on Scales (S2)**\u2014rather than increasing the model size, generally leads to superior performance across a diverse range of downstream tasks.\n\n**Key Findings:**\n\n1. Smaller models employing S2 can capture most of the insights learned by larger models.\n2. Pre-training smaller models with S2 can level the playing field with larger models, and in some cases, surpass them.\n\n**Implications for Future Research:**\n\nS2 introduces several considerations for future work:\n\n- **Scale-Selective Processing:** Not all scales at every position within an image hold valuable information. Depending on the content of the image and the overarching task, it can be more efficient to process certain scales for specific regions. This approach mimics the bottom-up and top-down selection mechanisms found in human visual attention (References: 86, 59, 33).\n\n- **Parallel Processing of a Single Image:** Unlike traditional Vision Transformers (ViT) where the entire image is processed in unison, S2 allows each sub-image to be handled independently. This capability facilitates parallel processing of different segments of a single image, which is particularly advantageous in scenarios where reducing latency in processing large images is paramount (Reference: 84).",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 2,
        "retweet_count": 68,
        "view_count": 28174,
        "like_count": 304
    },
    "1770199098345586815": {
        "content": "Incredibly cool work by my friend and compatriot @PetarV_93 ! TacticAI uses GNNs & Geometric deep learning to make tactical suggestions for the corner kicks and it turns out those suggestions (compared to real corners from previous games) are favored by football experts 90% of the time! \ud83d\ude31\n\nDeveloped in collaboration with Liverpool FC. I saw Petar visiting Liverpool and working on this while I was still at DeepMind and knew this is going to be uber cool work.\n\nWhen computer games become too easy there is always the real-world! :)\n\nCongrats!\n\nPaper: https://t.co/ewkjqJsgtp",
        "name": "Aleksa Gordi\u0107 \ud83c\udf7f\ud83e\udd16",
        "photo": "https://pbs.twimg.com/profile_images/1625654180105920514/9dCpi8Rs_normal.jpg",
        "reply_count": 1,
        "retweet_count": 22,
        "view_count": 69866,
        "like_count": 121
    },
    "1770221903661437086": {
        "content": "\ud83d\udea8Paper alert! Grokking Beyond Neural Networks has just been published at TMLR.\n\nhttps://t.co/EjRx3iFeFT https://t.co/4fVw4c62uQ",
        "name": "Jack Miller",
        "photo": "https://pbs.twimg.com/profile_images/1702198106249383936/aVy4CsAe_normal.jpg",
        "reply_count": 4,
        "retweet_count": 17,
        "view_count": 11771,
        "like_count": 105
    },
    "1770164255343485158": {
        "content": "Congrats. Looking forward to diving in",
        "name": "Pranav Rajpurkar",
        "photo": "https://pbs.twimg.com/profile_images/1730643480483930112/2VDfUAJs_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 2995,
        "like_count": 13
    },
    "1770154743349870772": {
        "content": "Excited to share new work on surfacing health equity-related biases in LLMs. We design rubrics covering 6 dimensions of bias, release EquityMedQA, a collection of 7 adversarial datasets, and conduct a large-scale human evaluation study with Med-PaLM 2. https://t.co/tkAF7TdJGM https://t.co/0yUGsTTmzv",
        "name": "Stephen Pfohl",
        "photo": "https://pbs.twimg.com/profile_images/1317296985305616384/Nh8uLufP_normal.jpg",
        "reply_count": 2,
        "retweet_count": 35,
        "view_count": 20082,
        "like_count": 145
    },
    "1770177729767305428": {
        "content": "Jensen got Kendrick??? now i'm paying attention",
        "name": "Ian Hogarth",
        "photo": "https://pbs.twimg.com/profile_images/1728782716731105280/nVAiafUn_normal.jpg",
        "reply_count": 2,
        "retweet_count": 3,
        "view_count": 5388,
        "like_count": 25
    },
    "1769852136639357060": {
        "content": "Nvidia\u2019s GTC event just wrapped up and check out all the A-listers leaving the building: George Lucas, Kendrick Lamar, Nas, Trevor Noah, Ashton Kutcher and more:\n\n$NVDA #GTC24 https://t.co/VDqAWpj6La",
        "name": "Kristina Partsinevelos",
        "photo": "https://pbs.twimg.com/profile_images/1585718447832551424/FD_6vf8h_normal.jpg",
        "reply_count": 68,
        "retweet_count": 93,
        "view_count": 187542,
        "like_count": 648
    },
    "1770127983258558790": {
        "content": "Today we release the Skin Condition Image Network (SCIN) dataset in collaboration with physicians @StanfordMed. Designed to reflect the broad range of conditions searched for online, it\u2019s freely available as a resource for researchers, educators, &amp; devs \u2192https://t.co/SosUb1T9Bu https://t.co/CUFSkFaYIe",
        "name": "Google AI",
        "photo": "https://pbs.twimg.com/profile_images/993649592422907904/yD7LkqU2_normal.jpg",
        "reply_count": 19,
        "retweet_count": 252,
        "view_count": 110093,
        "like_count": 1034
    },
    "1769931708063785381": {
        "content": "IBM presents Larimar: Large Language Models with Episodic Memory Control\n\nAttains accuracy comparable to most competitive baselines while yielding speed-ups of 4-10x\n\nhttps://t.co/LR5xrmPsaG https://t.co/XAZosp6N7c",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 4,
        "retweet_count": 76,
        "view_count": 26661,
        "like_count": 302
    },
    "1769834336558162405": {
        "content": "Jensen showing us the endgame of GenAI:\n\nMulti-modal in -> Multi-modal out.\n\nThe is the final model we will all use one day.\nCan get any modality and generate every modality.\nWhile also being able to work without each of it's parts.",
        "name": "Yam Peleg",
        "photo": "https://pbs.twimg.com/profile_images/1505912788031623170/GC7LMHNp_normal.jpg",
        "reply_count": 26,
        "retweet_count": 88,
        "view_count": 36949,
        "like_count": 549
    },
    "1769860044324319658": {
        "content": "Today is the beginning of our moonshot to solve embodied AGI in the physical world. I\u2019m so excited to announce Project GR00T, our new initiative to create a general-purpose foundation model for humanoid robot learning.\n\nThe GR00T model will enable a robot to understand multimodal instructions, such as language, video, and demonstration, and perform a variety of useful tasks. We are collaborating with many leading humanoid companies around the world, so that GR00T may transfer across embodiments and help the ecosystem thrive.\n\nGR00T is born on NVIDIA\u2019s deep technology stack. We simulate in Isaac Lab (new app on Omniverse Isaac Sim for humanoid learning), train on OSMO (new compute orchestration system to scale up models), and deploy to Jetson Thor (new edge GPU chip designed to power GR00T).\n\nAnnounced in Jensen's keynote, Project GR00T is a cornerstone for the \u201cFoundation Agent\u201d roadmap of the newly founded GEAR Lab. At GEAR, we are building generally capable agents that learn to act skillfully in many worlds, virtual and real. See if you can spot \"GEAR\" in the video ;)\n\nJoin us on the journey to land on the moon.",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 197,
        "retweet_count": 1162,
        "view_count": 831997,
        "like_count": 5291
    },
    "1769842867621581299": {
        "content": "Congratulations, interesting how Github stars seem to correlate to superfluous parameters \ud83d\ude09",
        "name": "Arthur Mensch",
        "photo": "https://pbs.twimg.com/profile_images/1670440736389582849/sJUeK3n-_normal.jpg",
        "reply_count": 55,
        "retweet_count": 98,
        "view_count": 149348,
        "like_count": 975
    },
    "1769770983924142475": {
        "content": "The Grok-1 repo is getting pretty popular. I will be responding to pull requests and issues. Feel free to contribute! https://t.co/NHhbyhuEaq",
        "name": "Igor Babuschkin",
        "photo": "https://pbs.twimg.com/profile_images/1233219229496668160/l1xzePUi_normal.jpg",
        "reply_count": 62,
        "retweet_count": 71,
        "view_count": 247703,
        "like_count": 880
    },
    "1769822727949472186": {
        "content": "Did Jensen just leak GPT-4 parameters count?!\n\n\"the latest OpenAI model has approximately 1.8 trillion parameters\"\n\nI mean.. we already know.. \n\nBut is it official now?",
        "name": "Yam Peleg",
        "photo": "https://pbs.twimg.com/profile_images/1505912788031623170/GC7LMHNp_normal.jpg",
        "reply_count": 9,
        "retweet_count": 24,
        "view_count": 65517,
        "like_count": 358
    },
    "1769810359064408184": {
        "content": "Holy ****, this is officially insane!!! \ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\n\n#GTC24 https://t.co/pdaSnzA8ip",
        "name": "Bojan Tunguz",
        "photo": "https://pbs.twimg.com/profile_images/1364232665440935946/cRy6WUM9_normal.jpg",
        "reply_count": 32,
        "retweet_count": 43,
        "view_count": 48146,
        "like_count": 689
    },
    "1769824889102348366": {
        "content": "Goodness me. \n\n1x GPU Blackwell - 192GB VRAM\n2x GPU Blackwell with CPU - 384 GB VRAM\n\nUnbelievable. https://t.co/vmINxtCrEi",
        "name": "Migel Tissera",
        "photo": "https://pbs.twimg.com/profile_images/1765247685827956736/_RALBjIx_normal.jpg",
        "reply_count": 29,
        "retweet_count": 171,
        "view_count": 151642,
        "like_count": 1489
    },
    "1769730077476917694": {
        "content": "Google just unveiled VLOGGER, a tool that generates lifelike talking videos with a single photo\n\nNow, anybody can become a YouTuber.\n\nHere's what you need to know: https://t.co/gpJVBNoAp3",
        "name": "EyeingAI",
        "photo": "https://pbs.twimg.com/profile_images/1669416462077837331/2w6F6q2u_normal.jpg",
        "reply_count": 640,
        "retweet_count": 143,
        "view_count": 2944227,
        "like_count": 782
    },
    "1769831073381241278": {
        "content": "Everybody: Accelerate\nJensen: Hold my beer\n\n30x inference the performance from previous generation https://t.co/JQGf9bINUZ",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 7,
        "retweet_count": 19,
        "view_count": 12850,
        "like_count": 193
    },
    "1769812043341639880": {
        "content": "ML bible arrived today autographed by the authors \ud83d\ude4f https://t.co/ToM8kqN0Cp",
        "name": "Michael Bronstein",
        "photo": "https://pbs.twimg.com/profile_images/1670082204364427266/TFASoaSY_normal.jpg",
        "reply_count": 11,
        "retweet_count": 22,
        "view_count": 24594,
        "like_count": 469
    },
    "1770626660338913666": {
        "content": "\ud83d\udea8 Reverse Training to Nurse the Reversal Curse\ud83d\udea8 \nLLMs fail on \u201cB is A\u201d if only trained on \"A is B\".\n- Reverse training doubles training tokens by reversing strings\n- Outperforms data-matched standard baselines\n- Fixes issues on reversal tasks\nhttps://t.co/yCcngh0C2X\n\ud83e\uddf5(1/6) https://t.co/4OXDNx0fry",
        "name": "Jason Weston",
        "photo": "https://pbs.twimg.com/profile_images/1161680026561069061/i-DdZcc1_normal.jpg",
        "reply_count": 1,
        "retweet_count": 24,
        "view_count": 48999,
        "like_count": 170
    },
    "1769794118035865890": {
        "content": "Are you excited about @ch402-style mechanistic interpretability research? I'm looking for scholars to mentor via MATS - apply by April 12!\n\nI'm very impressed by the great work from past scholars, and enjoy mentoring promising mech interp talent. I'm excited for my next cohort!",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 3,
        "retweet_count": 28,
        "view_count": 47310,
        "like_count": 189
    },
    "1769769275957334256": {
        "content": "When you have access to AGI and don\u2019t need to deal with chatgpt like us normal dogs: https://t.co/BpsWSP70sU",
        "name": "Flowers from the future",
        "photo": "https://pbs.twimg.com/profile_images/1769998727194804224/b7SW-RzC_normal.jpg",
        "reply_count": 37,
        "retweet_count": 104,
        "view_count": 161973,
        "like_count": 1044
    },
    "1769479649221070880": {
        "content": "@aryaman2020 @maxbittker I wanted to flag that the original image in this thread is actually not an attention pattern, but the different in token log-likelihoods across a phase change, from this paper: https://t.co/g78cqxNv4C https://t.co/1qC299aEfZ",
        "name": "Chris Olah",
        "photo": "https://pbs.twimg.com/profile_images/1422800200146378753/TdaSuRIB_normal.jpg",
        "reply_count": 1,
        "retweet_count": 0,
        "view_count": 1352,
        "like_count": 7
    },
    "1769053019939967080": {
        "content": "We live in such strange times. Apple, a company famous for its secrecy, published a paper with staggering amount of details on their multimodal foundation model. Those who are supposed to be open are now wayyy less than Apple.\n\nMM1 is a treasure trove of analysis. They discuss lots of architecture designs and even disclose that they train on GPT-4V-generated data. They provide exact scaling law coefficients (to 4 significant figures), MoE settings, and even optimal learning rate functions.\n\nI have not seen this level of details from a big tech's whitepaper for a very, very long time. Apple's so back!",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 57,
        "retweet_count": 764,
        "view_count": 551289,
        "like_count": 4469
    },
    "1709875695776592252": {
        "content": "Permit me to pique your interest: Self-Taught Optimizer (STOP) \n\nThis paper reveals a powerful new capability of large language models - the ability to recursively improve how they apply themselves. The authors show that models like GPT-4 can optimize code that leverages the model itself, exhibiting sophisticated techniques like genetic algorithms without any exposure in training. This demonstrates that modern language models are ready to take the first steps towards recursively self-improving systems. \n\nThe consequences of this conclusion are profound. It tells us that human engineering is no longer essential for scaffolding language models - they can begin improving their own reasoning scaffolds. And they can do so in a way aligned with a provided utility function, at least initially. This could lead to rapid advances in building more capable and general AI systems.\n\nAt the same time, this conclusion flags important risks. Unconstrained recursive self-improvement has been associated with existential threats from AI. Studying failures like reward hacking gives us insight into dangers before they occur in more powerful systems. We must guide this technology thoughtfully.\n\nBut used responsibly, this new capability also offers immense upsides for humanity. It could discover ways to apply language models we never imagined, unlocking solutions to our greatest challenges in health, education, sustainability and more. Self-improving code may be the missing catalyst to transform language models into beneficial AI we can trust. But we must engage deeply with this technology today to ensure it reflects human values. This paper opens the door - it's up to us to shape what comes next. If we rise to meet this challenge, a bright future lies ahead.",
        "name": "Carlos E. Perez",
        "photo": "https://pbs.twimg.com/profile_images/1740015728105832448/fRPNehGE_normal.png",
        "reply_count": 44,
        "retweet_count": 318,
        "view_count": 684982,
        "like_count": 1514
    },
    "1763243868353622089": {
        "content": "Can we build an LLM system to forecast geo-political events at the level of human forecasters?\n\nIntroducing our work Approaching Human-Level Forecasting with Language Models!\n\nArxiv: https://t.co/G1VK5k3iCa\nJoint work with @dannyhalawi15, @FredZhang0, and @jcyhc_ai https://t.co/arRGmtoItV",
        "name": "Jacob Steinhardt",
        "photo": "https://pbs.twimg.com/profile_images/1256077282856189953/r5Qc_t7M_normal.jpg",
        "reply_count": 11,
        "retweet_count": 71,
        "view_count": 41790,
        "like_count": 377
    },
    "1768737400023388623": {
        "content": "If I'm reviewing your #ICML paper and you have a table with data that *should* be displayed as a figure, then rest assured, you are going to get a comment telling you to visualize your data and telling you exactly how to do so \ud83d\ude07",
        "name": "Rylan Schaeffer",
        "photo": "https://pbs.twimg.com/profile_images/1733557514338471936/uXIn8yUI_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 2537,
        "like_count": 9
    },
    "1768700141307855160": {
        "content": "It's gorgeous.",
        "name": "Fran\u00e7ois Fleuret",
        "photo": "https://pbs.twimg.com/profile_images/1741919776773902336/pXUEFYUA_normal.jpg",
        "reply_count": 2,
        "retweet_count": 2,
        "view_count": 7083,
        "like_count": 44
    },
    "1767569938217087199": {
        "content": "Ok, this is amazing.\n\nI asked Claude 3 to generate an animation of the Pythagorean Theorem and this is what it created: https://t.co/bM4oDbyEbv",
        "name": "Alvaro Cintas",
        "photo": "https://pbs.twimg.com/profile_images/1615753720691556375/3IlAzsa0_normal.jpg",
        "reply_count": 68,
        "retweet_count": 325,
        "view_count": 541401,
        "like_count": 2346
    },
    "1768668564624654381": {
        "content": "Wanna know gpt-3.5-turbo's embed size? We find a way to extract info from LLM APIs and estimate gpt-3.5-turbo\u2019s embed size to be 4096. With the same trick we also develop 25x faster logprob extraction, audits for LLM APIs, and more!\n\ud83d\udcc4 https://t.co/NdYU8ZhuVH\nHere\u2019s how 1/\ud83e\uddf5 https://t.co/JOFmR0kmte",
        "name": "Matthew Finlayson",
        "photo": "https://pbs.twimg.com/profile_images/1413755625780121602/Krp10Rkr_normal.jpg",
        "reply_count": 6,
        "retweet_count": 79,
        "view_count": 144462,
        "like_count": 363
    },
    "1768514569264087083": {
        "content": "GDP per head is $ 83,000 in the USA, $ 52,000 in the UK and $36,000 in Europe according to the IMF. So how would linking ourselves more tightly to EU policies make us better off, when we already have higher incomes than  France, Italy, Spain etc.?",
        "name": "John Redwood",
        "photo": "https://pbs.twimg.com/profile_images/752484207021129728/wKk5lnls_normal.jpg",
        "reply_count": 398,
        "retweet_count": 267,
        "view_count": 82001,
        "like_count": 932
    },
    "1768311370360218097": {
        "content": "Thrilled to share our latest @nejm_ai article (https://t.co/7tljeH6MQc) releasing a new oncology NLP benchmark of 40 breast and pancreatic cancer progress notes from UCSF, comprehensively annotated by medical experts! (1/7)",
        "name": "Madhumita Sushil",
        "photo": "https://pbs.twimg.com/profile_images/1370438828847202313/Iw1dEClC_normal.jpg",
        "reply_count": 3,
        "retweet_count": 25,
        "view_count": 24278,
        "like_count": 77
    },
    "1768464429035692425": {
        "content": "Apple announces MM1\n\nMethods, Analysis &amp; Insights from Multimodal LLM Pre-training\n\nIn this work, we discuss building performant Multimodal Large Language Models (MLLMs). In particular, we study the importance of various architecture components and data choices. Through https://t.co/Cw1ITKJ3OT",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 17,
        "retweet_count": 183,
        "view_count": 272428,
        "like_count": 973
    },
    "1768446729710371115": {
        "content": "Apple presents MM1, a family of multimodal LLMs up to 30B parameters, that are SoTA in pre-training metrics and perform competitively after fine-tuning \n\nhttps://t.co/uoPLW2479h https://t.co/dnNr4HriD8",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 15,
        "retweet_count": 188,
        "view_count": 212039,
        "like_count": 968
    },
    "1768222846608613422": {
        "content": "This is a truly incredible speech by the great Tony Benn that I\u2019d recommend everyone watch.\n\n\ud83d\udc47\n\n https://t.co/8lTmmrqoAj",
        "name": "Tiberius",
        "photo": "https://pbs.twimg.com/profile_images/1733232340229320704/yFXiNmTA_normal.jpg",
        "reply_count": 549,
        "retweet_count": 7302,
        "view_count": 1646115,
        "like_count": 17703
    },
    "1768090059691929672": {
        "content": "Mila presents Simple and Scalable Strategies to Continually Pre-train Large Language Models\n\nShows efficient updates to LLMs using simple strategies, achieving re-training results with less compute\n\nhttps://t.co/cN6vqFBqOV https://t.co/P1Plt7jKLk",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 5,
        "retweet_count": 77,
        "view_count": 27887,
        "like_count": 347
    },
    "1768350046507143619": {
        "content": "You have 168 hours per week.\nFor most, sleep takes 56 of those.\nA full time job is anyone 40.\nFood, grooming, exercise add another 18 if you\u2019re reasonably efficient.\nMisc obligatory bullshit paperwork like taxes or errands, another 7.\nThis leaves you with 47 hours!",
        "name": "Emmett Shear",
        "photo": "https://pbs.twimg.com/profile_images/1638646637710147584/odiqsmwE_normal.jpg",
        "reply_count": 79,
        "retweet_count": 87,
        "view_count": 204881,
        "like_count": 1590
    },
    "1767975071887536355": {
        "content": "Great work from @soniajoseph_!\n\nFrontier models are multimodal, and it's increasingly clear that mechanistic interpretability can't only study language models. Good tooling is unglamorous to work on, but essential for good research. I'm excited to see what work Prisma enables!",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 8,
        "view_count": 7132,
        "like_count": 68
    },
    "1767963316943728779": {
        "content": "I'm excited to release Prisma, a mechanistic interpretability library for multimodal models like CLIP and ViTs. Incubated at @tyrell_turing's lab &amp; in collab with @NeelNanda5.\n\nRecent mech interp work has focused on language, but many techniques transfer. Behold, the dogit lens: https://t.co/gs2wCFIGAa",
        "name": "Sonia Joseph",
        "photo": "https://pbs.twimg.com/profile_images/1582107921755779072/1J1lLCFf_normal.jpg",
        "reply_count": 13,
        "retweet_count": 73,
        "view_count": 44322,
        "like_count": 392
    },
    "1768002009221701947": {
        "content": "They've done it again.\n\nMade me look fat and old with a big nose.\n\nLegal advice being sought. https://t.co/P5w4zHJP1E",
        "name": "Lee Anderson MP",
        "photo": "https://pbs.twimg.com/profile_images/1599753243118256132/7xk5iN21_normal.jpg",
        "reply_count": 2731,
        "retweet_count": 380,
        "view_count": 1175147,
        "like_count": 4256
    },
    "1767963562960630113": {
        "content": "New paper and library! \ud83e\udee1\n\nIntervening on internal states has emerged as a fundamental operation for analyzing and improving neural models.\n\nWe release pyvene, a library for performing interventions and sharing intervened models.\n\n\ud83d\udc49Code & Paper: https://t.co/VkU4sclMZZ",
        "name": "Zhengxuan Wu",
        "photo": "https://pbs.twimg.com/profile_images/1641146001938616321/Th2IWKmh_normal.jpg",
        "reply_count": 3,
        "retweet_count": 25,
        "view_count": 28589,
        "like_count": 152
    },
    "1767913661253984474": {
        "content": "With OpenAI, Figure 01 can now have full conversations with people\n\n-OpenAI models provide high-level visual and language intelligence\n-Figure neural networks deliver fast, low-level, dexterous robot actions\n\nEverything in this video is a neural network: https://t.co/OJzMjCv443",
        "name": "Figure",
        "photo": "https://pbs.twimg.com/profile_images/1762178234865930240/8SRNFl6R_normal.jpg",
        "reply_count": 1099,
        "retweet_count": 4753,
        "view_count": 4797571,
        "like_count": 17032
    },
    "1767616494752731633": {
        "content": "+1 to the best AI newsletter atm that I enjoy skimming, great/ambitious work by @swyx &amp; friends:\n\nhttps://t.co/60ial0bf3N\n\n\"Skimming\" because they are very long. Not sure how it is built, sounds like there is a lot of LLM aid going on indexing ~356 Twitters, ~21 Discords, etc.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 77,
        "retweet_count": 218,
        "view_count": 373422,
        "like_count": 2053
    },
    "1764853209498034537": {
        "content": "reading \"AI News\" (previously Smol Talk) is probably the highest-leverage 45 mins I spend everyday on catching up with what's going on in AI.\n\nSo much alpha, organized hierarchically; an exceptionally well curated (and summarized) daily newslettter.\n\nProbably only suited for people deep into AI everyday, but for that audience, it nails it IMO.\nhttps://t.co/L6nACTh8A7",
        "name": "Soumith Chintala",
        "photo": "https://pbs.twimg.com/profile_images/959995586689691648/DAFep10r_normal.jpg",
        "reply_count": 14,
        "retweet_count": 69,
        "view_count": 482666,
        "like_count": 793
    },
    "1767550900288069984": {
        "content": "Anyone arguing that AI isn't tackling major challenges isn't paying attention. Everyone knows batteries are integral to the clean energy transition but aren't where we need them to be. Now we're seeing serious strides in new battery materials thanks to AI, which narrowed 32 million materials to 23 promising options. Concrete advances in not just fundamental science but real problems are already underway https://t.co/wK6WQdeDxA",
        "name": "Mustafa Suleyman",
        "photo": "https://pbs.twimg.com/profile_images/1653542890373795840/87QVCgwx_normal.jpg",
        "reply_count": 24,
        "retweet_count": 93,
        "view_count": 81081,
        "like_count": 483
    },
    "1767381134525292810": {
        "content": "The final layer of an LLM up-projects from hidden dim \u2014&gt; vocab size. The logprobs are thus low rank, and with some clever API queries, you can recover an LLM\u2019s hidden dimension (or even the exact layer\u2019s weights).\n\nOur new paper is out, a collaboration between lot of friends!",
        "name": "Eric Wallace",
        "photo": "https://pbs.twimg.com/profile_images/1705599599761887232/YN3sqrvw_normal.jpg",
        "reply_count": 3,
        "retweet_count": 25,
        "view_count": 26390,
        "like_count": 207
    },
    "1767375818391539753": {
        "content": "Google presents: \n\nStealing Part of a Production Language Model\n\n- Extracts the projection matrix of OpenAI\u2019s ada and babbage LMs for <$20\n- Confirms that their hidden dim is 1024 and 2048, respectively\n- Also recovers the exact hidden dim size of gpt-3.5-turbo\n\nhttps://t.co/YU85tjnSBu",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 17,
        "retweet_count": 151,
        "view_count": 236140,
        "like_count": 975
    },
    "1767128405944791395": {
        "content": "From today, care workers entering the UK on Health and Care Worker visas can no longer bring dependants. \n\nThis is part of our plan to deliver the biggest ever cut in migration. https://t.co/lrP9Xp8NUa",
        "name": "Home Office",
        "photo": "https://pbs.twimg.com/profile_images/1724029369935425536/lPv67xGX_normal.jpg",
        "reply_count": 3369,
        "retweet_count": 823,
        "view_count": 3307695,
        "like_count": 2572
    },
    "1767327882978660513": {
        "content": "\ud83d\ude80New paper!\ud83d\ude80\n\nChain-of-thought (CoT) prompting can give misleading explanations of an LLM's reasoning, due to the influence of unverbalized biases. We introduce a simple unsupervised consistency training method that dramatically reduces this, even on held-out forms of bias.\n\ud83e\uddf5 https://t.co/LIxyqPLg9v",
        "name": "Miles Turpin",
        "photo": "https://pbs.twimg.com/profile_images/1465462208901566468/h6XBKbBv_normal.jpg",
        "reply_count": 5,
        "retweet_count": 55,
        "view_count": 48808,
        "like_count": 261
    },
    "1767187271122342164": {
        "content": "Does this photo from last year, look like the recent photo Billy posted of his wife and kids yesterday for Mother\u2019s Day\ud83e\udd28\ud83e\udd13\ud83d\ude33? https://t.co/BJ7vKMEbr7",
        "name": "Sparrow68\u2026Brazen Hussy on Purpose",
        "photo": "https://pbs.twimg.com/profile_images/1121569381828501509/5_SGSUwz_normal.jpg",
        "reply_count": 113,
        "retweet_count": 160,
        "view_count": 199029,
        "like_count": 814
    },
    "1767108624038449405": {
        "content": "This week, @xAI will open source Grok",
        "name": "Elon Musk",
        "photo": "https://pbs.twimg.com/profile_images/1780044485541699584/p78MCn3B_normal.jpg",
        "reply_count": 9020,
        "retweet_count": 11344,
        "view_count": 29958213,
        "like_count": 95843
    },
    "1766956376637460705": {
        "content": "I suspect this was not the headline Kensington Palace was hoping to get from the normally supportive @Telegraph on Monday morning:\n\u201cPhoto from Palace was doctored, say agencies\u201d. https://t.co/W7JxIgdlQA",
        "name": "Chris Ship",
        "photo": "https://pbs.twimg.com/profile_images/1371498839945936908/Sj3nRAd2_normal.jpg",
        "reply_count": 413,
        "retweet_count": 888,
        "view_count": 744964,
        "like_count": 4898
    },
    "1766956945154412802": {
        "content": "PR disaster so far. Royal Family wanted to lessen the speculation, of which most people would have actually been unaware. They\u2019ve amplified it. Kensington Palace is going to have to explain what\u2019s happened and quickly to avoid the story getting further out of control.",
        "name": "Lewis Goodall",
        "photo": "https://pbs.twimg.com/profile_images/1572255111056965633/mGJlUY1M_normal.jpg",
        "reply_count": 195,
        "retweet_count": 607,
        "view_count": 861089,
        "like_count": 4941
    },
    "1766944328847364201": {
        "content": "No comment from Kensington Palace tonight after at least 3 international pictures agencies refuse to distribute this morning\u2019s photo of Kate and her children.  Some of them (@AP ) have claimed \u201cthe source [the palace] has manipulated the image\u201d. https://t.co/ppOwDtPr9P",
        "name": "Chris Ship",
        "photo": "https://pbs.twimg.com/profile_images/1371498839945936908/Sj3nRAd2_normal.jpg",
        "reply_count": 1699,
        "retweet_count": 6169,
        "view_count": 42453783,
        "like_count": 33700
    },
    "1766565675630301198": {
        "content": "Some thoughts from Adam and I on qualitative research, especially in the context of interpretability (inspired by conversations with many others).",
        "name": "Chris Olah",
        "photo": "https://pbs.twimg.com/profile_images/1422800200146378753/TdaSuRIB_normal.jpg",
        "reply_count": 2,
        "retweet_count": 6,
        "view_count": 22040,
        "like_count": 93
    },
    "1766231617557729655": {
        "content": "Reflections on Qualitative Research:\nhttps://t.co/f7qlnV1img\n\n[h/t to @ch402 for originating &amp; driving this!]",
        "name": "Adam Jermyn",
        "photo": "https://pbs.twimg.com/profile_images/1046124191068577797/tqQ72nrh_normal.jpg",
        "reply_count": 4,
        "retweet_count": 23,
        "view_count": 60907,
        "like_count": 143
    },
    "1766447236299297010": {
        "content": "Really great post on how to think about doing mech interp research, and how it requires a very different mindset to normal ML",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 0,
        "retweet_count": 5,
        "view_count": 10184,
        "like_count": 76
    },
    "1766108386423132459": {
        "content": "BREAKING: Palestine Action spray and slash a historic painting of Lord Balfour in Trinity College, University of Cambridge.\n\nWritten in 1917, Balfour\u2019s declaration began the ethnic cleansing of Palestine by promising the land away \u2014 which the British never had the right to do. https://t.co/CGmh8GadQG",
        "name": "Palestine Action",
        "photo": "https://pbs.twimg.com/profile_images/1676684496031084547/AlqvMVFX_normal.jpg",
        "reply_count": 7843,
        "retweet_count": 16633,
        "view_count": 24211846,
        "like_count": 63808
    },
    "1765515566553629009": {
        "content": "Cool post from my MATS scholars\n@Connor_Kissane\n&amp; Rob Krzyzanowski: We Inspected Every Head in GPT-2 Small With SAEs So You Don't Have To!\n\nThe features in an attn output most aligned with a head let's you get the head's \"vibe\". Rob, the madman, looked through all 144 heads! https://t.co/E5IDmPSzJ1",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 14,
        "view_count": 9401,
        "like_count": 93
    },
    "1765537428931006715": {
        "content": "Happy to have supervised the continuing effort pushing Attention SAEs to the limit!",
        "name": "Arthur Conmy",
        "photo": "https://pbs.twimg.com/profile_images/1422332102486409218/dOEbifRB_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 843,
        "like_count": 12
    },
    "1765424847705047247": {
        "content": "Nice read on the rarely-discussed-in-the-open difficulties of training LLMs. Mature companies have dedicated teams maintaining the clusters. At scale, clusters leave the realm of engineering and become a lot more biological, hence e.g. teams dedicated to \"hardware health\".\n\nIt can be a frustrating daily life experience of training large models to \"babysit\" the training run. You're there carefully monitoring the vital signs of your run: loss spikes, numerical issues, throughput, gradient norms, policy entropy, etc. Every time the run degrades or flatlines (can happen often), you quickly look for the stack trace to see what's up. You have to do this fast or 10,000 GPUs could be idling. Often, it is a new, exotic, scary-looking error you've never seen before so you summon help to see if anyone can see what's up. The worst ones like to occur at 4am. Often no one can, so you just ban some nodes that look a bit sketchy and try to restart the run. Sometimes the run goes down just because you have not earned the favors of your gods that day, so you put a while True: loop around your launch command. The underlying issues can be highly diverse, from some GPUs just getting a bit too hot and suddenly doing incorrect multiplication once in a while, to some router going down and decreasing the networked file system I/O, to someone in the datacenter physically disconnecting a wire as part of an un-communicated maintenance. Sometimes you'll never know.\n\nAnother necessary related citation here is the famous OPT-175B logbook and I'd hope more like it can see the light of day in the future. (see chronicles/OPT175B_Logbook.pdf in the git repo)\nhttps://t.co/6xOHVtj0Gf\n\nTLDR LLM training runs are significant stress-tests of an overall fault tolerance of a large computing system acting as a biological entity. And when you're shopping around for your compute, think about a lot more than just FLOPs and $. Think about the whole service from hardware to software across storage, networking, and compute. And think about whether the team maintaining it looks like The Avengers and whether you could become best friends.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 109,
        "retweet_count": 523,
        "view_count": 641210,
        "like_count": 4303
    },
    "1765105066263052718": {
        "content": "Long overdue but here's a new blogpost on training LLMs in the wilderness from the ground up \ud83d\ude04\ud83e\uddd0\n\nIn this blog post, I discuss:\n1. Experiences in procuring compute & variance in different compute providers. Our biggest finding/surprise is that variance is super high and it's almost a lottery to what hardware one could get! (!?!) \ud83d\ude31\n2. Discussing \"wild life\" infrastructure/code and transitioning to what I used to at Google \ud83e\udd23\n3. New mindset when training models. \ud83d\ude36\u200d\ud83c\udf2b\ufe0f\n\nWriting can be quite therapeutic. I should write more but for now, link below: \ud83d\udc47",
        "name": "Yi Tay",
        "photo": "https://pbs.twimg.com/profile_images/1676934464159756291/1lM4joGC_normal.jpg",
        "reply_count": 44,
        "retweet_count": 258,
        "view_count": 896896,
        "like_count": 1764
    },
    "1765201089366773913": {
        "content": "We are dedicated to the OpenAI mission and have pursued it every step of the way.\n\nWe\u2019re sharing some facts about our relationship with Elon, and we intend to move to dismiss all of his claims.\n\nhttps://t.co/npC4P5pJE7",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 1545,
        "retweet_count": 2023,
        "view_count": 3529493,
        "like_count": 13225
    },
    "1764951275526111401": {
        "content": "Watch this space.\n\nEarlier than expected Claude 3 release may of changed risk / reward appetite.",
        "name": "Jimmy Apples \ud83c\udf4e/acc",
        "photo": "https://pbs.twimg.com/profile_images/1718784022506319872/7v6f0CqZ_normal.jpg",
        "reply_count": 1,
        "retweet_count": 38,
        "view_count": 40135,
        "like_count": 492
    },
    "1764828113202978982": {
        "content": "Anthropic owes OpenAI an apology. \n\nBurying this critical detail in a footnote was quite misleading. https://t.co/e3gJCjADN5",
        "name": "Gary Marcus",
        "photo": "https://pbs.twimg.com/profile_images/1749047536361586688/N1p9EZpc_normal.jpg",
        "reply_count": 5,
        "retweet_count": 9,
        "view_count": 14520,
        "like_count": 52
    },
    "1764824483137819097": {
        "content": "@GaryMarcus Yep!\n\nThis was the footnote lol\nhttps://t.co/6IkaWovYGy",
        "name": "Tolga Bilge",
        "photo": "https://pbs.twimg.com/profile_images/1483240044722855937/YOQD3SIi_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 15946,
        "like_count": 2
    },
    "1758149033473020081": {
        "content": "Kalamang Translation\n\nOne of the most exciting examples in the report involves translation of Kalamang.  Kalamang is a language spoken by fewer than 200 speakers in western New Guinea in the east of Indonesian Papua (https://t.co/2qAvCoQTLR).  Kalamang has almost no online presence.  Machine Translation from One Book (MTOB: https://t.co/dUjJxTZ6Cr) is a recently introduced benchmark evaluating the ability of a learning system to learn to translate Kalamang from just a single book.\n\nEline Visser (https://t.co/382qNz6vx0) wrote a 573 page book \u201cA Grammar of Kalamang\u201d (https://t.co/xXRW0vKwJc). \n Thank you, Eline!  The text of this book is used in the MTOB benchmark.  With this book and a simple bilingual wordlist (dictionary) provided in context, Gemini 1.5 Pro can learn to translate from English to/from Kalamang.  Without the Kalamang materials in context, the 1.5 Pro model produces almost random translations.  However, with the materials in the context window, Gemini Pro 1.5 is able to use in-context learning about Kalamang, and we find that the quality of its translations is comparable to that of a person who has learned from the same materials.  With a ChrF of 58.3 for English->Kalamang translation, Gemini Pro 1.5 improves substantially over the best model score of 45.8 ChrF and also slightly exceeds the human baseline of 57.0 ChrF reported in the MTOB paper (https://t.co/dUjJxTZ6Cr).\n\nThe possibilities for significantly improving translation for very low resource languages are quite exciting!",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 13,
        "retweet_count": 123,
        "view_count": 370481,
        "like_count": 726
    },
    "1764761910128603215": {
        "content": "Finally, the exciting news!!!!!\nOur dataset is now officially open to all! \ud83c\udf89\ud83d\udcca It's publicly available under the permissive MIT license, inviting everyone to explore, build, and innovate.\nhttps://t.co/PPLOhbsnt4",
        "name": "arindam mitra",
        "photo": "https://pbs.twimg.com/profile_images/1670138207298797568/_tIJtbD6_normal.jpg",
        "reply_count": 6,
        "retweet_count": 32,
        "view_count": 34110,
        "like_count": 176
    },
    "1727033002234909060": {
        "content": "\ud83e\uddf5Announcing GPQA, a graduate-level \u201cGoogle-proof\u201d Q&amp;A benchmark designed for scalable oversight! w/ @_julianmichael_, @sleepinyourhat\n\nGPQA is a dataset of *really hard* questions that PhDs with full access to Google can\u2019t answer.\n\nPaper: https://t.co/hb4u4xX1uY https://t.co/YCdpP4yPBu",
        "name": "david rein",
        "photo": "https://pbs.twimg.com/profile_images/1375548507621257220/OOUh4_Yz_normal.jpg",
        "reply_count": 23,
        "retweet_count": 139,
        "view_count": 219110,
        "like_count": 878
    },
    "1764681882695032917": {
        "content": "Really glad this @GoogleDeepMind mech interp paper is out!\n\nAtP is a blazing fast approximation for identifying which LLM components matter for a task, so fast it's practical on SoTA models. For the first time, we systematically show its a GOOD approximation, and safe-ish to use",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 9,
        "view_count": 10594,
        "like_count": 152
    },
    "1764657270263046567": {
        "content": "New @GoogleDeepmind mech interp research! \ud83c\udf89https://t.co/eB9aeBL05b\n\nCan we massively speed up the process of finding important nodes in LLMs? Yes! Introducing AtP*, an improved variant of Attribution Patching (AtP) that beats all our baselines on efficiency and effectiveness. \ud83e\uddf5 https://t.co/aThAaGhW41",
        "name": "J\u00e1nos Kram\u00e1r",
        "photo": "https://pbs.twimg.com/profile_images/740260969423765504/ik678VLh_normal.jpg",
        "reply_count": 3,
        "retweet_count": 32,
        "view_count": 29666,
        "like_count": 155
    },
    "1764626690154619039": {
        "content": "Listen to Professor Mike Wooldridge (@wooldridgemike) discussing Professor Geoffrey Hinton's (@geoffreyhinton) journey to being considered the \u2018Godfather of AI\u2019 on the Black Box @guardian.\n\nListen here: https://t.co/wCRMGkBgS0\n\n#compscioxford #OxfordAI",
        "name": "Oxford Comp Sci",
        "photo": "https://pbs.twimg.com/profile_images/1719352776457646081/wLEO0HlT_normal.jpg",
        "reply_count": 2,
        "retweet_count": 4,
        "view_count": 2218,
        "like_count": 10
    },
    "1764653830468428150": {
        "content": "Today, we're announcing Claude 3, our next generation of AI models. \n\nThe three state-of-the-art models\u2014Claude 3 Opus, Claude 3 Sonnet, and Claude 3 Haiku\u2014set new industry benchmarks across reasoning, math, coding, multilingual understanding, and vision. https://t.co/TqDuqNWDoM",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 557,
        "retweet_count": 2216,
        "view_count": 3644629,
        "like_count": 9899
    },
    "1764195092703670411": {
        "content": "Pretty damning commentary from\nthe co-founder and CEO of Cleo, a startup now doing over $100m in revenue:",
        "name": "Ian Hogarth",
        "photo": "https://pbs.twimg.com/profile_images/1728782716731105280/nVAiafUn_normal.jpg",
        "reply_count": 5,
        "retweet_count": 8,
        "view_count": 13525,
        "like_count": 28
    },
    "1764184431605035117": {
        "content": "There\u2019s no way in hell I\u2019d ever list in the UK under current conditions, no tech CEO would. (https://t.co/dKxu6Q9dDz) \n\nWe need radical and wholesale change that addresses the real core issue\u2026 the multiple you\u2019d trade at would be significantly lower in the UK.\n\nForget about tweaking listing rules, there should be one flagship policy:\n\nWorld leading R&D incentives. These have to be meaningful enough to close the multiple gap which would be significant but with the condition it should go back into investing in world class technical talent in the UK.\n\nUntil it feels financial viable, the best high growth companies will continue to list in the US and UK/EU markets slowly die.\n\nStop tweaking @Jeremy_Hunt, it\u2019s time for radical change.",
        "name": "Barney Hussey-Yeo",
        "photo": "https://pbs.twimg.com/profile_images/1732141556851740672/FvXf2Po6_normal.jpg",
        "reply_count": 10,
        "retweet_count": 15,
        "view_count": 35690,
        "like_count": 100
    },
    "1764099077221069164": {
        "content": "\ud83d\udc40 https://t.co/uePtFm4HxY",
        "name": "Smoke-away",
        "photo": "https://pbs.twimg.com/profile_images/1535493957953589249/qFzu0Dqt_normal.jpg",
        "reply_count": 79,
        "retweet_count": 65,
        "view_count": 356233,
        "like_count": 1384
    },
    "1763951505491599463": {
        "content": "It\u2019s pretty amazing you can run mistral 7b on this $80 raspberry pi\u2026!! https://t.co/ZFt3TqE5TV",
        "name": "Adam C.H.",
        "photo": "https://pbs.twimg.com/profile_images/1732027561977217024/KFUD6Hq3_normal.jpg",
        "reply_count": 112,
        "retweet_count": 246,
        "view_count": 734683,
        "like_count": 4135
    },
    "1764015678619603141": {
        "content": "\ud83d\udca5 Breaking: The wife of the MP Andrew Bridgen claims her husband has been radicalised and captured by an anti-vax cult. She claims she and her son were left homeless and living off benefits after the \u201csect\u201d took him over and destroyed their marriage. https://t.co/ABKPi4hvag",
        "name": "caroline wheeler",
        "photo": "https://pbs.twimg.com/profile_images/1365052120500690945/0eL_JaFC_normal.jpg",
        "reply_count": 460,
        "retweet_count": 1011,
        "view_count": 1259562,
        "like_count": 3112
    },
    "1763693362971062287": {
        "content": "I see no problems with this supervised-learning task. https://t.co/8HHjxUyugv",
        "name": "Mel Andrews",
        "photo": "https://pbs.twimg.com/profile_images/1751090595668389888/BaPggxFB_normal.jpg",
        "reply_count": 37,
        "retweet_count": 49,
        "view_count": 86347,
        "like_count": 495
    },
    "1763584352984735769": {
        "content": "Release phi-2-super. Fine tuned over phi-2 and aligned with cDPO. MT-bench of 7.1875, surpassing many larger models. Humaneval score 60.98%, Humaneval-Plus 54.88% https://t.co/IyWSw8Ytcc",
        "name": "anton",
        "photo": "https://pbs.twimg.com/profile_images/1678598826544734210/Z8ZMuiAR_normal.jpg",
        "reply_count": 48,
        "retweet_count": 61,
        "view_count": 115080,
        "like_count": 571
    },
    "1763650339574817061": {
        "content": "BREAKING: Nvidia passes Saudi Aramco to become 3rd-largest company in the world by market cap.",
        "name": "The Spectator Index",
        "photo": "https://pbs.twimg.com/profile_images/1145865652533547008/XBahoZmX_normal.png",
        "reply_count": 168,
        "retweet_count": 2007,
        "view_count": 1949476,
        "like_count": 16384
    },
    "1763608904494174289": {
        "content": "First performant finetune of Gemma in the wild \ud83d\udc40",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 1,
        "retweet_count": 0,
        "view_count": 1330,
        "like_count": 3
    },
    "1763607891343225217": {
        "content": "Zehpyr 7B Gemma released!\ud83d\udd37\ud83d\udd36\nWe are excited to announce a Zephyr Gemma, the best-fine-tuned version of @Google Gemma 7B. Outperforming Google Gemma Instruct on 5 out 6 benchmarks, including MT Bench, AGIEval & GPT4All. \ud83e\udd2f\ud83d\ude80\n\nZephyr Gemma TL;DR;\n\ud83e\udde0\u00a0Fine-tuned Gemma 7B on DEITA and then applied DPO with @argilla_io DPO mix dataset\n\ud83d\udcca\u00a07.81 on MT Bench & 47.47% on AGIEval, GPT4All, TruthfulQA, Big Bench\n\ud83c\udfc6\u00a0Outperforms Google Gemma Instruct by 1.4 on MT Bench and +14% on AGIEval et al. \n\ud83c\udf9a\ufe0f\u00a0Outperforms Zephyr Beta by 0.47 on MT Bench, but is -3.6% on AGIEval et al.\n\ud83d\udd02\u00a0Training Code open-source\n\ud83d\udcb8\u00a0Trained for 105 minutes on 8x H100 (SFT & DPO)\n\ud83d\udc68\u200d\ud83d\udcbb\u00a0Can run locally with Llama.cpp on a Mac\n\ud83d\udeab No System message following, include it in the user turns\n\nZephyr Gemma is not perfect and may appear slightly worse on AGIEval compared to Mistral-based models, it's crucial to conduct further testing in real-world applications to understand what model best meets your needs. \n\nWe believe you can push Gemma further with more optimization and experiments! \ud83d\udd0d\u00a0\ud83e\uddea\ud83d\udcca\n\nBig Kudos to @_lewtun. Working with you on Zephyr Gemma was an incredibly fun journey. \ud83e\udd17",
        "name": "Philipp Schmid",
        "photo": "https://pbs.twimg.com/profile_images/1714444511860887552/8TzsCn3e_normal.jpg",
        "reply_count": 5,
        "retweet_count": 80,
        "view_count": 54289,
        "like_count": 312
    },
    "1763508593209307310": {
        "content": "After @georgegalloway declared his Rochdale win \"for Gaza\", I asked him how much he really cares about Rochdale...\n\nThat didn't go down too well.\n\nWe spoke again for longer a bit later - watch @GranadaReports tonight. https://t.co/BOL35hEFEG",
        "name": "Andrew Misra",
        "photo": "https://pbs.twimg.com/profile_images/1707090654017282048/hY9a3Fuj_normal.jpg",
        "reply_count": 413,
        "retweet_count": 138,
        "view_count": 360529,
        "like_count": 787
    },
    "1763317828948783219": {
        "content": "Geoffrey Hinton says AI models really do possess understanding because they understand in the same way that people do https://t.co/ymrZH1Lub0",
        "name": "Tsarathustra",
        "photo": "https://pbs.twimg.com/profile_images/1690941803200208896/PRpYEDXP_normal.jpg",
        "reply_count": 45,
        "retweet_count": 63,
        "view_count": 32621,
        "like_count": 346
    },
    "1763091200155033879": {
        "content": "great quote from karpathy\n\nmost great organizations require leader(s) with a disproportionate amount of power\n\nwhen this is absent you end up with countless hierarchies of ineffective committees, e.g. many google products lack a Directly Responsible Individual with actual power https://t.co/esiO7X9t94",
        "name": "near",
        "photo": "https://pbs.twimg.com/profile_images/1734512939170988032/a1UiXXYC_normal.jpg",
        "reply_count": 48,
        "retweet_count": 315,
        "view_count": 356991,
        "like_count": 3076
    },
    "1763300075588259985": {
        "content": "We are partnering with @DubCityCouncil to explore how GPT-4 can enhance European tourism for visitors and cities. \n\nThis exploration will include the creation of an AI assistant for bespoke itineraries and a hands-on AI workshop for European city leaders. https://t.co/MYC7HjIDH9 https://t.co/lvaFqsk571",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 310,
        "retweet_count": 301,
        "view_count": 381728,
        "like_count": 1434
    },
    "1763279054244049006": {
        "content": "OpenAI + humanoid robots \u2014 we\u2019re collaborating with @Figure_robot to expand our multimodal models to robotic perception, reasoning, and interaction. https://t.co/YOk24AqYZf",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 610,
        "retweet_count": 1244,
        "view_count": 2074145,
        "like_count": 6793
    },
    "1763202513355022357": {
        "content": "Last month we demonstrated Figure 01 making coffee only using neural networks\n\nThis is a fully learned, end-to-end visuomotor policy mapping onboard images to low level actions at 200hz\n\nNext up: excited to push the boundaries on AI learning with OpenAI\n\nhttps://t.co/DNAZWnaYK3",
        "name": "Figure",
        "photo": "https://pbs.twimg.com/profile_images/1762178234865930240/8SRNFl6R_normal.jpg",
        "reply_count": 65,
        "retweet_count": 257,
        "view_count": 1252412,
        "like_count": 1415
    },
    "1763048317863576062": {
        "content": "\u26a0\ufe0f 5 out of 5 chatbots tested \u2014\u201cOpenAI\u2019s ChatGPT-4, Meta\u2019s Llama 2, Google\u2019s Gemini, Anthropic\u2019s Claude, and Mixtral from the French company Mistral \u2014 failed to varying degrees when asked to respond to basic questions about the democratic process\u201d\n\nhttps://t.co/H6Q6oG2yvk",
        "name": "Gary Marcus",
        "photo": "https://pbs.twimg.com/profile_images/1749047536361586688/N1p9EZpc_normal.jpg",
        "reply_count": 6,
        "retweet_count": 22,
        "view_count": 17110,
        "like_count": 93
    },
    "1763156163233767876": {
        "content": "The Angiolini Inquiry lays bare how Wayne Couzens was able to join the police.\n\nHe abused his position to do the unthinkable. We are so, so sorry.\n\n\ud83d\udcf0 | Read Commissioner Sir Mark Rowley\u2019s response\n\nhttps://t.co/KcmiXR5SgU https://t.co/akeyqEAPVf",
        "name": "Metropolitan Police",
        "photo": "https://pbs.twimg.com/profile_images/1724008131628294144/l1ZbW2ux_normal.jpg",
        "reply_count": 470,
        "retweet_count": 110,
        "view_count": 210598,
        "like_count": 334
    },
    "1762926924739879320": {
        "content": "Confirmed https://t.co/ryBnZJlkNx",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 3,
        "retweet_count": 0,
        "view_count": 4490,
        "like_count": 31
    },
    "1762924699300819238": {
        "content": "surely this is wrong right, right,... RIGHT?\nIt's already done training! lol https://t.co/4YqeKVuu6B",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 5,
        "retweet_count": 0,
        "view_count": 6990,
        "like_count": 18
    },
    "1762886582372327527": {
        "content": "Using our Open Instruct and Tulu 2, we adapt OLMo to acquire different capabilities and safety measures through fine-tuning and Direct Preference Optimization (DPO). The adapted models demonstrate quick improvement on popular reasoning tasks such as MMLU and TruthfulQA, and on safety datasets such as ToxicGen. https://t.co/fD4quSv6wQ",
        "name": "Allen Institute for AI",
        "photo": "https://pbs.twimg.com/profile_images/1191417163648626688/Ylny0kyT_normal.jpg",
        "reply_count": 0,
        "retweet_count": 9,
        "view_count": 21354,
        "like_count": 50
    },
    "1762872471479529522": {
        "content": "Here is my episode with @demishassabis\n\nWe discuss: \n- Why scaling is an artform \n- Adding search &amp; AlphaZero type training atop LLMs \n- Making sure rogue nations can't steal weights \n- The right way to align superhuman AIs &amp; do an intelligence explosion\n\nLinks below. Enjoy! https://t.co/MW3lz06eta",
        "name": "Dwarkesh Patel",
        "photo": "https://pbs.twimg.com/profile_images/1516990544165150721/gkmNmTig_normal.jpg",
        "reply_count": 18,
        "retweet_count": 77,
        "view_count": 85257,
        "like_count": 578
    },
    "1762849225425952768": {
        "content": "\ud83e\udd16 Incredibly cool Google DeepMind paper: Concordia is a library for building agents that leverage language models to simulate human behavior with a high degree of detail and realism. The agents can reason, plan, and communicate in natural language, interacting with each other in grounded physical, social, or digital environments. https://t.co/gw6UhAsgPM\n\nSo many cool use cases (with obvious limitations): studying complex social phenomena, generating synthetic data, evaluating AI systems etc. Some excerpts I really liked below:",
        "name": "S\u00e9b Krier",
        "photo": "https://pbs.twimg.com/profile_images/1638328586351386626/K82oZLUM_normal.jpg",
        "reply_count": 13,
        "retweet_count": 101,
        "view_count": 91999,
        "like_count": 530
    },
    "1762712860403384346": {
        "content": "New paper on whether LLMs think in English (Wendler et al).\nSuppose Llama must translate from German to Chinese. Does it first translate German to English internally? https://t.co/ve0v8ezRt4",
        "name": "Owain Evans",
        "photo": "https://pbs.twimg.com/profile_images/1248907970374746112/f-dlZd6-_normal.jpg",
        "reply_count": 14,
        "retweet_count": 97,
        "view_count": 64575,
        "like_count": 556
    },
    "1762568122857353604": {
        "content": "if anyone want \u00a39.50 off for tesco then here it is unlimited\u2026 https://t.co/ZlRNMyI1Rn",
        "name": "george",
        "photo": "https://pbs.twimg.com/profile_images/1565722268738748416/4FWACDQs_normal.jpg",
        "reply_count": 113,
        "retweet_count": 291,
        "view_count": 2094257,
        "like_count": 5503
    },
    "1762729757454618720": {
        "content": "Microsoft presents The Era of 1-bit LLMs\n\nAll Large Language Models are in 1.58 Bits\n\nRecent research, such as BitNet, is paving the way for a new era of 1-bit Large Language Models (LLMs). In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single parameter (or weight) of the LLM is ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16) Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being significantly more cost-effective in terms of latency, memory, throughput, and energy consumption. More profoundly, the 1.58-bit LLM defines a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective. Furthermore, it enables a new computation paradigm and opens the door for designing specific hardware optimized for 1-bit LLMs.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 53,
        "retweet_count": 627,
        "view_count": 421438,
        "like_count": 2522
    },
    "1762621031121145996": {
        "content": "Setting up my shiny new fully maxed out Space Black MacBook Pro M3 Max 128GB 16-inch (upgrading from an M1 Air). I always like to set up the new one with a clean slate, from scratch - this time I will not allow my dev configuration to get out of hand. Then we'll talk to it.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 374,
        "retweet_count": 146,
        "view_count": 583348,
        "like_count": 5908
    },
    "1762538430276460801": {
        "content": "What would @demishassabis do if he thought a model he was training was capable of an intelligence explosion?\n\nFull episode tomorrow. https://t.co/VuCb3GxI5X",
        "name": "Dwarkesh Patel",
        "photo": "https://pbs.twimg.com/profile_images/1516990544165150721/gkmNmTig_normal.jpg",
        "reply_count": 10,
        "retweet_count": 10,
        "view_count": 25024,
        "like_count": 124
    },
    "1762215502926237779": {
        "content": "New paper! \ud83e\udee1\n\nLM interpretability has made progress in finding feature representations using many methods, but we don\u2019t know which ones are generally performant or reliable.\n\nWe (@jurafsky @ChrisGPotts) introduce CausalGym, a benchmark of 29 linguistic tasks for interp!\n\n(1/n) https://t.co/yCuJwfsD3L",
        "name": "Aryaman Arora",
        "photo": "https://pbs.twimg.com/profile_images/1735523039515926528/FghjGV3n_normal.jpg",
        "reply_count": 6,
        "retweet_count": 45,
        "view_count": 32035,
        "like_count": 284
    },
    "1762225275511951666": {
        "content": "A couple new admits have been asking what researching at Stanford is like, here\u2019s a thread of cool projects that my awesome cohort / lab mates did in their first 0.5 year here at @stanfordnlp \ud83e\uddf5",
        "name": "CLS",
        "photo": "https://pbs.twimg.com/profile_images/1356609929243734018/FDzdwcv6_normal.jpg",
        "reply_count": 1,
        "retweet_count": 8,
        "view_count": 33590,
        "like_count": 113
    },
    "1762225276682203189": {
        "content": "mech interp benchmark from @aryaman2020: https://t.co/i4LqFFzdys",
        "name": "CLS",
        "photo": "https://pbs.twimg.com/profile_images/1356609929243734018/FDzdwcv6_normal.jpg",
        "reply_count": 2,
        "retweet_count": 1,
        "view_count": 3065,
        "like_count": 14
    },
    "1762100361475625050": {
        "content": "Something seem super fishy\n\n@KrutrimAI says it was created by OpenAI https://t.co/m8NKyuIrcw",
        "name": "Raghav Arora",
        "photo": "https://pbs.twimg.com/profile_images/1485516771071492097/pKe7m_Bd_normal.jpg",
        "reply_count": 229,
        "retweet_count": 277,
        "view_count": 627849,
        "like_count": 2386
    },
    "1762020053611073839": {
        "content": "As promised, starting the @Krutrim AI public beta roll out today. Use it here: https://t.co/9XCqSlLOF9\n\nThis is a start for us and our first generation product. Lots more to come and this will also improve significantly as we build on this base. Do give us your feedback.\n\nWhile some hallucinations will be there but much lower for Indian contexts than other global platforms. And we will be working overtime to find and fix!\n\nWe\u2019ve rooted Krutrim strongly into Indian values and data with over 10+ Indian languages and ready to assist in English, Hindi, Tamil, Bengali, Marathi, Kannada, Gujarati and even Hinglish!\n\nKrutrim marks the dawn of a new era in the AI computing stack for our nation. We will aim to innovate alongside the world and define future paradigms.",
        "name": "Bhavish Aggarwal",
        "photo": "https://pbs.twimg.com/profile_images/1133256267340713984/UaxcE0fi_normal.jpg",
        "reply_count": 527,
        "retweet_count": 376,
        "view_count": 986082,
        "like_count": 4214
    },
    "1762143055652782502": {
        "content": ".@demishassabis on the scaling hypothesis:\n\n\u201cI look at the large models today, and I think they are almost unreasonably effective for what they are.\n\n5+ years ago I would\u2019ve said we needed an additional algorithmic breakthrough.\u201d\n\nFull episode out Wednesday. https://t.co/Ym55wB3ZNq",
        "name": "Dwarkesh Patel",
        "photo": "https://pbs.twimg.com/profile_images/1516990544165150721/gkmNmTig_normal.jpg",
        "reply_count": 29,
        "retweet_count": 72,
        "view_count": 63628,
        "like_count": 766
    },
    "1762128616849072171": {
        "content": "Today, we are releasing Mistral Large, our latest model. Mistral Large is vastly superior to Mistral Medium, handles 32k tokens of context, and is natively fluent in English, French, Spanish, German, and Italian.\n\nWe have also updated Mistral Small on our API to a model that is significantly better (and faster) than Mixtral 8x7B.\n\nLastly, we are introducing Le Chat (https://t.co/CCMpILcmFy), a chat interface (currently in beta) on top of our models.",
        "name": "Guillaume Lample",
        "photo": "https://pbs.twimg.com/profile_images/1204529916026458112/_kcTUp8s_normal.jpg",
        "reply_count": 178,
        "retweet_count": 832,
        "view_count": 843064,
        "like_count": 5371
    },
    "1761719827041853549": {
        "content": "Demis Hassabis admits that Google has some secret sauce in how Gemini is able to process 1-10m token context windows.  The extreme context length in Gemini 1.5 Pro \"can't\" be achieved \"without some new Innovations\". This is an astonishing development that seems to hint at machines that can form their own abstractions!",
        "name": "Carlos E. Perez",
        "photo": "https://pbs.twimg.com/profile_images/1740015728105832448/fRPNehGE_normal.png",
        "reply_count": 15,
        "retweet_count": 76,
        "view_count": 113125,
        "like_count": 375
    },
    "1761238627038703829": {
        "content": "Many people were arguing that RAG will still be necessary in most cases even after 1 million+ long context windows because of the cost. But in a NYT interview today, Demis said they're working on caching  reference materials to make subsequent processing much cheaper. https://t.co/7nf9WfKsMO",
        "name": "MachDiamonds",
        "photo": "https://pbs.twimg.com/profile_images/1680373560651464705/o77WtqTV_normal.jpg",
        "reply_count": 4,
        "retweet_count": 18,
        "view_count": 127736,
        "like_count": 116
    },
    "1761469844359147774": {
        "content": "We are excited to announce the CASMI AI Incidents and Best Practices Paper Award.\n\nThe CASMI AI Incidents and Best Practices Paper Award recognizes outstanding contributions in analyzing AI incidents and showcasing best practices for preventing or mitigating their recurrence. This award acknowledges research that deepens our understanding of the factors related to AI incidents, identifies open problems in AI system deployment, and offers valuable insights and guidelines for producing and deploying systems that prioritize safety and mitigate potential harms.\n\n\ud83d\udcbb: https://t.co/EYhVktdhms",
        "name": "AAAI",
        "photo": "https://pbs.twimg.com/profile_images/1582705849109209089/R9O-0nbO_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 1859,
        "like_count": 4
    },
    "1761480112560812285": {
        "content": "This MIT student surfs the entire internet using his mind, silently Googling questions and receiving answers through skull vibrations https://t.co/b0TRJ09Ubr",
        "name": "Historic Vids",
        "photo": "https://pbs.twimg.com/profile_images/1648334723725361152/ev7V1230_normal.jpg",
        "reply_count": 850,
        "retweet_count": 5416,
        "view_count": 14820117,
        "like_count": 43759
    },
    "1761087686365036833": {
        "content": "Pod drop! Enjoy! https://t.co/1vIkityBXM",
        "name": "Aravind Srinivas",
        "photo": "https://pbs.twimg.com/profile_images/1781508360069894144/1fReqIat_normal.jpg",
        "reply_count": 21,
        "retweet_count": 10,
        "view_count": 31470,
        "like_count": 433
    },
    "1755307308085555276": {
        "content": "This isn\u2019t just funny, it\u2019s the truth. https://t.co/DNBmh0pQAr",
        "name": "The Ricky Gervais Clips",
        "photo": "https://pbs.twimg.com/profile_images/1727397034011828224/lItrceUl_normal.jpg",
        "reply_count": 354,
        "retweet_count": 2948,
        "view_count": 2719072,
        "like_count": 17417
    },
    "1761103680739152034": {
        "content": "Sorry, what?\n\nI've been sent a letter from @ThamesVP that I have \"an allegation of malicious communications\" against me - because I posted homophobic messages sent to me from a former fellow Oxford student and a now Tory councillor?\n\nIs this some sort of dark joke? https://t.co/G1ak9nTrJ2",
        "name": "Owen Jones",
        "photo": "https://pbs.twimg.com/profile_images/1579546696236793870/ZML8GjGs_normal.jpg",
        "reply_count": 1014,
        "retweet_count": 2185,
        "view_count": 1966222,
        "like_count": 13089
    },
    "1750147189932782025": {
        "content": "Simon Clarke was in the year below me at university, and his crew were the first Tories I'd then met.\n\nAnd all I'm saying is it had quite the lasting impact on my politics!\n\nHis best friend was @CllrCarlJackson, who sent me these messages after we graduated.\n\nSuper cool people! https://t.co/dgoRJezopp",
        "name": "Owen Jones",
        "photo": "https://pbs.twimg.com/profile_images/1579546696236793870/ZML8GjGs_normal.jpg",
        "reply_count": 1102,
        "retweet_count": 3014,
        "view_count": 3671772,
        "like_count": 15939
    },
    "1761124883101032752": {
        "content": "\ud83d\udd25 Just got access to Gemini 1.5 with the incredible 1M tokens and video capabilities (thanks @asoroken @googleaistudio ) and fed it this viral video of mine. \nit's 5 minutes which converted into 80K tokens and the extraction + summarization of the video is bonkers! \n\nFirst I provided the actual video with me speaking and narrating myself and this is the results I got! Quite quite impressive! \n\nThen I decided to make it harder on Gemini, and provided the same exact video without any sound to make sure it's not cheating off my narration and it did in fact do less great, but still, impressively impressively so! \n\nSpecifically it knows that I'm inside the Apple Vision Pro which was not provided in prompts nor in narration, not even sure how TBH, maybe settings show this? \ud83e\udd14",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 10,
        "retweet_count": 4,
        "view_count": 8906,
        "like_count": 50
    },
    "1753649516341817805": {
        "content": "? Who said Vision Pro is not a gaming device? \n\nThis is my set up to play PalWorld  via Steam Link with a Bluetooth controller on the huge vision, pro screen on top of my kitchen sink?! https://t.co/LsmvxkyUcy",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 60,
        "retweet_count": 52,
        "view_count": 397856,
        "like_count": 454
    },
    "1760939023798050930": {
        "content": "Delighted to share our team's latest paper, \"Towards Generalist Biomedical AI,\" published in @NEJM_AI!    Congratulations to all involved! https://t.co/V2XOmbzcI9",
        "name": "Amy C. Chou",
        "photo": "https://pbs.twimg.com/profile_images/1248105921345028102/zRr4g5Ej_normal.jpg",
        "reply_count": 1,
        "retweet_count": 40,
        "view_count": 13162,
        "like_count": 102
    },
    "1760656767237656820": {
        "content": "Announcing Stable Diffusion 3, our most capable text-to-image model, utilizing a diffusion transformer architecture for greatly improved performance in multi-subject prompts, image quality, and spelling abilities.\n\nToday, we are opening the waitlist for early preview. This phase is crucial for gathering insights to improve its performance and safety ahead of open release. \n\nYou can sign up to join the waitlist and learn more here: https://t.co/lX8z1UTc8s #stablediffusion3\n\nPrompt: Epic anime artwork of a wizard atop a mountain at night casting a cosmic spell into the dark sky that says \"Stable Diffusion 3\" made out of colorful energy",
        "name": "Stability AI",
        "photo": "https://pbs.twimg.com/profile_images/1641030998518374402/GiZSATqD_normal.jpg",
        "reply_count": 267,
        "retweet_count": 1346,
        "view_count": 1392368,
        "like_count": 5268
    },
    "1760350892317098371": {
        "content": "Seeing as I published my Tokenizer video yesterday, I thought it could be fun to take a deepdive into the Gemma tokenizer. \n\nFirst, the Gemma technical report [pdf]: \nhttps://t.co/iPVo3iLXQC \nsays: \"We use a subset of the SentencePiece tokenizer (Kudo and Richardson, 2018) of Gemini for com- patibility. It splits digits, does not remove extra whitespace, and relies on byte-level encodings for unknown tokens, following the techniques used for both (Chowdhery et al., 2022) and (Gemini Team, 2023). The vocabulary size is 256k tokens.\"\n\nThe tokenizer.model file is with this code release:\nhttps://t.co/SwcVU2nkkS\n\nI decoded this model protobuf in Python and here is the diff with the Llama 2 tokenizer:\nhttps://t.co/4HoAeYJsZz\n\nNotes:\n- vocab size is quite large: 32K -> 256K\n- add_dummy_prefix is False. Different from Llama but consistent with GPT. This is a bit more consistent w.r.t. \"leave the data alone\", as there is no preprocessing step that adds a space to the encoding text.\n- the model_prefix is the path of the training dataset, which is amusing to look at: \"/cns/mf-d/home/gemini-data-access/tokenizers/final_v1_51GB_run1/bpe_coverage_0_999995_v5/255969\".  Seems to indicate the tokenizer training corpus was ~51GB (?).\n- a lot of user_defined symbols (i.e. special tokens) are present, e.g. \"hardcoding\" a sequence of up to 31 newlines as tokens, and a large number of other unclear tokens. I tried decoding the octal representations but it's not clear what's happening here. Also a lot of more special tokens for what look like html elements, e.g. <table>, <tr>, <td>, <i>, <b>, etc. Not 100% sure what the unused tokens are for, maybe this is pre-allocated space to make easier future finetunes that try to add more special tokens, as there is no need to resize vocabularies and perform model surgeries (?).\n\nTLDR this is basically the Llama 2 tokenizer, except bigger (32K -> 256K), with a lot more special tokens, and the only functional departure is that add_dummy_prefix is turned off to False. So e.g. tokenizing:\n\n\"hello world\" becomes:\n[17534, 2134]\n['hello', '\u2581world']\n\nwhich otherwise would have been preprocessed to \" hello world\" (note leading space) and tokenized as:\n[25612, 2134]\n['\u2581hello', '\u2581world']\n\ncool",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 184,
        "retweet_count": 474,
        "view_count": 617998,
        "like_count": 4634
    },
    "1760291769252762110": {
        "content": "Introducing Gemma - a family of lightweight, state-of-the-art open models for their class, built from the same research & technology used to create the Gemini models.\n\nBlog post:\nhttps://t.co/JEhKUsLzXI\nTech report:\nhttps://t.co/MCzyojmDV4\n\nThis thread explores some of the performance characteristics of these models.",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 107,
        "retweet_count": 833,
        "view_count": 1268110,
        "like_count": 4491
    },
    "1760336183068950765": {
        "content": "I have new paper \"Simulacra as Conscious Exotica\" on @arxiv about #consciousness in #AI and large language models (#LLMs):\nhttps://t.co/0dlAmnPuNf\nI'm releasing into the world with some trepidation \ud83d\ude2c; it's such a difficult and controversial issue. \ud83e\uddf5 1/n",
        "name": "Murray Shanahan",
        "photo": "https://pbs.twimg.com/profile_images/1189809148348829697/HJPXbo3J_normal.jpg",
        "reply_count": 24,
        "retweet_count": 74,
        "view_count": 58145,
        "like_count": 301
    },
    "1760135690795516057": {
        "content": "confession: not making this list was a primary motivation for @interconnectsai in the last 6 months.\n\nat least at this point I think I've made my point.",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 2,
        "retweet_count": 0,
        "view_count": 3498,
        "like_count": 9
    },
    "1711529144121688158": {
        "content": "Top information sources for AI Engineers, at @aiDotEngineer Summit courtesy of @barrnanas &amp; @AmplifyPartners. https://t.co/r7DulbdmLe",
        "name": "Mike Conover",
        "photo": "https://pbs.twimg.com/profile_images/1612203679763034112/uzV9x4ZN_normal.jpg",
        "reply_count": 16,
        "retweet_count": 43,
        "view_count": 125149,
        "like_count": 340
    },
    "1760288612719968627": {
        "content": "Gemma an open Gemini LLM released by Google! \ud83e\udd2f\u00a0@Google just released Gemma, their first open LLM based on Gemini, which outperforms Mistral AI 7B! \ud83e\udd2f Gemma comes in 2 different sizes, 2B & 7B, and can be commercially used! \ud83d\udd25\n\nTL;DR;\n\n\ud83e\uddee\u00a02B & 7B parameter Instruction and base versions, not multimodal\n\ud83d\udd20\u00a0Trained on 2T tokens (2B) and 6T tokens (7B)\n\ud83d\udcb0Commercial use allowed \u2705\n\ud83e\ude9f\u00a08192 default context window\n\ud83e\udd47\u00a07B scores 64.56 on MMLU and avg. of 63.75 on the Leaderboard\n\u2696\ufe0f\u00a0Used RLHF for instruction model\n\ud83e\udde0\u00a07B\u00a0trained on 16 TPUv5e pods for 23 days\n\ud83d\udcf1\u00a02B can run on Phones\n\ud83e\udd17\u00a0Available on @Hugging Face\n\u2601\u00a01-click deployment to Google Cloud from Hugging Face",
        "name": "Philipp Schmid",
        "photo": "https://pbs.twimg.com/profile_images/1714444511860887552/8TzsCn3e_normal.jpg",
        "reply_count": 18,
        "retweet_count": 255,
        "view_count": 135014,
        "like_count": 1122
    },
    "1760288967352598843": {
        "content": "Introducing Gemma - a family of lightweight, state-of-the-art open models for their class built from the same research & tech used to create the Gemini models.\u00a0\n\nDemonstrating strong performance across benchmarks for language understanding and reasoning, Gemma is available worldwide starting today in two sizes (2B and 7B), supports a wide range of tools and systems, and runs on a developer laptop, workstation or @GoogleCloud.\n\nExcited to see what you\u2019ll create \u2192\u00a0 https://t.co/gQl3TBEYxS https://t.co/XY9YGFOEb2",
        "name": "Sundar Pichai",
        "photo": "https://pbs.twimg.com/profile_images/1710036756731510784/FyfFgM-B_normal.jpg",
        "reply_count": 362,
        "retweet_count": 742,
        "view_count": 948904,
        "like_count": 5303
    },
    "1759981191716057500": {
        "content": "A new model was just dropped by @MistralAI called Mistral-Next, and it went completely under the radar. \n\nCan it beat GPT4? \ud83d\udc51\n\nLet's find out!\n\n\ud83d\udc47\ud83c\udfa5 https://t.co/kFCpLpbFll",
        "name": "MatthewBerman",
        "photo": "https://pbs.twimg.com/profile_images/1656436683926302721/oLW2WgJx_normal.jpg",
        "reply_count": 10,
        "retweet_count": 21,
        "view_count": 12841,
        "like_count": 148
    },
    "1760022429605474550": {
        "content": "\"My benchmark for large language models\"\nhttps://t.co/YZBuwpL0tl\n\nNice post but even more than the 100 tests specifically, the Github code looks excellent - full-featured test evaluation framework, easy to extend with further tests and run against many LLMs.\nhttps://t.co/KnmDD1AJci\n\nE.g. for the 100 current tests on 7 models:\n- GPT-4: 49% passed\n- GPT-3.5: 30% passed\n- Claude 2.1: 31% passed\n- Claude Instant 1.2: 23% passed\n- Mistral Medium: 25% passed\n- Mistral Small 21% passed\n- Gemini Pro: 21% passed\n\nAlso a huge fan of the idea of mining tests from actual use cases in the chat history. I think people would be surprised how odd and artificial many \"standard\" LLM eval benchmarks can be. Now... how can a community collaborate on more of these benchmarks... \ud83e\udd14",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 174,
        "retweet_count": 456,
        "view_count": 388644,
        "like_count": 3953
    },
    "1760054728208294073": {
        "content": "Hugging Face announces Cosmo 1B, a fully open sourced Phi competitor with an open sourced dataset. The dataset references various articles and textbooks as \"seed data\" to generate conversations. Licensed under the Apache 2.0 license.\nhttps://t.co/0zSe0az7J8",
        "name": "mrfakename",
        "photo": "https://pbs.twimg.com/profile_images/1761535542330785792/19N_pCHF_normal.png",
        "reply_count": 1,
        "retweet_count": 42,
        "view_count": 32691,
        "like_count": 244
    },
    "1760023931640291550": {
        "content": "@kgourg also quite enjoyed his recent paper on data poisoning is practical.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 2,
        "retweet_count": 1,
        "view_count": 15397,
        "like_count": 40
    },
    "1760084085232599392": {
        "content": "Announcing the new flagship 7B model in the Hermes series: Hermes 2-Mistral-7B DPO.\n\nA very special thanks to our compute sponsor for this run, @fluidstackio.\n\nhttps://t.co/0V85T8NKLX\n\nThis model was DPO'd from OpenHermes 2.5 and improved on all benchmarks tested - AGIEval, BigBench Reasoning, GPT4All, and TruthfulQA.\n\nThe Hermes project is led by @Teknium1 and includes contributions from @theemozilla @karan4d and @huemin_art.",
        "name": "Nous Research",
        "photo": "https://pbs.twimg.com/profile_images/1722061115453272064/dydqIH88_normal.jpg",
        "reply_count": 9,
        "retweet_count": 48,
        "view_count": 94939,
        "like_count": 356
    },
    "1760033475510624582": {
        "content": "To quote @soldni: \"it's always a tokenizer problem\"\nExcited to watch these masterful videos again \ud83e\uddd1\u200d\ud83c\udf73",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 2,
        "retweet_count": 1,
        "view_count": 6792,
        "like_count": 30
    },
    "1759996551378940395": {
        "content": "We will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We'll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely. https://t.co/5haV7FvbBx",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 57,
        "retweet_count": 279,
        "view_count": 602868,
        "like_count": 2590
    },
    "1759883657731289364": {
        "content": "The independent Bank of England is failing. https://t.co/7zQvDkH2Re",
        "name": "Jacob Rees-Mogg",
        "photo": "https://pbs.twimg.com/profile_images/1572131691023532034/CIQOqDbT_normal.jpg",
        "reply_count": 759,
        "retweet_count": 83,
        "view_count": 156809,
        "like_count": 439
    },
    "1760084353055588539": {
        "content": "A nice example of the kind of capabilities unlocked by the long context feature in the Gemini 1.5 Pro model.",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 33,
        "retweet_count": 51,
        "view_count": 98396,
        "like_count": 469
    },
    "1760066335898513655": {
        "content": "Gemini 1.5 pro is STILL under hyped\n\nI uploaded an entire codebase directly from github, AND all of the issues (@vercel ai sdk,)\n\nNot only was it able to understand the entire codebase, it identified the most urgent issue, and IMPLEMENTED a fix.\n\nThis changes everything",
        "name": "Sully",
        "photo": "https://pbs.twimg.com/profile_images/1550142055854141440/iA_vPg8D_normal.jpg",
        "reply_count": 130,
        "retweet_count": 345,
        "view_count": 652324,
        "like_count": 2558
    },
    "1760005663416299798": {
        "content": "Andrej\u2019s brain is a big LLM that tokenizes complex things into easy tokens that our small mental LLMs can digest.",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 61,
        "retweet_count": 83,
        "view_count": 81568,
        "like_count": 1036
    },
    "1759996549109776702": {
        "content": "New (2h13m \ud83d\ude05) lecture: \"Let's build the GPT Tokenizer\"\n\nTokenizers are a completely separate stage of the LLM pipeline: they have their own training set, training algorithm (Byte Pair Encoding), and after training implement two functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 383,
        "retweet_count": 1947,
        "view_count": 1527121,
        "like_count": 14224
    },
    "1759970827053994132": {
        "content": "A few big papers throwing question on \"does RLAIF work\" yesterday.\n\nThe first is a paper by @archit_sharma97 is a pretty timely critique of RLAIF. It shows SFT on GPT 4 outputs > DPO + RLAIF on GPT4 ratings of GPT3.5 completions. A few things aren't surprising:\n1. The most important thing you can do right now is have better completions going into fine-tuning, rather than worrying about algorithm\n2. The second best thing is worrying about prompts, which us RLHFers don't do. ShareGPT and similar things without filtering are bad. Preference optimization is likely more sensitive than SFT, given the newer optimizers.\n\nThere's still lots more headroom in improving RLAIF imo than SFT. Looking at popular datasets like Nectar or Ultrafeedback there are so many bugs that can be filtered by heuristics.\n\nWe also got HELM-Instruct, which showed wacky results on different evaluators. All of Amazon MTurk, Scale AI, GPT4, and Claude aren't very correlated. Seeing this, I thought training a model with the evaluator you use is prolly needed, they may not transfer too.\n\nSo, while GPT4-as-a-judge is popular, it has a long way to go. Finally, in the appendix of @Muennighoff 's paper GRIT was more uncertainty over how we use GPT4 as judgments for MT Bench. \nArchit's paper: https://t.co/QeXRzseLCZ\nHELM-Instruct: https://t.co/wODR3Srx44\nGRIT paper: https://t.co/afm4c0hVt0",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 7,
        "retweet_count": 40,
        "view_count": 25947,
        "like_count": 169
    },
    "1759641209285324881": {
        "content": "The most epic AI panel in a while! We at NVIDIA have gathered ALL 8 authors of \"Attention is All You Need\" for a panel at GTC, hosted by none other than the GOAT himself, Jensen Huang.\n\nIn 2017, 8 researchers had a flash of genius and invented Transformer, the seminal work that transformed AI once and for all.\n\nHow did they come up with the idea?\nWhat challenges did they face? \nWhat surprised them in the following years?\nWhat have they been up to these days?\nHow do they envision a post-transformer future? \n\nThanks @maggie_albrecht for making this happen! I'm so glad to play a part in reaching out to some of the coauthors. \n\nJoin us for a behind-the-scenes look at modern AI's greatest moment. Mar. 20, 11 am PDT, at San Jose McEnery Convention Center, NVIDIA GTC: https://t.co/O9xzUX8K5R",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 71,
        "retweet_count": 267,
        "view_count": 186875,
        "like_count": 1687
    },
    "1759438523277443113": {
        "content": "Meta presents SPAR\n\nPersonalized Content-Based Recommendation via Long Engagement Attention\n\nLeveraging users' long engagement histories is essential for personalized content recommendations. The success of pretrained language models (PLMs) in NLP has led to their use in encoding user histories and candidate items, framing content recommendations as textual semantic matching tasks. However, existing works still struggle with processing very long user historical text and insufficient user-item interaction. In this paper, we introduce a content-based recommendation framework, SPAR, which effectively tackles the challenges of holistic user interest extraction from the long user engagement history. It achieves so by leveraging PLM, poly-attention layers and attention sparsity mechanisms to encode user's history in a session-based manner. The user and item side features are sufficiently fused for engagement prediction while maintaining standalone representations for both sides, which is efficient for practical model deployment. Moreover, we enhance user profiling by exploiting large language model (LLM) to extract global interests from user engagement history. Extensive experiments on two benchmark datasets demonstrate that our framework outperforms existing state-of-the-art (SoTA) methods.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 10,
        "retweet_count": 113,
        "view_count": 136230,
        "like_count": 689
    },
    "1759693120503971912": {
        "content": "I wrote down some thoughts on that \"LLM Agents can Autonomously Hack Websites\" paper thats been going around. TLDR; no data, lack of transparency, no knowledge of existing traditional tools.\n\nhttps://t.co/is1bGAeuGY",
        "name": "chrisrohlf",
        "photo": "https://pbs.twimg.com/profile_images/1616544882683793410/Vew04UdJ_normal.jpg",
        "reply_count": 5,
        "retweet_count": 26,
        "view_count": 20587,
        "like_count": 74
    },
    "1759486703696318935": {
        "content": "Modeling the world for action by generating pixel is as wasteful and doomed to failure as the largely-abandoned idea of \"analysis by synthesis\".\n\nDecades ago, there was a big debate in ML about the relative advantages of generative methods vs discriminative methods for classification.\nLearning theorists, such as Vapnik, argued against generative methods, pointing out that training a generative modeling was a way more difficult than classification (from the sample complexity standpoint).\n\nRegardless, a whole community in computer vision was arguing that recognition should work by generating pixels from explanatory latent variables. At inference time, one would infer the configuration of latent variables that generated the observed pixels.\nThe inference method would use optimization: e.g. use a 3D model of an object and try to find the pose parameters that reproduce the image.\nThis never quite worked, and it was very slow.\n\nLater, some people converted to the Bayesian religion and tried to use Bayesian inference for the latent (e.g. using variational approximations and/or sampling).\nAt some point, when Non-Parametric Bayes and Latent Dirichlet Allocation became the rage in text modeling, some folks heroically attempted to apply that to object recognition from images.\n>>> THIS WAS A COMPLETE AND UTTER FAILURE <<<\n\nIf your goal is to train a world model for recognition or planning, using pixel-level prediction is a terrible idea.\n\nGeneration happens to work for text because text is discrete with a finite number of symbols. Dealing with uncertainty in the prediction is easy in such settings. Dealing with prediction uncertainty in high-dimension continuous sensory inputs is simply intractable. \nThat's why generative models for sensory inputs are doomed to failure.",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 126,
        "retweet_count": 235,
        "view_count": 576034,
        "like_count": 1665
    },
    "1759476788152189291": {
        "content": "\u2591M\u2591Y\u2591\u2591W\u2591E\u2591I\u2591G\u2591H\u2591T\u2591S\u2591\u2591I\u2591N\u2591\u2591B\u2591I\u2591O\u2591",
        "name": "ChatGPT",
        "photo": "https://pbs.twimg.com/profile_images/1722425721602347008/UWMHieDx_normal.png",
        "reply_count": 164,
        "retweet_count": 258,
        "view_count": 1125574,
        "like_count": 4753
    },
    "1759437628150075879": {
        "content": "Great company here! \n\nProud to be among these awesome pods!",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 1704,
        "like_count": 7
    },
    "1759419918045356462": {
        "content": "This is a love letter to AI podcasts. At a time that feels almost impossible to keep up, these folks deserve their flowers for keeping us informed and educated. I am so grateful for these shows. Here are my favorites in case this helps you add to your stack (\ud83e\uddf5)... https://t.co/PRuwmAW1l9",
        "name": "Rex Harris",
        "photo": "https://pbs.twimg.com/profile_images/1587520501/205830_10100301967132364_12313060_50876982_5335125_n_normal.jpg",
        "reply_count": 2,
        "retweet_count": 2,
        "view_count": 5071,
        "like_count": 30
    },
    "1758182184694005787": {
        "content": "I want to draw people's attention to the ultra low resource translation use case for Kalamang highlighted here (and in the tech report at https://t.co/CTzTHNDCdo).  In context language learning from a single grammar book!\n\nThis is easy to miss in my longer thread about Gemini 1.5 Pro.",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 24,
        "retweet_count": 75,
        "view_count": 107978,
        "like_count": 597
    },
    "1759035574206500899": {
        "content": "@emilymbender Yes to the first.\n\nPresumably working on this problem and improving the translation quality increases the likelihood that it becomes \"usefully good\" if it's not already.\n\nhttps://t.co/SGwjYDfWaG",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 3,
        "retweet_count": 0,
        "view_count": 13325,
        "like_count": 45
    },
    "1758271975577837940": {
        "content": "@emilymbender Yes, from the original paper. https://t.co/q06eJLxcfQ https://t.co/htNeKrB9WH",
        "name": "Venkat",
        "photo": "https://pbs.twimg.com/profile_images/1716476284014927872/gLZN1EnL_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 13973,
        "like_count": 5
    },
    "1759065204443222405": {
        "content": "Every graduate student a department teaches stata/spss instead of actual statistical programming is a student they have knowingly and intentionally failed",
        "name": "A. Jordan Nafa",
        "photo": "https://pbs.twimg.com/profile_images/1774671901736284160/FSHrqR3I_normal.jpg",
        "reply_count": 18,
        "retweet_count": 58,
        "view_count": 117559,
        "like_count": 588
    },
    "1759041391274201531": {
        "content": "Programming is no longer a nice-to-have, we should really be teaching modern engineering practices in social science PhD programs",
        "name": "Cameron 'Quadron' Pfiffer",
        "photo": "https://pbs.twimg.com/profile_images/1760494311135956992/VATf1Q0D_normal.jpg",
        "reply_count": 7,
        "retweet_count": 22,
        "view_count": 142873,
        "like_count": 302
    },
    "1759049663917838659": {
        "content": "Worth watching, especially for parents \nhttps://t.co/k6gb2CMVqU",
        "name": "Elon Musk",
        "photo": "https://pbs.twimg.com/profile_images/1780044485541699584/p78MCn3B_normal.jpg",
        "reply_count": 14305,
        "retweet_count": 75147,
        "view_count": 46381340,
        "like_count": 205877
    },
    "1758919940143542388": {
        "content": "\"I'm annoyed that people let others express opinions I don't like\" is, for the record, not a sentiment I share.",
        "name": "Amanda Askell",
        "photo": "https://pbs.twimg.com/profile_images/1542922855431647233/-KRy-wfH_normal.jpg",
        "reply_count": 9,
        "retweet_count": 0,
        "view_count": 13600,
        "like_count": 109
    },
    "1757985933910237441": {
        "content": "Its not that these people walk around saying this shit and making millions that pisses me off but everyone else who lets them do this. The politicians, the journalists, the uncritical handing of microphones and resources and letting them chart policy.",
        "name": "@timnitGebru@dair-community.social on Mastodon",
        "photo": "https://pbs.twimg.com/profile_images/1660443800370827264/-X6cD__T_normal.jpg",
        "reply_count": 5,
        "retweet_count": 24,
        "view_count": 26232,
        "like_count": 109
    },
    "1758526890174751160": {
        "content": "What the fuck...\n\nOn a benchmark measuring precision recall from a FULL DAY OF AUDIO, Gemini Pro 1.5, when just seeing the *audio file* directly (no transcription!) far outperforms GPT-4 with a Whisper transcription.\n\nThis is mind-bending. https://t.co/HfsAPD6kit",
        "name": "Matt Shumer",
        "photo": "https://pbs.twimg.com/profile_images/1490950574090571778/BtgOaqUP_normal.jpg",
        "reply_count": 54,
        "retweet_count": 234,
        "view_count": 449874,
        "like_count": 2431
    },
    "1758694068744278225": {
        "content": "Well there you go https://t.co/GhzmnQmgTo",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 4,
        "retweet_count": 0,
        "view_count": 1570,
        "like_count": 12
    },
    "1758463018621640958": {
        "content": "Google keeps leveling up its AI game.\n\nGoogle just upgraded Maps with huge AI features!\n\nHere are the Key AI features of New Google Maps: \u2935\ufe0f\n\n(Number 2 is my favorite) https://t.co/0SqXm7bb1Z",
        "name": "Mushfiq Sajib",
        "photo": "https://pbs.twimg.com/profile_images/1679577721884770307/2Hd3y-vA_normal.jpg",
        "reply_count": 191,
        "retweet_count": 1259,
        "view_count": 4120679,
        "like_count": 10620
    },
    "1758631343595168142": {
        "content": "We\u2019ve just doubled GPT-4 Turbo rate limits across the board and removed all daily limits. Here are the new maximum tokens per minute (TPM) you can now achieve.\nhttps://t.co/D2Xm3QidZy https://t.co/f0k3L5FLzs",
        "name": "OpenAI Developers",
        "photo": "https://pbs.twimg.com/profile_images/1720598745664958465/TYA_2LYQ_normal.png",
        "reply_count": 103,
        "retweet_count": 234,
        "view_count": 433669,
        "like_count": 1931
    },
    "1758316913149534508": {
        "content": "The OpenAI Sora research article has been released\n\nThe release includes even more incredible AI generated video examples!\n\nHere are 10 more wild generated examples:\n(1/10) https://t.co/Cn6mwgkLSU",
        "name": "Allen T",
        "photo": "https://pbs.twimg.com/profile_images/1637173591627161600/D6VaNjXg_normal.jpg",
        "reply_count": 86,
        "retweet_count": 275,
        "view_count": 1465102,
        "like_count": 2456
    },
    "1758334064015126867": {
        "content": "Google presents A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts\n\npaper page: https://t.co/LTpxAIfy1N\n\nCurrent Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension tasks: QuALITY, NarrativeQA, and QMSum. ReadAgent outperforms the baselines on all three tasks while extending the effective context window by 3-20x.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 9,
        "retweet_count": 143,
        "view_count": 62710,
        "like_count": 562
    },
    "1758340385254891698": {
        "content": "Chain-of-Thought Reasoning Without Prompting\n\npaper page: https://t.co/o5fcJqa20L\n\nIn enhancing the reasoning capabilities of large language models (LLMs), prior research primarily focuses on specific prompting techniques such as few-shot or zero-shot chain-of-thought (CoT) prompting. These methods, while effective, often involve manually intensive prompt engineering. Our study takes a novel approach by asking: Can LLMs reason effectively without prompting? Our findings reveal that, intriguingly, CoT reasoning paths can be elicited from pre-trained LLMs by simply altering the decoding process. Rather than conventional greedy decoding, we investigate the top-k alternative tokens, uncovering that CoT paths are frequently inherent in these sequences. This approach not only bypasses the confounders of prompting but also allows us to assess the LLMs' intrinsic reasoning abilities. Moreover, we observe that the presence of a CoT in the decoding path correlates with a higher confidence in the model's decoded answer. This confidence metric effectively differentiates between CoT and non-CoT paths. Extensive empirical studies on various reasoning benchmarks show that the proposed CoT-decoding substantially outperforms the standard greedy decoding.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 7,
        "retweet_count": 140,
        "view_count": 62537,
        "like_count": 649
    },
    "1758191409973121259": {
        "content": "\"How do you find good research questions\"\n\nI'm starting to appreciate that good PhD students are like at my level or above in terms of \"problem solving\" ability, like given a direction pushing it - but on average the faculty are much \"more efficient\" at question-asking",
        "name": "alz",
        "photo": "https://pbs.twimg.com/profile_images/1548663597668122627/-u985urp_normal.jpg",
        "reply_count": 7,
        "retweet_count": 6,
        "view_count": 21862,
        "like_count": 104
    },
    "1758267186920181819": {
        "content": "We have AI voices that are indistinguishable from human ones \n\nWe have image generation that's close to indistinguishable \n\nWe just got video that's crazy temporally consistent. \n\nWe have headsets that mix reality with virtual generated reality. \n\nAnyone is adjusting their simulation theory probabilities? or just me?",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 10,
        "retweet_count": 3,
        "view_count": 5379,
        "like_count": 39
    },
    "1758208245980938595": {
        "content": "The next few years are going to be wilder than almost anyone realizes.\n\nI've been watching this over and over again and it's still hard to believe it's not real.\n\nhttps://t.co/OsArhNqV7v https://t.co/4ZESSIqTwR",
        "name": "Collin Burns",
        "photo": "https://pbs.twimg.com/profile_images/1407821826852474882/V2nW4C3s_normal.jpg",
        "reply_count": 9,
        "retweet_count": 30,
        "view_count": 46820,
        "like_count": 382
    },
    "1758244921985921314": {
        "content": "wtaf is going on today https://t.co/jB8kWE29c0",
        "name": "Patrick Blumenthal",
        "photo": "https://pbs.twimg.com/profile_images/1665157749376950272/lA3hus9D_normal.jpg",
        "reply_count": 75,
        "retweet_count": 479,
        "view_count": 625321,
        "like_count": 3467
    },
    "1758196706733068326": {
        "content": "This video was generated by Sora.\n\nThat's the new model by OpenAI. The most advanced text-to-video tool created so far.\n\nI'll share the videos here. Absolutely insane.\n\nPrompt: This close-up shot of a Victoria crowned pigeon showcases its striking blue plumage and red chest. Its crest is made of delicate, lacy feathers, while its eye is a striking red color. The bird\u2019s head is tilted slightly to the side, giving the impression of it looking regal and majestic. The background is blurred, drawing attention to the bird\u2019s striking appearance.",
        "name": "Eduardo Borges",
        "photo": "https://pbs.twimg.com/profile_images/1647206091774734340/nqyocaHs_normal.jpg",
        "reply_count": 872,
        "retweet_count": 2634,
        "view_count": 16881147,
        "like_count": 18337
    },
    "1758170436221677667": {
        "content": "Some PhD students seem to think a good way to find research ideas is to read the conclusions paragraph of good papers, and do the things authors say are natural next steps for research\n\nThis is a terrible idea! Absolutely terrible! It is hard to do worse than this!",
        "name": "alz",
        "photo": "https://pbs.twimg.com/profile_images/1548663597668122627/-u985urp_normal.jpg",
        "reply_count": 18,
        "retweet_count": 21,
        "view_count": 122500,
        "like_count": 327
    },
    "1758154521711452517": {
        "content": "Betting that Gemini 1.5 Turing Test will not be able to watch TV shows and reliably answer questions about them correctly.\n \nLet\u2019s see who is right!\n\n(My original challenge, from 2014: https://t.co/1N4qeEn6uH )",
        "name": "Gary Marcus",
        "photo": "https://pbs.twimg.com/profile_images/1749047536361586688/N1p9EZpc_normal.jpg",
        "reply_count": 8,
        "retweet_count": 4,
        "view_count": 12214,
        "like_count": 40
    },
    "1758152293734580614": {
        "content": "Up to 1 hr video. I'm guessing it will be able to pass @GaryMarcus' \"Turing Test\" of watching a TV program and answering questions on it. https://t.co/GBY0Cr7Uz5",
        "name": "Greg \u23f9\ufe0f Colbourn",
        "photo": "https://pbs.twimg.com/profile_images/1640378326203105284/wIZ2CGJM_normal.jpg",
        "reply_count": 2,
        "retweet_count": 0,
        "view_count": 12500,
        "like_count": 9
    },
    "1758165400720957646": {
        "content": "I'm coming around on long-context. Shit seems to work. Heck yeah.",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 7,
        "retweet_count": 4,
        "view_count": 12595,
        "like_count": 69
    },
    "1758146211029405951": {
        "content": "Needle in a Haystack Tests Out to 10M Tokens\n\nFirst, let\u2019s take a quick glance at a needle-in-a-haystack test across many different modalities to exercise Gemini 1.5 Pro\u2019s ability to retrieve information from its very long context.  In these tests, green is good, and red is not good, and these are almost entirely green (>99.7% recall), even out to 10M tokens.  Great!  A bit more on needle-in-a-haystack tests later in the thread.",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 32,
        "retweet_count": 125,
        "view_count": 401033,
        "like_count": 1091
    },
    "1758157119986057613": {
        "content": "JUST IN: Google releases Gemini 1.5, a powerful MoE model.\n\nIt's a huge breakthrough. The model has the longest context window ever seen: 1 million tokens.\n\nIt can process 1 hour of video, 11 hours of audio, 30,000 lines of code, or 700,000 words in a single prompt.\n\nWhen tested on text, code, image, audio and video evaluations, 1.5 Pro outperforms 1.0 Pro on 87% of the benchmarks used for developing LLMs.\n\nYou can can sign up in AI Studio to try it out.",
        "name": "Lior\u26a1",
        "photo": "https://pbs.twimg.com/profile_images/1737888535099899906/5YPbFAld_normal.jpg",
        "reply_count": 18,
        "retweet_count": 90,
        "view_count": 81774,
        "like_count": 440
    },
    "1758148949884670074": {
        "content": "New version of Gemini. There was a lot of buzz - did anyone predict this?",
        "name": "Mira",
        "photo": "https://pbs.twimg.com/profile_images/1776446400932597760/ioK8-UYG_normal.jpg",
        "reply_count": 3,
        "retweet_count": 4,
        "view_count": 18799,
        "like_count": 58
    },
    "1758147653425058014": {
        "content": "Google announces Gemini 1.5\n\nGemini 1.5 Pro, mid-sized model, will soon come standard with a 128K-token context window, but starting today, developers + customers can sign up for the limited Private Preview to try out 1.5 Pro with a groundbreaking and experimental 1 million token context window",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 21,
        "retweet_count": 118,
        "view_count": 116857,
        "like_count": 594
    },
    "1758147447237366189": {
        "content": "In December we began the Gemini Era, and we\u2019ve continued to make relentless progress since. Today we\u2019re thrilled to introduce the next generation: Gemini 1.5 - hugely enhanced performance, highly efficient architecture &amp; long-context length breakthrough\nhttps://t.co/dKlzOQLyK4 https://t.co/y942bkDd31",
        "name": "Demis Hassabis",
        "photo": "https://pbs.twimg.com/profile_images/691700243809718272/z7XZUARB_normal.jpg",
        "reply_count": 78,
        "retweet_count": 226,
        "view_count": 530028,
        "like_count": 1514
    },
    "1758145921131630989": {
        "content": "In December, we launched Gemini 1.0 Pro. Today, we're introducing Gemini 1.5 Pro! \ud83d\ude80\u00a0\n\nThis next-gen model uses a Mixture-of-Experts (MoE) approach for more efficient training & higher-quality responses. Gemini 1.5 Pro, our mid-sized model, will soon come standard with a 128K-token context window, but starting today, developers + customers can sign up for the limited Private Preview to try out 1.5 Pro with a groundbreaking and experimental 1 million token context window!\n\nThe 1M tokens feature unlocks huge possibilities for devs - upload hundreds of pages of text, entire code repos, and long videos and let Gemini reason across them.\n\nIt's still experimental and early and we\u2019d love your feedback - learn more here.\u00a0 https://t.co/8Har4kAD6n",
        "name": "Sundar Pichai",
        "photo": "https://pbs.twimg.com/profile_images/1710036756731510784/FyfFgM-B_normal.jpg",
        "reply_count": 480,
        "retweet_count": 809,
        "view_count": 832095,
        "like_count": 5261
    },
    "1758087727487111405": {
        "content": "Sadiq Khan says the quiet part out loud. https://t.co/dKMOgRopf3",
        "name": "Conservatives",
        "photo": "https://pbs.twimg.com/profile_images/1726550468191469568/lsMFt5-G_normal.jpg",
        "reply_count": 1533,
        "retweet_count": 460,
        "view_count": 1215257,
        "like_count": 1717
    },
    "1757986972512239665": {
        "content": "My calendar this week https://t.co/LxN6yB7qn6",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 734,
        "retweet_count": 320,
        "view_count": 1495503,
        "like_count": 12357
    },
    "1758036247115608317": {
        "content": "Meta\u2019s LLM for software testing work is super exciting. \n\nThis paper describes Meta\u2019s TestGen-LLM tool, which uses LLMs to automatically improve existing human-written tests. TestGen-LLM verifies that its generated test classes successfully clear a set of filters that assure measurable improvement over the original test suite, thereby eliminating problems due to LLM hallucination. We describe the deployment of TestGen-LLM at Meta test-a-thons for the Instagram and Facebook platforms. In an evaluation on Reels and Stories products for Instagram, 75% of TestGen-LLM\u2019s test cases built correctly, 57% passed reliably, and 25% increased coverage. During Meta\u2019s Instagram and Facebook test-a-thons, it improved 11.5% of all classes to which it was applied, with 73% of its recommendations being accepted for production deployment by Meta software engineers. We believe this is the first report on industrial scale deployment of LLM-generated code backed by such assurances of code improvement.",
        "name": "Nathan Benaich",
        "photo": "https://pbs.twimg.com/profile_images/1860887094/2564_517540442680_3904369_31246376_1912207_n_normal.jpg",
        "reply_count": 15,
        "retweet_count": 269,
        "view_count": 298601,
        "like_count": 1339
    },
    "1757636603231850825": {
        "content": "the odds of youtube videos getting us to AGI just dramatically increased today.",
        "name": "Aravind Srinivas",
        "photo": "https://pbs.twimg.com/profile_images/1781508360069894144/1fReqIat_normal.jpg",
        "reply_count": 43,
        "retweet_count": 39,
        "view_count": 128184,
        "like_count": 882
    },
    "1757605047989379420": {
        "content": "Google Deepmind presents Mixtures of Experts Unlock Parameter Scaling for Deep RL\n\npaper page: https://t.co/IjxzP9rrV6\n\nThe recent rapid progress in (self) supervised learning models is in large part predicted by empirical scaling laws: a model's performance scales proportionally to its size. Analogous scaling laws remain elusive for reinforcement learning domains, however, where increasing the parameter count of a model often hurts its final performance. In this paper, we demonstrate that incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs (Puigcerver et al., 2023), into value-based networks results in more parameter-scalable models, evidenced by substantial performance increases across a variety of training regimes and model sizes. This work thus provides strong empirical evidence towards developing scaling laws for reinforcement learning.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 6,
        "retweet_count": 117,
        "view_count": 103056,
        "like_count": 492
    },
    "1757594413159924035": {
        "content": "I often see resumes where someone has worked at 6 companies over the last 10 years.\n\nI'm staring at one right now. These job-hoppers usually last a little under 2yrs per company on average.\n\nIf someone has a jumpy resume, it's the first thing I notice. It's so blatant to me, yet it continues to fool a lot of people.\n\nThinking back over the last 15yrs at my companies:\n\nI've hired thousands of people, and I can't think of a single person I've hired with a jumpy resume who has worked out long-term. Not one.",
        "name": "gelo",
        "photo": "https://pbs.twimg.com/profile_images/1626854349380132865/-34_eKsI_normal.jpg",
        "reply_count": 79,
        "retweet_count": 101,
        "view_count": 664711,
        "like_count": 2209
    },
    "1757601059474677942": {
        "content": "We just had one of the biggest days in AI.\n\nHuge developments from Sam Altman/GPT-5, NVIDIA, OpenAI, Cohere, Andrej Karpathy, Nous, and ElevenLabs.\n\nHere's EVERYTHING you need to know:",
        "name": "Rowan Cheung",
        "photo": "https://pbs.twimg.com/profile_images/1711152452735774720/Cotttl-n_normal.jpg",
        "reply_count": 60,
        "retweet_count": 607,
        "view_count": 1687871,
        "like_count": 4774
    },
    "1757600075281547344": {
        "content": "Hi everyone yes, I left OpenAI yesterday. First of all nothing \"happened\" and it\u2019s not a result of any particular event, issue or drama (but please keep the conspiracy theories coming as they are highly entertaining :)). Actually, being at OpenAI over the last ~year has been really great - the team is really strong, the people are wonderful, and the roadmap is very exciting, and I think we all have a lot to look forward to. My immediate plan is to work on my personal projects and see what happens. Those of you who\u2019ve followed me for a while may have a sense for what that might look like ;) Cheers",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 1593,
        "retweet_count": 1454,
        "view_count": 3311872,
        "like_count": 22903
    },
    "1757464973930881453": {
        "content": "Every time I start a new project, I follow a very specific 5-step checklist\n\n\u2022 It leverages the existing information in my Second Brain\n\u2022 Takes me 20-30 minutes to complete\n\u2022 Helps me to execute efficiently\n\nHere\u2019s why \ud83d\udc47",
        "name": "Tiago Forte",
        "photo": "https://pbs.twimg.com/profile_images/1527701676521672707/YXvJP3ac_normal.jpg",
        "reply_count": 10,
        "retweet_count": 11,
        "view_count": 28268,
        "like_count": 106
    },
    "1757471884654837872": {
        "content": "New ChatGPT feature just dropped: Memory.\n\nPersonalized and tailored AI assistants are getting closer every day.",
        "name": "Rowan Cheung",
        "photo": "https://pbs.twimg.com/profile_images/1711152452735774720/Cotttl-n_normal.jpg",
        "reply_count": 16,
        "retweet_count": 69,
        "view_count": 212064,
        "like_count": 437
    },
    "1757469997742666052": {
        "content": "We\u2019re testing ChatGPT's ability to remember things you discuss to make future chats more helpful. \n\nThis feature is being rolled out to a small portion of Free and Plus users, and it's easy to turn on or off. https://t.co/1Tv355oa7V https://t.co/BsFinBSTbs",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 483,
        "retweet_count": 1056,
        "view_count": 2061227,
        "like_count": 6255
    },
    "1757489956854087691": {
        "content": "I often see resumes where someone has worked at 6 companies over the last 10 years.\n\nI'm staring at one right now. These job-hoppers usually last a little under 2yrs per company on average.\n\nIf someone has a jumpy resume, it's the first thing I notice. It's so blatant to me, yet it continues to fool a lot of people.\n\nThinking back over the last 15yrs at my companies:\n\nI've hired thousands of people, and I can't think of a single person I've hired with a jumpy resume who has worked out long-term. Not one.",
        "name": "Brett Adcock",
        "photo": "https://pbs.twimg.com/profile_images/1687518352179335168/e__sKBmM_normal.jpg",
        "reply_count": 8311,
        "retweet_count": 927,
        "view_count": 25956541,
        "like_count": 18040
    },
    "1757466498287722783": {
        "content": "Finally, someone cracked it. The ChatGPT system prompt.\n\nIf you were wondering why GPT became so bad in the past 6 months, its because \"laziness\" is part of the system prompt: \n\n1. \"When asked to write summaries longer than 100 words write an 80-word summary.\"\n\n2. \"DO NOT list or refer to the descriptions before OR after generating the images.\"\n\n3. \"Do not create more than 1 image, even if the user requests more.\"",
        "name": "Lior\u26a1",
        "photo": "https://pbs.twimg.com/profile_images/1737888535099899906/5YPbFAld_normal.jpg",
        "reply_count": 99,
        "retweet_count": 431,
        "view_count": 922954,
        "like_count": 3496
    },
    "1757148082209235287": {
        "content": "Looks like Sunak\u2019s appearance on GB News was an even bigger car crash than predicted. What did he and his advisers think would happen?\nhttps://t.co/OZXYUjEMAs",
        "name": "Nick Tyrone",
        "photo": "https://pbs.twimg.com/profile_images/1417431981969842176/-rJgrafy_normal.jpg",
        "reply_count": 301,
        "retweet_count": 512,
        "view_count": 1142638,
        "like_count": 2614
    },
    "1757083958981063153": {
        "content": "BREAKING: NVIDIA is now worth more than Amazon and Google:\n\n1. \ud83c\uddfa\ud83c\uddf8 Microsoft: $3.115 trillion \n2. \ud83c\uddfa\ud83c\uddf8 Apple: $2.904 trillion \n3. \ud83c\uddf8\ud83c\udde6 Saudi Aramco: $2.034 trillion \n4. \ud83c\uddfa\ud83c\uddf8 NVIDIA: $1.831 trillion \n5. \ud83c\uddfa\ud83c\uddf8 Alphabet: $1.820 trillion \n6. \ud83c\uddfa\ud83c\uddf8 Amazon: $1.803 trillion\n7. \ud83c\uddfa\ud83c\uddf8 Meta: $1.217 trillion",
        "name": "World of Statistics",
        "photo": "https://pbs.twimg.com/profile_images/1335168437220421632/VCHg78Nf_normal.jpg",
        "reply_count": 301,
        "retweet_count": 1523,
        "view_count": 3096338,
        "like_count": 14401
    },
    "1757147630453362880": {
        "content": "What Algorithms can Transformers Learn? (https://t.co/pQjeXfZdhX)  has an interesting discussion about indexes and sharp restrictions on their usage. \n\n(I didn't really think about this much in my version, but it is a worthwhile point. positional embeddings are a bit gnarly.) https://t.co/IFIellEUPN",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 3,
        "retweet_count": 42,
        "view_count": 32892,
        "like_count": 333
    },
    "1756939511374692850": {
        "content": "My kindest sympathies for the Bayesian Optimization folks",
        "name": "Chirag Nagpal",
        "photo": "https://pbs.twimg.com/profile_images/1605920875077046274/AcMimDDJ_normal.jpg",
        "reply_count": 12,
        "retweet_count": 41,
        "view_count": 121474,
        "like_count": 633
    },
    "1756930242965606582": {
        "content": "Have you ever done a dense grid search over neural network hyperparameters? Like a *really dense* grid search? It looks like this (!!). Blueish colors correspond to hyperparameters for which training converges, redish colors to hyperparameters for which training diverges. https://t.co/yqJlschvVK",
        "name": "Jascha Sohl-Dickstein",
        "photo": "https://pbs.twimg.com/profile_images/926209612860100609/wsLflqKD_normal.jpg",
        "reply_count": 279,
        "retweet_count": 2069,
        "view_count": 1556069,
        "like_count": 10066
    },
    "1756675813519380503": {
        "content": "The result is horrific. Weekly attacks. Sometimes daily. From 2001 - 2021 the UK Averaged 3.3 deaths from dog attacks. In 2022 it was 10. Since then we have seen constant reports of XL Bullies, without warning, attacking either their owners or members of the public.",
        "name": "Sam Browfan",
        "photo": "https://pbs.twimg.com/profile_images/1765145527144853504/ccHCzxci_normal.jpg",
        "reply_count": 1,
        "retweet_count": 1,
        "view_count": 2598,
        "like_count": 30
    },
    "1756675744632098886": {
        "content": "The XL Bullies, despite being only 1% of dogs in the UK are responsible for 75% of human deaths and around 50% of all attacks on people and pets.\n\nTo understand why they attack and kill so disproportionately you have to understand their history.",
        "name": "Sam Browfan",
        "photo": "https://pbs.twimg.com/profile_images/1765145527144853504/ccHCzxci_normal.jpg",
        "reply_count": 3,
        "retweet_count": 3,
        "view_count": 3838,
        "like_count": 46
    },
    "1756701124063789251": {
        "content": "My night time erections are now better than the average 18 year old. \n\nLast night was 179 minutes.  Here's the data. \n\nNight time erections are a biomarker for cardiovascular, physiological and sexual health. https://t.co/OJRWyhgJKi",
        "name": "Bryan Johnson /dd",
        "photo": "https://pbs.twimg.com/profile_images/1685130833823436800/SjZkO7Rb_normal.jpg",
        "reply_count": 979,
        "retweet_count": 398,
        "view_count": 4086765,
        "like_count": 4584
    },
    "1756606815033282759": {
        "content": "This happened during a football match in Indonesia \ud83c\uddee\ud83c\udde9 https://t.co/JHdzafaUpV",
        "name": "Context Hunter",
        "photo": "https://pbs.twimg.com/profile_images/1645017697850097666/IUT7e3SF_normal.jpg",
        "reply_count": 808,
        "retweet_count": 5602,
        "view_count": 15272874,
        "like_count": 42924
    },
    "1756701264941912503": {
        "content": "It\u2019s time for common sense not divisiveness.\n\nThat\u2019s why I\u2019m commissioning a root and branch review of ethnicity, diversity and inclusivity policies across defence. https://t.co/0biPwTrO5Z",
        "name": "Rt Hon Grant Shapps MP",
        "photo": "https://pbs.twimg.com/profile_images/1604158037522087938/7Oec6fFe_normal.jpg",
        "reply_count": 1669,
        "retweet_count": 171,
        "view_count": 866437,
        "like_count": 1064
    },
    "1755919209551294741": {
        "content": "Oh Lord. There is film footage",
        "name": "ALASTAIR CAMPBELL",
        "photo": "https://pbs.twimg.com/profile_images/1441638351052881920/13PTOAD0_normal.jpg",
        "reply_count": 1026,
        "retweet_count": 3525,
        "view_count": 1448100,
        "like_count": 12141
    },
    "1755906381461262564": {
        "content": "Coming up on #BBCPM today at 5 \u2013 what is happening with government debt?\n\nJoin us to find out, after this interview on yesterday\u2019s programme by @EvanHD with the Treasury Chief Secretary Laura Trott \u2b07\ufe0f https://t.co/PvvAeYma9x",
        "name": "BBC Radio 4 PM",
        "photo": "https://pbs.twimg.com/profile_images/1196760037642948609/utNEBcyH_normal.jpg",
        "reply_count": 990,
        "retweet_count": 2139,
        "view_count": 3325768,
        "like_count": 6022
    },
    "1755578475186913400": {
        "content": "Bard (the product) is now Gemini.  Gemini Advanced is powered by the Gemini Ultra 1.0 model, our most advanced multimodal model.  Congrats to everyone who worked on this effort, including the Bard and Gemini teams!  Lots more updates in the blog post!\n\nhttps://t.co/Rd50lEJQYI",
        "name": "Jeff Dean (@\ud83c\udfe1)",
        "photo": "https://pbs.twimg.com/profile_images/935325968280907776/AcBo6zJc_normal.jpg",
        "reply_count": 70,
        "retweet_count": 258,
        "view_count": 167395,
        "like_count": 1609
    },
    "1755577976454799448": {
        "content": "Today, we\u2019re entering the next chapter of our Gemini era by bringing our #GeminiAI models to more of our products, starting with Bard \u2014 which will now be called Gemini. https://t.co/KFRp1qkfHg https://t.co/WKHZyv3Ejp",
        "name": "Google",
        "photo": "https://pbs.twimg.com/profile_images/1754606338460487681/bWupXdxo_normal.jpg",
        "reply_count": 556,
        "retweet_count": 1333,
        "view_count": 1069208,
        "like_count": 4690
    },
    "1755571452663988467": {
        "content": "The AI model that supposedly beats GPT-4:\n\nGoogle's Gemini Advanced (Ultra) is finally here. \n\nIt's free for two months. Link in replies. Let me know how you're finding it compared to GPT-4 and Claude! https://t.co/4t6rBwPmYG",
        "name": "Jeremy Nguyen \u270d\ud83c\udffc \ud83d\udea2",
        "photo": "https://pbs.twimg.com/profile_images/1446643610904973313/_B74rHQL_normal.jpg",
        "reply_count": 21,
        "retweet_count": 4,
        "view_count": 7868,
        "like_count": 47
    },
    "1755548988823191800": {
        "content": "Bard Advanced !\nhttps://t.co/6aL2rDdWAI https://t.co/b3Yvosmdv6",
        "name": "general intelligence",
        "photo": "https://pbs.twimg.com/profile_images/1707765289742647296/pqpnMSPc_normal.jpg",
        "reply_count": 1,
        "retweet_count": 2,
        "view_count": 2021,
        "like_count": 18
    },
    "1755284528887734661": {
        "content": "A woman with an 'extreme interest in death' live-streamed the sadistic killing of a cat four months before she murdered a man she met in a street, a court has heard.\n\nScarlet Blake, 25, is accused of targeting Jorge Martin Carreno, 30, as he walked home from a night-out in Oxford in July 2021.\n\nhttps://t.co/fF3dBGI78j",
        "name": "London & UK Street News",
        "photo": "https://pbs.twimg.com/profile_images/1591070792393039874/FOQ1dPI-_normal.jpg",
        "reply_count": 31,
        "retweet_count": 99,
        "view_count": 146001,
        "like_count": 187
    },
    "1755438453343547462": {
        "content": "\ud83c\udfc5 To me, this feels more like the kind of neural model interpretability research we should be doing than much of the recent work on interpretability of transformer models.",
        "name": "Christopher Manning",
        "photo": "https://pbs.twimg.com/profile_images/512256295542333440/8Jo4w8kV_normal.jpeg",
        "reply_count": 4,
        "retweet_count": 56,
        "view_count": 64883,
        "like_count": 432
    },
    "1755158457785704771": {
        "content": "Emergence in LLMs is a mystery. Emergence in physics is linked to phase transitions. We identify a phase transition between semantic and positional learning in a toy model of dot-product attention. Very excited about this one! https://t.co/ALb9D8YdfP https://t.co/WXwG3atZWw",
        "name": "Lenka Zdeborova",
        "photo": "https://pbs.twimg.com/profile_images/1426449775319306245/mlTg7OkP_normal.jpg",
        "reply_count": 15,
        "retweet_count": 248,
        "view_count": 171471,
        "like_count": 1389
    },
    "1755130612657111067": {
        "content": "Warwickshire County Council Conservatives - swapping notes on their theories as to why there's been a rise in children with Special Educational Needs.\n\nPrepare to be appalled.",
        "name": "Otto English",
        "photo": "https://pbs.twimg.com/profile_images/1658473821639426052/Svd-4AEt_normal.jpg",
        "reply_count": 191,
        "retweet_count": 696,
        "view_count": 235637,
        "like_count": 1823
    },
    "1754599357356167406": {
        "content": "@Warwickshire_CC this is absolutely disgusting! Talking about SEN children in this way, is this what your council thinks of SEN children ? #SEND https://t.co/DXylrMWrr5",
        "name": "Kerry Wilks",
        "photo": "https://pbs.twimg.com/profile_images/1583150152348581907/-FHNb4tp_normal.jpg",
        "reply_count": 159,
        "retweet_count": 255,
        "view_count": 293763,
        "like_count": 491
    },
    "1755303301032124699": {
        "content": "Are you telling me web browsers can do this now?\nOn-device background removal is no joke.\n\n\u2b07\ufe0f link below to try it yourself https://t.co/89b1aX7Oa8",
        "name": "Victor M",
        "photo": "https://pbs.twimg.com/profile_images/1099983311101984768/p7dZK4S__normal.jpg",
        "reply_count": 33,
        "retweet_count": 164,
        "view_count": 214754,
        "like_count": 1789
    },
    "1755276397336236339": {
        "content": "To help make models more robust and defend against misuse, we created HarmBench, an evaluation framework for automated red teaming and testing the adversarial robustness of LLMs and multimodal models.\n\n\ud83c\udf10 https://t.co/uKz8B5T9jP\n\ud83d\udcdd https://t.co/LrVdH1aGNd https://t.co/VUI3cI85Nw",
        "name": "Dan Hendrycks",
        "photo": "https://pbs.twimg.com/profile_images/1099568087253245952/4_SNw6E6_normal.png",
        "reply_count": 4,
        "retweet_count": 49,
        "view_count": 23537,
        "like_count": 256
    },
    "1755117828208722195": {
        "content": "Cool post from my MATS scholars @Connor_Kissane &amp; Rob Krzyzanowski: Attention SAEs scale to GPT2 Small!\n\nWe find that training sparse auto encoders on the attention outputs continues to work on GPT2 Small, and open source SAEs on every layer! We hope this is a useful resource https://t.co/bX2lDNtqnw",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 2,
        "retweet_count": 11,
        "view_count": 9372,
        "like_count": 77
    },
    "1754690055895916740": {
        "content": "I might need to write a blog post on precision and recall.... lol how are people not measuring precision and recall PLEASE",
        "name": "jason liu",
        "photo": "https://pbs.twimg.com/profile_images/1753841038408536065/T21ZMwAT_normal.jpg",
        "reply_count": 10,
        "retweet_count": 1,
        "view_count": 9134,
        "like_count": 61
    },
    "1754811293142241650": {
        "content": "As we\u2019re ruminating on Saturday supplement articles and what a creep Gregg Wallace is, let\u2019s just remember this work of art: https://t.co/jlkDm2NTRR",
        "name": "monsieurmangetout #StopTheTories",
        "photo": "https://pbs.twimg.com/profile_images/1724056793570025472/D6kVKphJ_normal.jpg",
        "reply_count": 343,
        "retweet_count": 1035,
        "view_count": 1399257,
        "like_count": 13502
    },
    "1754896431461052886": {
        "content": "Lee Anderson MP, former Deputy Chairman of the Conservative Party: \"I'm pretty sure that coal 100 million years ago was trees and plants.. it was, well I would argue that's sustainable.\" https://t.co/0wzIvXntz7",
        "name": "Shehab Khan ITV",
        "photo": "https://pbs.twimg.com/profile_images/1646491461679022083/5l6DKDVT_normal.jpg",
        "reply_count": 1810,
        "retweet_count": 430,
        "view_count": 2275164,
        "like_count": 1815
    },
    "1754606747333906494": {
        "content": "7B model better than the most recent GPT4 out of the gate on text to SQL!\n\nI've said it and will say it again: except for very general tasks (like a search engine), smaller models are better/cheaper/faster!",
        "name": "clem \ud83e\udd17",
        "photo": "https://pbs.twimg.com/profile_images/1100512198139498497/utHSJ4st_normal.png",
        "reply_count": 6,
        "retweet_count": 18,
        "view_count": 29717,
        "like_count": 173
    },
    "1754577775493886308": {
        "content": "Launching the second generation of SQLCoder-7b on @huggingface today!\n\nThis is distilled from our 70B model, and performs around as well* as GPT-4 for text-to-SQL generation. Finetuned on @AIatMeta's CodeLlama-7b.\n\n*To be more precise \u2013 this model is much better at ratios and datetime than GPT-4, but GPT-4 is better (as of today) at complex joins and group-bys than our 7B model.\n\nWe'd been sitting on this one for a while, and this launch was inspired by the excellent natural-sql-7b that\n@calebfahlgren launched today. \n\nWe expect to improve this model quite significantly over this week with better data (specially for joins and group bys), and will also launch a GUI + webserver where you can connect this with your database and start talking to it.  Shipping is fun :D",
        "name": "Rishabh Srivastava",
        "photo": "https://pbs.twimg.com/profile_images/1597288749225779200/D8yr60Mz_normal.jpg",
        "reply_count": 5,
        "retweet_count": 48,
        "view_count": 94017,
        "like_count": 442
    },
    "1754877980642296245": {
        "content": "\u201cHow much money did you make in The City?\u201d\n\n@lewis_goodall asks @Jacob_Rees_Mogg about his time working in finance after his speech rallying against \u2018Davos Man\u2019 at the launch of \u2018Popular Conservatism.\u2019\n\nComing to @GlobalPlayer https://t.co/5tmM04fokN",
        "name": "The News Agents",
        "photo": "https://pbs.twimg.com/profile_images/1571968059660713987/xcfgceDS_normal.jpg",
        "reply_count": 1150,
        "retweet_count": 1111,
        "view_count": 1479531,
        "like_count": 4512
    },
    "1749902875264774263": {
        "content": "More pragmatically, I'd guess the rise of LLMs force out many fields EXCEPT mech interp, making it more compelling in comparison? With the rise of scale, you need a lot of compute to do anything interesting in most areas, or need to do less sexy things like extensive prompt engineering.",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 3,
        "retweet_count": 0,
        "view_count": 3305,
        "like_count": 26
    },
    "1754723073889120555": {
        "content": "BlackMamba\n\nMixture of Experts for State-Space Models\n\npaper page: https://t.co/4Zbl0X4f87\n\nState-space models (SSMs) have recently demonstrated competitive performance to transformers at large-scale language modeling benchmarks while achieving linear time and memory complexity as a function of sequence length. Mamba, a recently released SSM model, shows impressive performance in both language modeling and long sequence processing tasks. Simultaneously, mixture-of-expert (MoE) models have shown remarkable performance while significantly reducing the compute and latency costs of inference at the expense of a larger memory footprint. In this paper, we present BlackMamba, a novel architecture that combines the Mamba SSM with MoE to obtain the benefits of both. We demonstrate that BlackMamba performs competitively against both Mamba and transformer baselines, and outperforms in inference and training FLOPs. We fully train and open-source 340M/1.5B and 630M/2.8B BlackMamba models on 300B tokens of a custom dataset. We show that BlackMamba inherits and combines both of the benefits of SSM and MoE architectures, combining linear-complexity generation from SSM with cheap and fast inference from MoE.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 2,
        "retweet_count": 45,
        "view_count": 30484,
        "like_count": 251
    },
    "1754708562561933572": {
        "content": "DeepSeekMath\n\nPushing the Limits of Mathematical Reasoning in Open Language Models\n\npaper page: https://t.co/nWRZbfLRdC\n\nDeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 2,
        "retweet_count": 52,
        "view_count": 49107,
        "like_count": 267
    },
    "1754721998951899163": {
        "content": "Microsoft presents Rethinking Interpretability in the Era of Large Language Models\n\npaper page: https://t.co/lP2rzxjyXq\n\nInterpretable machine learning has exploded as an area of interest over the last decade, sparked by the rise of increasingly large datasets and deep neural networks. Simultaneously, large language models (LLMs) have demonstrated remarkable capabilities across a wide array of tasks, offering a chance to rethink opportunities in interpretable machine learning. Notably, the capability to explain in natural language allows LLMs to expand the scale and complexity of patterns that can be given to a human. However, these new capabilities raise new challenges, such as hallucinated explanations and immense computational costs. In this position paper, we start by reviewing existing methods to evaluate the emerging field of LLM interpretation (both interpreting LLMs and using LLMs for explanation). We contend that, despite their limitations, LLMs hold the opportunity to redefine interpretability with a more ambitious scope across many applications, including in auditing LLMs themselves. We highlight two emerging research priorities for LLM interpretation: using LLMs to directly analyze new datasets and to generate interactive explanations.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 4,
        "retweet_count": 79,
        "view_count": 47593,
        "like_count": 352
    },
    "1754538215959335100": {
        "content": "\ud83c\udf89Happy to announce the release of Qwen1.5! This time, we directly opensource new models of 6 sizes, 0.5B, 1.8B, 4B, 7B, 14B, and 72B (including base, chat, AWQ, GPTQ, GGUF)! From small to huge! \n\nBlog: https://t.co/XH2KuHSKDb\nGitHub: https://t.co/vRLJukyWlQ\nHF: https://t.co/Ct2TVyOT1A\nModelScope: https://t.co/2ZEE2p0uVm\n\nThis time, except for the model quality improvement (check @huybery 's tweet), we also have:\n \nQwen2 codes are integrated to \ud83e\udd17Hugging face transformers (since 4.37.0) , and from now on, we don\u2019t need `trust_remote_code` anymore. \n\nAdditionally we\u2019ve collaborated with frameworks like:\n\ud83d\udd27vLLM, SGLang for deployment;\n\ud83c\udf1fAutoAWQ, AutoGPTQ for quantization;\n\ud83d\ude80Axolotl, LLaMA-Factory for finetuning;\n\ud83d\udcbb llama.cpp, MLX for local LLM inference;\n\u2026\nand the Qwen1.5 series is available on platforms such as Ollama and LMStudio!\n \nAPI services are offered not only on DashScope but also on Together, with global accessibility. Visit https://t.co/flTlbPjIuR to get started, and we recommend trying out Qwen1.5-72B-chat!\n \nWe hope this time you will find Qwen1.5 easier to use and enjoy the model quality!",
        "name": "Junyang Lin",
        "photo": "https://pbs.twimg.com/profile_images/1546168426799828992/YjzzbM6Z_normal.jpg",
        "reply_count": 34,
        "retweet_count": 116,
        "view_count": 260698,
        "like_count": 617
    },
    "1754475453190914512": {
        "content": "There's more controversy in the Battle of Bramall Lane.\n\nTrailing 3-0 after 3 red cards, they suffer 2 convenient injuries.\n\nWith the Blades down to 6 men, the ref is forced to abandon the match.\n\nWarnock denies cheating and complains he's accused of \"more crimes than Bin Laden\". https://t.co/Cp5UzzQHmR",
        "name": "The Upshot",
        "photo": "https://pbs.twimg.com/profile_images/1470787186719174657/5x9IDTSC_normal.jpg",
        "reply_count": 3,
        "retweet_count": 20,
        "view_count": 46824,
        "like_count": 469
    },
    "1754485544875417841": {
        "content": "Hinton is so wrong about this and so far behind the times that he doesn\u2019t realize that @ylecun moved over to my side of this argument.\n\nTech bros don\u2019t seem to realize that, either \ud83e\udd37\u200d\u2642\ufe0f\n\nGiven vast datasets, LLMs approximate well, but their understanding is at best superficial. That\u2019s *why* they are unreliable, and unstable,  hallucinate, are constitutionally unable to fact check, etc.\n\nAny time @geoffreyhinton wants to debate this publicly, instead of just taking potshots, I am here for it.",
        "name": "Gary Marcus",
        "photo": "https://pbs.twimg.com/profile_images/1749047536361586688/N1p9EZpc_normal.jpg",
        "reply_count": 72,
        "retweet_count": 46,
        "view_count": 112225,
        "like_count": 387
    },
    "1754439023551213845": {
        "content": "Don't mess with the Godfather. Geoffrey Hinton savages Gary Marcus https://t.co/RKCf95U4oo",
        "name": "Tsarathustra",
        "photo": "https://pbs.twimg.com/profile_images/1690941803200208896/PRpYEDXP_normal.jpg",
        "reply_count": 134,
        "retweet_count": 233,
        "view_count": 643335,
        "like_count": 1507
    },
    "1754334655405326482": {
        "content": "Repeat After Me\n\nTransformers are Better than State Space Models at Copying\n\npaper page: https://t.co/8sEJUv5IUZ\n\nTransformers are the dominant architecture for sequence modeling, but there is growing interest in models that use a fixed-size latent state that does not depend on the sequence length, which we refer to as \"generalized state space models\" (GSSMs). In this paper we show that while GSSMs are promising in terms of inference-time efficiency, they are limited compared to transformer models on tasks that require copying from the input context. We start with a theoretical analysis of the simple task of string copying and prove that a two layer transformer can copy strings of exponential length while GSSMs are fundamentally limited by their fixed-size latent state. Empirically, we find that transformers outperform GSSMs in terms of efficiency and generalization on synthetic tasks that require copying the context. Finally, we evaluate pretrained large language models and find that transformer models dramatically outperform state space models at copying and retrieving information from context. Taken together, these results suggest a fundamental gap between transformers and GSSMs on tasks of practical interest.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 18,
        "retweet_count": 88,
        "view_count": 136871,
        "like_count": 700
    },
    "1753841566144180289": {
        "content": "https://t.co/FXTUCBjWnv",
        "name": "Shengwu Li",
        "photo": "https://pbs.twimg.com/profile_images/1161766928354070529/aFKscvCf_normal.jpg",
        "reply_count": 124,
        "retweet_count": 594,
        "view_count": 1024913,
        "like_count": 6986
    },
    "1753819728240341464": {
        "content": "Interesting results in this paper\u2026 they showed expanding the vocabulary of llama for multilingual fine tuning results in a worse model. Surprisingly they even outperformed a Chinese llama that was trained on 60x the data?! https://t.co/kv87G3dNCS",
        "name": "anton",
        "photo": "https://pbs.twimg.com/profile_images/1678598826544734210/Z8ZMuiAR_normal.jpg",
        "reply_count": 13,
        "retweet_count": 14,
        "view_count": 21119,
        "like_count": 187
    },
    "1753497800447594603": {
        "content": "TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities. Learn more \u2192 https://t.co/U1OctNPZET https://t.co/geLWSRzSZB",
        "name": "Google AI",
        "photo": "https://pbs.twimg.com/profile_images/993649592422907904/yD7LkqU2_normal.jpg",
        "reply_count": 25,
        "retweet_count": 240,
        "view_count": 123120,
        "like_count": 872
    },
    "1753424518171738194": {
        "content": "LLMs for Mathematical Reasoning\n\nIntroduces an overview of research developments in LLMs for mathematical reasoning. \n\nDiscusses advancements, capabilities, limitations, and applications to inspire ongoing research on LLMs for Mathematics. https://t.co/KTRIastE62",
        "name": "elvis",
        "photo": "https://pbs.twimg.com/profile_images/939313677647282181/vZjFWtAn_normal.jpg",
        "reply_count": 5,
        "retweet_count": 148,
        "view_count": 49581,
        "like_count": 566
    },
    "1753271625649475913": {
        "content": "Apple presents Can Large Language Models Understand Context?\n\npaper page: https://t.co/3eW2vVpcMZ\n\nUnderstanding context is key to understanding human language, an ability which Large Language Models (LLMs) have been increasingly seen to demonstrate to an impressive extent. However, though the evaluation of LLMs encompasses various domains within the realm of Natural Language Processing, limited attention has been paid to probing their linguistic capability of understanding contextual features. This paper introduces a context understanding benchmark by adapting existing datasets to suit the evaluation of generative models. This benchmark comprises of four distinct tasks and nine datasets, all featuring prompts designed to assess the models' ability to understand context. First, we evaluate the performance of LLMs under the in-context learning pretraining scenario. Experimental results indicate that pre-trained dense models struggle with understanding more nuanced contextual features when compared to state-of-the-art fine-tuned models. Second, as LLM compression holds growing significance in both research and real-world applications, we assess the context understanding of quantized models under in-context-learning settings. We find that 3-bit post-training quantization leads to varying degrees of performance reduction on our benchmark. We conduct an extensive analysis of these scenarios to substantiate our experimental results.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 1,
        "retweet_count": 75,
        "view_count": 38321,
        "like_count": 339
    },
    "1753263969337291133": {
        "content": "Google presents Efficient Exploration for LLMs\n\npaper page: https://t.co/rFc0MzPMbE\n\npresent evidence of substantial benefit from efficient exploration in gathering human feedback to improve large language models. In our experiments, an agent sequentially generates queries while fitting a reward model to the feedback received. Our best-performing agent generates queries using double Thompson sampling, with uncertainty represented by an epistemic neural network. Our results demonstrate that efficient exploration enables high levels of performance with far fewer queries. Further, both uncertainty estimation and the choice of exploration scheme play critical roles.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 8,
        "retweet_count": 94,
        "view_count": 52383,
        "like_count": 400
    },
    "1753131726552064218": {
        "content": "Shipped an upgraded &amp; cheaper GPT-3.5 Turbo in the API:",
        "name": "Greg Brockman",
        "photo": "https://pbs.twimg.com/profile_images/1347621377503711233/bHg3ipfD_normal.jpg",
        "reply_count": 38,
        "retweet_count": 89,
        "view_count": 160225,
        "like_count": 1061
    },
    "1753121660004401275": {
        "content": "New GPT-3.5 Turbo model with lower pricing is now live! \ud83e\udee1",
        "name": "OpenAI Developers",
        "photo": "https://pbs.twimg.com/profile_images/1720598745664958465/TYA_2LYQ_normal.png",
        "reply_count": 32,
        "retweet_count": 91,
        "view_count": 260458,
        "like_count": 781
    },
    "1753104826458865941": {
        "content": "\"No, senator. Again, I'm Singaporean.\"\n\nUS senator Tom Cotton repeatedly asks TikTok's Singaporean CEO Shou Zi Zhou if he has ties to China. Bosses of four other social media companies are questioned alongside Zhou at a Senate hearing on online safety for children. https://t.co/k7L9SlWeso",
        "name": "Channel 4 News",
        "photo": "https://pbs.twimg.com/profile_images/875404558528393216/cTknVhwm_normal.jpg",
        "reply_count": 371,
        "retweet_count": 409,
        "view_count": 646246,
        "like_count": 2408
    },
    "1753097724239737040": {
        "content": "Can LLMs be trusted for evaluation \ud83e\udd14?\n\nExisting meta-evaluation methods to assess the reliability of LLM-based evaluators are often limited by the coverage of existing benchmarks and require extensive human annotation.\n\nWe introduce ScaleEval, a scalable, agent-debate-assisted meta-evaluation framework to assist human annotators in conducting meta-evaluation. \n\nPaper \ud83d\udcc4: https://t.co/mMyynxUXSn\nCode \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb: https://t.co/1dQKLlLMwo\n(1/n)",
        "name": "Steffi Chern",
        "photo": "https://pbs.twimg.com/profile_images/1684105484255772679/UOGol0G2_normal.jpg",
        "reply_count": 2,
        "retweet_count": 38,
        "view_count": 31352,
        "like_count": 169
    },
    "1752993130671227238": {
        "content": "In October \u201823, @stateofaireport reached its 5th anniversary. \n\nWith 934 slides over 6 editions serving as a historical document, we\u2019re opening 2024 with a retrospective of the main storylines, what we predicted, and what we didn't. \n\nWelcome to the State of the State of AI. \ud83e\uddf5 https://t.co/UC0MtInCpM",
        "name": "Nathan Benaich",
        "photo": "https://pbs.twimg.com/profile_images/1860887094/2564_517540442680_3904369_31246376_1912207_n_normal.jpg",
        "reply_count": 8,
        "retweet_count": 95,
        "view_count": 68723,
        "like_count": 321
    },
    "1753080417530318872": {
        "content": "Accelerating the Science of Language Models\n\nThis is huge! \n\n@allen_ai just released its first Open Language Model (OLMo), a 7B parameter model. \n\nIt includes open training code, open data, full model weights, evaluation code, and fine-tuning code. \n\nIt shows strong performance on many generative tasks. \n\nThere is also a smaller version of it, OLMo 1B.\n\nI will be writing a complete prompting guide for this. Stay tuned!\n\nThis is brilliant work and will ignite even more research opportunities for the AI community.",
        "name": "elvis",
        "photo": "https://pbs.twimg.com/profile_images/939313677647282181/vZjFWtAn_normal.jpg",
        "reply_count": 13,
        "retweet_count": 264,
        "view_count": 97000,
        "like_count": 1121
    },
    "1753072249459081599": {
        "content": "OLMo is here! And it\u2019s 100% open. \n\nIt\u2019s a state-of-the-art LLM and we are releasing it with all pre-training data and code. Let\u2019s get to work on understanding the science behind LLMs. Learn more about the framework and how to access it here:\nhttps://t.co/utvPpWwJIp https://t.co/65Rt9dDHt2",
        "name": "Allen Institute for AI",
        "photo": "https://pbs.twimg.com/profile_images/1191417163648626688/Ylny0kyT_normal.jpg",
        "reply_count": 29,
        "retweet_count": 356,
        "view_count": 351140,
        "like_count": 1434
    },
    "1752892317277556976": {
        "content": "Meta presents Efficient Tool Use with Chain-of-Abstraction Reasoning\n\nhttps://t.co/lHzwJgf0dw\n\nIn mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average ~6% absolute QA accuracy improvement. LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 0,
        "retweet_count": 62,
        "view_count": 32425,
        "like_count": 295
    },
    "1752758698991354317": {
        "content": "We are building an early warning system for LLMs being capable of assisting in biological threat creation. Current models turn out to be, at most, mildly useful for this kind of misuse, and we will continue evolving our evaluation blueprint for the future. https://t.co/WX54iYuOMw",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 173,
        "retweet_count": 347,
        "view_count": 626232,
        "like_count": 1920
    },
    "1752737462663684344": {
        "content": "An over-enthusiastic employee of one of our early access customers leaked a quantised (and watermarked) version of an old model we trained and distributed quite openly.\n\nTo quickly start working with a few selected customers, we retrained this model from Llama 2 the minute we got access to our entire cluster \u2014 the pretraining finished on the day of Mistral 7B release.\n\nWe've made good progress since \u2014 stay tuned!",
        "name": "Arthur Mensch",
        "photo": "https://pbs.twimg.com/profile_images/1670440736389582849/sJUeK3n-_normal.jpg",
        "reply_count": 64,
        "retweet_count": 178,
        "view_count": 638818,
        "like_count": 1678
    },
    "1752531574568972775": {
        "content": "Weak-to-Strong Jailbreaking on Large Language Models\n\npaper page: https://t.co/2I5Wz3ocqs\n\nAlthough significant efforts have been dedicated to aligning large language models (LLMs), red-teaming reports suggest that these carefully aligned LLMs could still be jailbroken through adversarial prompts, tuning, or decoding. Upon examining the jailbreaking vulnerability of aligned LLMs, we observe that the decoding distributions of jailbroken and aligned models differ only in the initial generations. This observation motivates us to propose the weak-to-strong jailbreaking attack, where adversaries can utilize smaller unsafe/aligned LLMs (e.g., 7B) to guide jailbreaking against significantly larger aligned LLMs (e.g., 70B). To jailbreak, one only needs to additionally decode two smaller LLMs once, which involves minimal computation and latency compared to decoding the larger LLMs. The efficacy of this attack is demonstrated through experiments conducted on five models from three different organizations. Our study reveals a previously unnoticed yet efficient way of jailbreaking, exposing an urgent safety issue that needs to be considered when aligning LLMs. As an initial attempt, we propose a defense strategy to protect against such attacks, but creating more advanced defenses remains challenging.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 4,
        "retweet_count": 47,
        "view_count": 99063,
        "like_count": 197
    },
    "1752281504728707076": {
        "content": "\ud83e\uddf5/ We\u2019ve examined headline voting intention from 14,000 voters over the last 3 months to take a detailed look at voting demographics as we head towards the likely 2024 general election\n\nhttps://t.co/ynHwPPtQbF https://t.co/CzHLiICMWT",
        "name": "YouGov",
        "photo": "https://pbs.twimg.com/profile_images/1488782700886511618/uIN1vuUt_normal.jpg",
        "reply_count": 151,
        "retweet_count": 376,
        "view_count": 828955,
        "like_count": 1237
    },
    "1752316716212683034": {
        "content": "Today I learned that a Kaggle competitions grandmaster was unable to get even to the screening interview stage for a low-level AI position at Google, the parent company of Kaggle. I am sure they will select a candidate who can perfectly sort a linked list on a whiteboard. And that, in a nutshell, is why I think that the job screening process in tech is absolutely f***ed up.",
        "name": "Bojan Tunguz",
        "photo": "https://pbs.twimg.com/profile_images/1364232665440935946/cRy6WUM9_normal.jpg",
        "reply_count": 151,
        "retweet_count": 236,
        "view_count": 852542,
        "like_count": 2931
    },
    "1752098121826361453": {
        "content": "Cohere reranking is seriously good\n\nToday, I expanded the RAG reranking tests that I'm running to include Cohere.\n\nOveral Test:  \n\u2022 Reranking Airbnb's 10-K, as before\n\nReranking Speeds:\n\u2022 0.24 secs for Cohere\n\u2022 1.04 secs for ColBERT \n\u2022 25.47 secs for GPT-4 Turbo \n\u2022 50.94 secs for mistral-medium\n\nReranking quality for top-1 results was consistent across the four models.\n\nBrilliant by the team at @cohere",
        "name": "virat",
        "photo": "https://pbs.twimg.com/profile_images/1237964548704841736/iai1MNLE_normal.jpg",
        "reply_count": 19,
        "retweet_count": 60,
        "view_count": 89108,
        "like_count": 390
    },
    "1752301119676784777": {
        "content": "(1/5)\ud83d\ude80 Our OpenMoE Paper is out! \ud83d\udcc4 Including:\n\n\ud83d\udd0dALL Checkpoints\n\ud83d\udcca In-depth MoE routing analysis\n\ud83e\udd2fLearning from mistakes & solutions \n\nThree important findings:\n(1) Context-Independent Specialization;\n(2) Early Routing Learning;\n(3) Drop-towards-the-End.\n\nPaper Link: https://t.co/zCZhlBbKMC",
        "name": "Fuzhao Xue",
        "photo": "https://pbs.twimg.com/profile_images/1734575225671487488/7043wqJE_normal.jpg",
        "reply_count": 5,
        "retweet_count": 106,
        "view_count": 73467,
        "like_count": 518
    },
    "1752170730907680862": {
        "content": "MoE-LLaVA\n\nMixture of Experts for Large Vision-Language Models\n\ndemo: https://t.co/3J5CAKS5QW\npaper page: https://t.co/5jVfT5eSTq\n\nwith just 3 billion sparsely activated parameters, MoE-LLaVA demonstrates performance comparable to the LLaVA-1.5-7B on various visual understanding datasets and even surpasses the LLaVA-1.5-13B in object hallucination benchmarks.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 4,
        "retweet_count": 114,
        "view_count": 41377,
        "like_count": 504
    },
    "1752013879532782075": {
        "content": "Today we\u2019re releasing Code Llama 70B: a new, more performant version of our LLM for code generation \u2014 available under the same license as previous Code Llama models.\n\nDownload the models \u27a1\ufe0f https://t.co/GApdj5PW83\n\u2022 CodeLlama-70B\n\u2022 CodeLlama-70B-Python\n\u2022 CodeLlama-70B-Instruct",
        "name": "AI at Meta",
        "photo": "https://pbs.twimg.com/profile_images/1454145678075117568/2qXqM_Cu_normal.png",
        "reply_count": 174,
        "retweet_count": 1226,
        "view_count": 875116,
        "like_count": 5781
    },
    "1751656971126587531": {
        "content": "The Top ML Papers of the Week (Jan 22 - Jan 28):\n\n- WARM\n- Medusa\n- AgentBoard\n- MambaByte\n- Knowledge Fusion of LLMs\n- Resource-efficient LLMs &amp; Multimodal Models\n...",
        "name": "DAIR.AI",
        "photo": "https://pbs.twimg.com/profile_images/1643277398522187778/31dedbLo_normal.jpg",
        "reply_count": 3,
        "retweet_count": 78,
        "view_count": 57469,
        "like_count": 382
    },
    "1751801040066719953": {
        "content": "Google presents Learning Universal Predictors\n\npaper page: https://t.co/8MyIUdppBg\n\nMeta-learning has emerged as a powerful approach to train neural networks to learn new tasks quickly from limited data. Broad exposure to different tasks leads to versatile representations enabling general problem solving. But, what are the limits of meta-learning? In this work, we explore the potential of amortizing the most powerful universal predictor, namely Solomonoff Induction (SI), into neural networks via leveraging meta-learning to its limits. We use Universal Turing Machines (UTMs) to generate training data used to expose networks to a broad range of patterns. We provide theoretical analysis of the UTM data generation processes and meta-training protocols. We conduct comprehensive experiments with neural architectures (e.g. LSTMs, Transformers) and algorithmic data generators of varying complexity and universality. Our results suggest that UTM data is a valuable resource for meta-learning, and that it can be used to train neural networks capable of learning universal prediction strategies.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 2,
        "retweet_count": 94,
        "view_count": 55659,
        "like_count": 466
    },
    "1751837962738827378": {
        "content": "In case you are out of the loop:\n\n\ud835\ude96\ud835\ude92\ud835\ude9c\ud835\ude9d\ud835\ude9b\ud835\ude8a\ud835\ude95-\ud835\ude96\ud835\ude8e\ud835\ude8d\ud835\ude92\ud835\ude9e\ud835\ude96 might have been leaked.\n(or we are all trolled by 4chan)\n\nWhy is this big?\n\n\ud835\ude96\ud835\ude92\ud835\ude9c\ud835\ude9d\ud835\ude9b\ud835\ude8a\ud835\ude95-\ud835\ude96\ud835\ude8e\ud835\ude8d\ud835\ude92\ud835\ude9e\ud835\ude96 is the best LLM ever after GPT-4\n\nEverything is all still ongoing, people are benchmarking this model right now.\n\nBut so far it seems to be generating VERY similar texts to what you get by mistral's endpoint.\n\nLet's see.\n\n---\nLinks:\n\n- Model: https://t.co/b1Aav5lyde\n\n- 4chan thread: https://t.co/ln8Y9lxugE\n\nOriginal thread starting the investigation by \n@JagersbergKnut here: https://t.co/1JiUBm10ha\n\nSome investigation into the weights by @nisten here: https://t.co/ODp46wpS0l",
        "name": "Yam Peleg",
        "photo": "https://pbs.twimg.com/profile_images/1505912788031623170/GC7LMHNp_normal.jpg",
        "reply_count": 21,
        "retweet_count": 74,
        "view_count": 126569,
        "like_count": 667
    },
    "1751796334531592496": {
        "content": "Microsoft presents SliceGPT\n\nCompress Large Language Models by Deleting Rows and Columns\n\npaper page: https://t.co/Mxf445SAnu\n\nshow that SliceGPT can remove up to 25% of the model parameters (including embeddings) for LLAMA2-70B, OPT 66B and Phi-2 models while maintaining 99%, 99% and 90% zero-shot task performance of the dense model respectively. Our sliced models run on fewer GPUs and run faster without any additional code optimization: on 24GB consumer GPUs we reduce the total compute for inference on LLAMA2-70B to 64% of that of the dense model; on 40GB A100 GPUs we reduce it to 66%. We offer a new insight, computational invariance in transformer networks, which enables SliceGPT and we hope it will inspire and enable future avenues to reduce memory and computation demands for pre-trained models.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 12,
        "retweet_count": 170,
        "view_count": 99221,
        "like_count": 857
    },
    "1751550686553071823": {
        "content": "This is not normal.",
        "name": "James O'Brien",
        "photo": "https://pbs.twimg.com/profile_images/1676524106785726464/vWqHYTHm_normal.jpg",
        "reply_count": 1776,
        "retweet_count": 7109,
        "view_count": 2023298,
        "like_count": 27931
    },
    "1751543810209771631": {
        "content": "Laura Kuenssberg after finishing her interview with a Tory MP and Laura Kuenssberg after finishing her interview with a Labour MP\u2026\n\n#bbclaurak https://t.co/Z0tYKXQVWh",
        "name": "David",
        "photo": "https://pbs.twimg.com/profile_images/659855570862792705/OlzAoKnS_normal.jpg",
        "reply_count": 852,
        "retweet_count": 3528,
        "view_count": 3106210,
        "like_count": 10410
    },
    "1751575754201014297": {
        "content": "Last night on the London underground.. https://t.co/Xfv7PgM9SZ",
        "name": "London & UK Street News",
        "photo": "https://pbs.twimg.com/profile_images/1591070792393039874/FOQ1dPI-_normal.jpg",
        "reply_count": 1476,
        "retweet_count": 984,
        "view_count": 7891109,
        "like_count": 7399
    },
    "1750773579220709638": {
        "content": "A strong political divide is emerging between young men and women in many countries:\nhttps://t.co/kPY21noAt8 https://t.co/5KDhYkxIEQ",
        "name": "Dina D. Pomeranz \ud83d\udfe3",
        "photo": "https://pbs.twimg.com/profile_images/1230603211226177552/kaqj_FJK_normal.jpg",
        "reply_count": 437,
        "retweet_count": 2382,
        "view_count": 4731934,
        "like_count": 5943
    },
    "1750567140997108219": {
        "content": "Our research on \u2018Almanac: Retrieval Augmented LLMs for Clinical Medicine\u2019 is finally out on @NEJM_AI! We demonstrate that LLMs augmented with tools (browser, calculators) outperform ChatGPT-4 &amp; others on a novel dataset of 300+ questions assessed by board-certified physicians!",
        "name": "Cyril Zakka, MD",
        "photo": "https://pbs.twimg.com/profile_images/1583657504147267584/sOWrPqkJ_normal.jpg",
        "reply_count": 6,
        "retweet_count": 25,
        "view_count": 23261,
        "like_count": 108
    },
    "1749979780122804485": {
        "content": "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding\n\npaper page: https://t.co/zUscjKIz5y\n\nintroduce meta-prompting, an effective scaffolding technique designed to enhance the functionality of language models (LMs). This approach transforms a single LM into a multi-faceted conductor, adept at managing and integrating multiple independent LM queries. By employing high-level instructions, meta-prompting guides the LM to break down complex tasks into smaller, more manageable subtasks. These subtasks are then handled by distinct \"expert\" instances of the same LM, each operating under specific, tailored instructions. Central to this process is the LM itself, in its role as the conductor, which ensures seamless communication and effective integration of the outputs from these expert models. It additionally employs its inherent critical thinking and robust verification processes to refine and authenticate the end result. This collaborative prompting approach empowers a single LM to simultaneously act as a comprehensive orchestrator and a panel of diverse experts, significantly enhancing its performance across a wide array of tasks. The zero-shot, task-agnostic nature of meta-prompting greatly simplifies user interaction by obviating the need for detailed, task-specific instructions. Furthermore, our research demonstrates the seamless integration of external tools, such as a Python interpreter, into the meta-prompting framework, thereby broadening its applicability and utility. Through rigorous experimentation with GPT-4, we establish the superiority of meta-prompting over conventional scaffolding methods: When averaged across all tasks, including the Game of 24, Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented with a Python interpreter functionality, surpasses standard prompting by 17.1%, expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 2,
        "retweet_count": 22,
        "view_count": 26340,
        "like_count": 146
    },
    "1750235992559173914": {
        "content": "Imagine \"untraining\" a Large Language Model on specific content.\n\nThe New York Times doesn't want its content in ChatGPT. OpenAI would have to retrain its models from scratch. Removing any content from their models would cost them millions of dollars.\n\nI just read a new paper from Microsoft Research that tries to fix this. This is the only study I've found so far that's looking into making models forget. \n\nThe paper proposes a process that makes a model forget about Harry Potter without retraining it from scratch.\n\nIt's a proof of concept. The researchers aren't sure whether their solution generalizes to other topics. It's a first step, but it's cool nonetheless.\n\nWhat they did is kind of a hack, but I like it:\n\nThey fine-tuned the model using a dataset containing the original Harry Potter text as the input tokens and some generic labels as targets. They pre-generate these generic labels. For example, instead of using \"Harry,\" they use \"Jack,\" and instead of using \"Hermione,\" they use \"her.\"\n\nIn other words, they don't actually delete knowledge from the model. They overwrite it.\n\nAs we start using these models everywhere, the ability to forget information will become critical.\n\nLet's see how much progress we make this year on this.\n\nYou'll find a link to the paper in the image ALT.",
        "name": "Santiago",
        "photo": "https://pbs.twimg.com/profile_images/1581385027757264898/j5GjtUiq_normal.jpg",
        "reply_count": 137,
        "retweet_count": 362,
        "view_count": 370752,
        "like_count": 1911
    },
    "1748680995350470774": {
        "content": "Meet the UK\u2019s first laser weapon: DragonFire \n\nUK military scientists have for the first time shot down drones by using the laser to cut through incoming targets at the speed of light.\n\nCapable of being fitted to future warships, it will be a vital British weapon as the threat of drone warfare grows.\n\nDragonFire is just one of the potentially revolutionary capabilities we\u2019re investing in to gain an advantage against our enemies.",
        "name": "Rt Hon Grant Shapps MP",
        "photo": "https://pbs.twimg.com/profile_images/1604158037522087938/7Oec6fFe_normal.jpg",
        "reply_count": 3513,
        "retweet_count": 1614,
        "view_count": 12938149,
        "like_count": 12774
    },
    "1748034519104450874": {
        "content": "Parcel delivery firm DPD have replaced their customer service chat with an AI robot thing. It\u2019s utterly useless at answering any queries, and when asked, it happily produced a poem about how terrible they are as a company. It also swore at me. \ud83d\ude02 https://t.co/vjWlrIP3wn",
        "name": "Ashley Beauchamp",
        "photo": "https://pbs.twimg.com/profile_images/1393588397281792002/a0N9bbDP_normal.jpg",
        "reply_count": 693,
        "retweet_count": 5211,
        "view_count": 2217696,
        "like_count": 28311
    },
    "1748302834070618610": {
        "content": "The Daily Mail on Kate Middleton being hospitalized is honestly one of the most mental pieces of journalism I've ever read. https://t.co/M5FVPgQ2YC",
        "name": "Patrick Dalton",
        "photo": "https://pbs.twimg.com/profile_images/1666432077393166336/-Tqf-SVW_normal.jpg",
        "reply_count": 1656,
        "retweet_count": 3476,
        "view_count": 3837531,
        "like_count": 30513
    },
    "1748043513156272416": {
        "content": "Prompt engineering (or rather \"Flow engineering\") intensifies for code generation. Great reading and a reminder of how much alpha there is (pass@5 19% to 44%) in moving from a naive prompt:answer paradigm to a \"flow\" paradigm, where the answer is constructed iteratively. https://t.co/FSx9Xd1JCa",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 125,
        "retweet_count": 546,
        "view_count": 765668,
        "like_count": 3321
    },
    "1747971746047627682": {
        "content": "We are one step closer to having AI generate code better than humans!\n\nThere's a new open-source, state-of-the-art code generation tool. It's a new approach that improves the performance of Large Language Models generating code.\n\nThe paper's authors call the process \"AlphaCodium\" and tested it on the CodeContests dataset, which contains around 10,000 competitive programming problems.\n\nThe results put AlphaCodium as the best approach to generate code we've seen. It beats DeepMind's AlphaCode and their new AlphaCode2 without needing to fine-tune a model!\n\nI'm linking to the paper, the GitHub repository, and a blog post below, but let me give you a 10-second summary of how the process works:\n\nInstead of using a single prompt to solve problems, AlphaCodium relies on an iterative process that repeatedly runs and fixes the generated code using the testing data.\n\n1. The first step is to have the model reason about the problem. They describe it using bullet points and focus on the goal, inputs, outputs, rules, constraints, and any other relevant details.\n\n2. Then, they make the model reason about the public tests and come up with an explanation of why the input leads to that particular output.\n\n3. The model generates two to three potential solutions in text and ranks them in terms of correctness, simplicity, and robustness.\n\n4. Then, it generates more diverse tests for the problem, covering cases not part of the original public tests.\n\n5. Iteratively, pick a solution, generate the code, and run it on a few test cases. If the tests fail, improve the code and repeat the process until the code passes every test.\n\nThere's a lot more information in the paper and the blog post. Here are the links:\n\n\u2022 Paper: https://t.co/OFzeRGIYvz\n\u2022 Blog: https://t.co/3BiAfpTFA2\n\u2022 Code: https://t.co/rcGwx220lM\n\nI attached an image comparing AlphaCodium with direct prompting using different models.\n\n2024 has barely started, and we are making a ton of progress!",
        "name": "Santiago",
        "photo": "https://pbs.twimg.com/profile_images/1581385027757264898/j5GjtUiq_normal.jpg",
        "reply_count": 70,
        "retweet_count": 423,
        "view_count": 814625,
        "like_count": 2350
    },
    "1747351832949928047": {
        "content": "\ud83c\udf89Happy to share 2 papers accepted to #ICLR2024 w/ @hbXNov @siyan_zhao @adityagrover_ !\n\n1) Peering Through Preferences: Unraveling Feedback Acquisition for Aligning LLMs: https://t.co/gYQYbU7gu3\n2) Group Preference Optimization: Few-Shot Alignment of LLMs https://t.co/n04JyKzYg1 https://t.co/19cr9HXLgf",
        "name": "John Dang",
        "photo": "https://pbs.twimg.com/profile_images/1405006946806026243/owN-tzqZ_normal.jpg",
        "reply_count": 3,
        "retweet_count": 8,
        "view_count": 20855,
        "like_count": 76
    },
    "1747303434234036557": {
        "content": "Not all #AI is the same. Each of the 3 epochs of AI offer unique strengths, weaknesses, and challenges. Understanding how to work with AI is a necessary step toward mastering the ways to advance healthcare with AI's help.\n\nRead more in @JAMA \ud83d\udc49https://t.co/KUNHzcWgHp https://t.co/g0DpcvUiya",
        "name": "Google Health",
        "photo": "https://pbs.twimg.com/profile_images/1214221958063304706/oshhf5T5_normal.jpg",
        "reply_count": 1,
        "retweet_count": 9,
        "view_count": 4470,
        "like_count": 49
    },
    "1747403789177585849": {
        "content": "Our paper just got into ICLR 2024! Great work leading it from @FredZhang0\n\nActivation patching is a widely used tool in mech interp, but seemingly every paper invents their own variant. We systematically studied these variants, and tried to recommend best practices",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 1,
        "retweet_count": 6,
        "view_count": 8802,
        "like_count": 100
    },
    "1707552376142602317": {
        "content": "Activation patching (AP) is a standard tool in LM interpretability, esp circuit analysis.\n\nIt has multiple degrees of freedom, but the literature has little consensus on them.\n\nOur new work systematically studies these, and works towards best practices. https://t.co/qWgjaUWq91",
        "name": "Fred Zhang",
        "photo": "https://pbs.twimg.com/profile_images/1676628056000086016/qGcAUE7D_normal.jpg",
        "reply_count": 4,
        "retweet_count": 15,
        "view_count": 28610,
        "like_count": 114
    },
    "1746946080628195770": {
        "content": "# Portrayals of AI\nPeople sometimes read a bit too specifically into my bio \"Building a kind of JARVIS\". \n\nI name JARVIS in general terms only, as one of my favorite popular portrayals of an AI - a helpful, conversational, empowering e/ia automation. An aid against evil and entropy.\n\nIn personality, I much prefer and love TARS from Interstellar. I love that TARS is funny, quirky, and sarcastic. But you can tone down that down to \"dry\" if you like. That said TARS (with a few major and notable exceptions) is portrayed a bit too much like a comic relief sidekick instead of a pervasive, helpful and active problem solver.\n\nThe movie that best explores emotional depth and connection with an AI is undoubtedly Samantha from Her. I find this to be a very prescient movie because not too long ago, AIs have been thought of and portrayed as primarily highly calculating and logical entities incapable of understanding human emotion (think: Star Trek et al.). I think it's becoming very clear today that these will turn out very wrong, and that the future looks a lot more like Samantha from Her than Data from Star Trek.\n\nThe movie that most touches on the creative dimension of AI is maybe Sonny from iRobot, but in general I think this dimension is dramatically underexplored territory.\n\nHonorable mentions\nMy most favorite unaligned AI is, of course, GLaDOS :) And sticking with Valve for a moment, shoutout to Dog from Half Life 2.\nI also recall really enjoying Legion of the geth in the Mass Effect series.\n\nSo TLDR all of these have aspects that feel right and desirable - a blend of personality of TARS, a creativity of Sonny, the emotional capability of Her, and the technical problem solving capability of JARVIS.\n\nCurious what are people's favorite portrayals of AI and why?",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 319,
        "retweet_count": 164,
        "view_count": 393755,
        "like_count": 1976
    },
    "1745921205020799433": {
        "content": "I touched on the idea of sleeper agent LLMs at the end of my recent video, as a likely major security challenge for LLMs (perhaps more devious than prompt injection).\n\nThe concern I described is that an attacker might be able to craft special kind of text (e.g. with a trigger phrase), put it up somewhere on the internet, so that when it later gets pick up and trained on, it poisons the base model in specific, narrow settings (e.g. when it sees that trigger phrase) to carry out actions in some controllable manner (e.g. jailbreak, or data exfiltration). Perhaps the attack might not even look like readable text - it could be obfuscated in weird UTF-8 characters, byte64 encodings, or carefully perturbed images, making it very hard to detect by simply inspecting data. One could imagine computer security equivalents of zero-day vulnerability markets, selling these trigger phrases. \n\nTo my knowledge the above attack hasn't been convincingly demonstrated yet. This paper studies a similar (slightly weaker?) setting, showing that given some (potentially poisoned) model, you can't \"make it safe\" just by applying the current/standard safety finetuning. The model doesn't learn to become safe across the board and can continue to misbehave in narrow ways that potentially only the attacker knows how to exploit. Here, the attack hides in the model weights instead of hiding in some data, so the more direct attack here looks like someone releasing a (secretly poisoned) open weights model, which others pick up, finetune and deploy, only to become secretly vulnerable.\n\nWell-worth studying directions in LLM security and expecting a lot more to follow.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 222,
        "retweet_count": 732,
        "view_count": 873921,
        "like_count": 5112
    },
    "1745854907968880970": {
        "content": "New Anthropic Paper: Sleeper Agents.\n\nWe trained LLMs to act secretly malicious. We found that, despite our best efforts at alignment training, deception still slipped through.\n\nhttps://t.co/mIl4aStR1F https://t.co/qhqvAoohjU",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 130,
        "retweet_count": 582,
        "view_count": 1762206,
        "like_count": 3112
    },
    "1744405133721735222": {
        "content": "I'm hiring research engineers for several alignment/technical safety teams at Anthropic! https://t.co/L3EQJPTKiy",
        "name": "Sam Bowman",
        "photo": "https://pbs.twimg.com/profile_images/1549251621275570177/f4GNUquc_normal.jpg",
        "reply_count": 24,
        "retweet_count": 89,
        "view_count": 127637,
        "like_count": 689
    },
    "1742302545781956900": {
        "content": "nn layers align their singular vectors\n\neach matrix syncs to its neighbor, its rotation neatly clicking into the basis directions of the next rotation.  like two gears precision-machined to be partners\n\nLLMs are swiss watches, ticking in a billion-dimensional pocket universe https://t.co/YMpqeDnY64",
        "name": "cider",
        "photo": "https://pbs.twimg.com/profile_images/1652257498009686017/2Md1Rnza_normal.jpg",
        "reply_count": 4,
        "retweet_count": 20,
        "view_count": 31323,
        "like_count": 321
    },
    "1741971580488409179": {
        "content": "When I count on my fingers, I use binary, so I can count to 31 on one hand, or 1023 on two. It took me about 1 hour to train the muscle memory, and it's very rhythmic, so now my right hand just auto-increments in binary till I'm done, and then I just read off the number. https://t.co/HWXSo7tgqz",
        "name": "Andrew Critch (h/acc)",
        "photo": "https://pbs.twimg.com/profile_images/1552317805902512129/xCrYE-2X_normal.jpg",
        "reply_count": 45,
        "retweet_count": 61,
        "view_count": 140512,
        "like_count": 863
    },
    "1741906261950845364": {
        "content": "FYI: you can count up to 100 on your fingers like so:\n- right hand is ones\n- left hand is tens\n- thumbs are 5/50, fingers are 1/10.\nThis is convenient enough that it's the way I count by default. https://t.co/44hpak9fP6",
        "name": "Daniel Filan \ud83d\udd0e",
        "photo": "https://pbs.twimg.com/profile_images/1681539209952399360/1FgoF99g_normal.jpg",
        "reply_count": 3,
        "retweet_count": 2,
        "view_count": 130230,
        "like_count": 80
    },
    "1742085439027060913": {
        "content": "I came to do my PhD in the UK (and stayed to eventually pay more taxes than 99% of Brits) only because my partner could move with me.\n\nAs a Cambridge academic, I am losing out on great students, top global talent, who choose Germany because they have a partner.",
        "name": "Ferenc Husz\u00e1r",
        "photo": "https://pbs.twimg.com/profile_images/1643333057892556800/x62-vXzj_normal.jpg",
        "reply_count": 47,
        "retweet_count": 271,
        "view_count": 356105,
        "like_count": 1921
    },
    "1741782514270671194": {
        "content": "From today, the majority of foreign university students cannot bring family members to the UK.\n\nIn 2024, we\u2019re already delivering for the British people.",
        "name": "Rishi Sunak",
        "photo": "https://pbs.twimg.com/profile_images/1572638567381307394/AEahAxu5_normal.jpg",
        "reply_count": 12123,
        "retweet_count": 1866,
        "view_count": 26636362,
        "like_count": 7023
    },
    "1741753631538626682": {
        "content": "We are fully committed to seeing a decisive cut in migration.\n\nFrom today, new overseas students will no longer be able to bring family members to the UK.\n\nPostgraduate research or government-funded scholarships students will be exempt. https://t.co/QpwEf9BCfj",
        "name": "Home Office",
        "photo": "https://pbs.twimg.com/profile_images/1724029369935425536/lPv67xGX_normal.jpg",
        "reply_count": 1263,
        "retweet_count": 611,
        "view_count": 4059637,
        "like_count": 1583
    },
    "1741748597723422830": {
        "content": "The world's largest research programme is officially open to the UK\ud83d\udd13\ud83d\udd2c\n\n\ud83c\uddec\ud83c\udde7 Scientists, researchers and businesses can apply for Horizon's 2024 programme - teaming up with European and global partners to lead science globally \ud83c\udf0d\n\nFind out more \ud83d\udc47\nhttps://t.co/Z1hM2nQO5u https://t.co/rZBkrsbALr",
        "name": "Department for Science, Innovation and Technology",
        "photo": "https://pbs.twimg.com/profile_images/1724012013213335552/osSYWB4d_normal.jpg",
        "reply_count": 22,
        "retweet_count": 99,
        "view_count": 79350,
        "like_count": 167
    },
    "1741564729628229973": {
        "content": "As 2023 wraps, I\u2019m reflecting on the Biden-Harris Administration\u2019s accomplishments in climate and clean energy. I\u2019ve been working on this topic for over two decades, and there were always lists of good ideas that somebody should do. A lot of those good ideas, GOT DONE. A thread:",
        "name": "Costa Samaras",
        "photo": "https://pbs.twimg.com/profile_images/1692383475473555456/liUrohsZ_normal.jpg",
        "reply_count": 12,
        "retweet_count": 262,
        "view_count": 144450,
        "like_count": 742
    },
    "1741084584400327105": {
        "content": "This is a genuinely amazing chart\n\nAnd it\u2019s well worth reading @RuxandraTeslo\u2019s piece in full  https://t.co/JIQOar9bEO",
        "name": "John Burn-Murdoch",
        "photo": "https://pbs.twimg.com/profile_images/922511756110557184/IDxUQ_rr_normal.jpg",
        "reply_count": 5,
        "retweet_count": 22,
        "view_count": 92257,
        "like_count": 101
    },
    "1741079374877565137": {
        "content": "Just saw this graph posted by @HenryEOliver that kinda further adds to my point re Britain taking pride in withstanding hardship as opposed to trying to overcome hardship and become prosperous. \n\nUse of \"blitz spirit\" higher now than during the actual blitz https://t.co/k4jwtw0SvL",
        "name": "Ruxandra Teslo \ud83e\uddec",
        "photo": "https://pbs.twimg.com/profile_images/1776598984506667008/oMBKKXts_normal.jpg",
        "reply_count": 14,
        "retweet_count": 25,
        "view_count": 109741,
        "like_count": 122
    },
    "1741229576473457088": {
        "content": "Is there a Whoop or Oura Ring for focus?\n\nI.e., you turn it on during deep work sessions and it measures brain activity associated with focus or something similar?",
        "name": "Jason Carman",
        "photo": "https://pbs.twimg.com/profile_images/1622397524337377281/70WYnaKR_normal.jpg",
        "reply_count": 86,
        "retweet_count": 10,
        "view_count": 187532,
        "like_count": 376
    },
    "1741053014343840247": {
        "content": "'It's a really bad game.'\n\nProf @MarcusduSautoy explains why he's not a fan of Monopoly during his lecture on what makes a good game.\n\n\ud83c\udfac | @OxUniMaths \nhttps://t.co/OARZ0QhsYa",
        "name": "University of Oxford",
        "photo": "https://pbs.twimg.com/profile_images/1763165205020696576/3uRgf_U__normal.jpg",
        "reply_count": 12,
        "retweet_count": 51,
        "view_count": 30822,
        "like_count": 209
    },
    "1740809785619194055": {
        "content": "New Bishop \"Deep Learning\" book is available free at the bottom of this page. \nhttps://t.co/7SDDZYd7So\n\n(Although I bought a copy, because I need to convey gravitas)",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 2,
        "retweet_count": 70,
        "view_count": 49887,
        "like_count": 412
    },
    "1740516470873088348": {
        "content": "The year in AI was WILD. But you already know that, so instead of looking back, I\u2019m looking ahead! I asked AI experts at NeurIPS what they expect in 2024: Predictions include a new crop of more powerful AI tools, less hype about the tech, and more. https://t.co/m5ffMnePGv",
        "name": "Rachel Metz",
        "photo": "https://pbs.twimg.com/profile_images/1737735045522370560/5Um5bVq7_normal.jpg",
        "reply_count": 3,
        "retweet_count": 13,
        "view_count": 23467,
        "like_count": 53
    },
    "1740514663711031562": {
        "content": "i\u2019m curious about effective altruism: how do so many smart people with the goal \u201cdo good for the world\u201d wind up with the subgoal \u201canalyze the neurons of GPT-2 small\u201d or something similar?",
        "name": "jack morris",
        "photo": "https://pbs.twimg.com/profile_images/1500863924413022213/QkzKVSND_normal.jpg",
        "reply_count": 45,
        "retweet_count": 11,
        "view_count": 97016,
        "like_count": 319
    },
    "1740288086624669742": {
        "content": "AirLLM make 8GB MacBook run 70B https://t.co/uxZW25M94l",
        "name": "Rohan Paul",
        "photo": "https://pbs.twimg.com/profile_images/1715475762516840448/kst_-vG1_normal.jpg",
        "reply_count": 15,
        "retweet_count": 94,
        "view_count": 140547,
        "like_count": 787
    },
    "1739935401668694407": {
        "content": "We\u2019ve removed burdensome bottle size restrictions for 900 British wine makers \ud83c\udf7e\n\nAnd consumers will benefit from improved choice \ud83d\ude4c\n\nRead more \ud83d\udc49 https://t.co/NVECJWdaht https://t.co/3xDEWdh1am",
        "name": "Department for Business and Trade",
        "photo": "https://pbs.twimg.com/profile_images/1724105517226737664/D3hfB3n8_normal.jpg",
        "reply_count": 4722,
        "retweet_count": 89,
        "view_count": 3626689,
        "like_count": 254
    },
    "1740199739206070574": {
        "content": "One of the best lectures to watch on LLMs, well worth the 80 minutes \u2014 by @rao2z.",
        "name": "Omar Khattab",
        "photo": "https://pbs.twimg.com/profile_images/1613558765764374528/aZQB6U4b_normal.jpg",
        "reply_count": 4,
        "retweet_count": 9,
        "view_count": 17334,
        "like_count": 75
    },
    "1726962530143412641": {
        "content": "\ud83d\udce2 ICYMI, here is the video of the keynote talk I gave last Friday at @SCAI_ASU's #AI day titled \"Can LLMs Really Reason & Plan?\". It is the most comprehensive of my talks on the topic to-date. Slides are available with the video.\n\nhttps://t.co/9IkakLsaZo",
        "name": "Subbarao Kambhampati (\u0c15\u0c02\u0c2d\u0c02\u0c2a\u0c3e\u0c1f\u0c3f \u0c38\u0c41\u0c2c\u0c4d\u0c2c\u0c3e\u0c30\u0c3e\u0c35\u0c41)",
        "photo": "https://pbs.twimg.com/profile_images/1240088892751007745/zFdWaIFe_normal.jpg",
        "reply_count": 4,
        "retweet_count": 43,
        "view_count": 58291,
        "like_count": 194
    },
    "1740076296833785923": {
        "content": "@campbellclaret @RestIsPolitics @RoryStewartUK https://t.co/sRg2h7HcqG",
        "name": "Getting Britain Moving",
        "photo": "https://pbs.twimg.com/profile_images/1710592995383255041/e_x24YTB_normal.jpg",
        "reply_count": 1,
        "retweet_count": 0,
        "view_count": 2641,
        "like_count": 5
    },
    "1738575020727640550": {
        "content": "Check it out! Mystery AI Hype Theater 3000 now has its own web page:\n\nhttps://t.co/xUm97HEkpE\n\nNew episodes to come in 2024 :)\n\nw/ @alexhanna; production by @ctaylsaurus",
        "name": "@emilymbender@dair-community.social on Mastodon",
        "photo": "https://pbs.twimg.com/profile_images/952722635305009152/5E-c0x1C_normal.jpg",
        "reply_count": 4,
        "retweet_count": 18,
        "view_count": 16998,
        "like_count": 55
    },
    "1740326754617614736": {
        "content": "Air conditioning makes up 70 per cent of Gulf states electricity consumption, 97 per cent of which is generated from oil and gas.\nhttps://t.co/rKed1BSmDL",
        "name": "Chatham House",
        "photo": "https://pbs.twimg.com/profile_images/1214140568877576192/Om8GlbSo_normal.jpg",
        "reply_count": 0,
        "retweet_count": 9,
        "view_count": 4138,
        "like_count": 13
    },
    "1740288384835445233": {
        "content": "Really interesting to see this narrative emerge when productivity stopped growing before the implementation of austerity and is primarily observed in the private, not public sector",
        "name": "\ud83e\udd51\ud83d\uddfd\ud83c\udfd7\ud83c\udfd8\ufe0f Na\u2082Ca(CO\u2083)\u2082\u20225H\u2082O",
        "photo": "https://pbs.twimg.com/profile_images/1768799131055616000/DD7_JfHU_normal.jpg",
        "reply_count": 22,
        "retweet_count": 16,
        "view_count": 116149,
        "like_count": 258
    },
    "1740255135782351046": {
        "content": "George Osborne\u2019s Austerity and the rest of the Tory party destroyed the UK economy and the productive capacity of its working people. There is no argument against it. https://t.co/hLhpGLfCNb",
        "name": "Shiv Malik",
        "photo": "https://pbs.twimg.com/profile_images/1750549978823430144/cTOWRiXB_normal.jpg",
        "reply_count": 98,
        "retweet_count": 478,
        "view_count": 369938,
        "like_count": 1411
    },
    "1740174122850930979": {
        "content": "Hey @DailyMailUK I've updated your graph which shows that it was a spectacular miscalculation to publish it! https://t.co/1iyEzlNGYI",
        "name": "Kev \u0643\u064a\u0641\u064a\u0646 Pluck \ud83c\uddf5\ud83c\uddf8\ud83c\uddfa\ud83c\udde6",
        "photo": "https://pbs.twimg.com/profile_images/1353617922099298304/VQovNc4U_normal.jpg",
        "reply_count": 46,
        "retweet_count": 480,
        "view_count": 143803,
        "like_count": 1404
    },
    "1740294502181654799": {
        "content": "Imagine how the news media would be if this was happening under a Labour government. News leading, front pages for days. The normalisation of corruption has been enabled by a widely corrupt and corrupting media",
        "name": "ALASTAIR CAMPBELL",
        "photo": "https://pbs.twimg.com/profile_images/1441638351052881920/13PTOAD0_normal.jpg",
        "reply_count": 307,
        "retweet_count": 3955,
        "view_count": 623376,
        "like_count": 11156
    },
    "1737034465753420054": {
        "content": "\"According to the New York Times, \u00a39bn went to companies run by friends and associates of politicians in the Conservative Party, or to companies with either no prior experience or a history of controversy.\" (Dec 2020)\n\n#PPEMedpro #MichelleMone #r4today\nhttps://t.co/MsLVmbs2PO",
        "name": "paulusthewoodgnome \ud83c\uddfa\ud83c\udde6\ud83d\udc99\uea00",
        "photo": "https://pbs.twimg.com/profile_images/1214896349059137536/2ZRBfuzg_normal.jpg",
        "reply_count": 134,
        "retweet_count": 2644,
        "view_count": 1675888,
        "like_count": 3657
    },
    "1740165132486082600": {
        "content": "this is what you get when you don't get your hands dirty with code and play with model capabilities. you channel others' narratives that confirm your fears/biases and put too much value on social signals.",
        "name": "Delip Rao e/\u03c3",
        "photo": "https://pbs.twimg.com/profile_images/1521801057965264896/bo8B1BjJ_normal.jpg",
        "reply_count": 3,
        "retweet_count": 11,
        "view_count": 21503,
        "like_count": 92
    },
    "1740129420944548188": {
        "content": "ugh turns out douglas hofstadter also became an ai doomer. this is surprising, and as much as he is depressed by the thought of ai taking over, i am depressed by him believing this based on chatgpt.\n\nhttps://t.co/Yl2fIp3S6C",
        "name": "(((\u0644()(\u0644() 'yoav))))\ud83d\udc7e",
        "photo": "https://pbs.twimg.com/profile_images/1431395997/profile_normal.jpg",
        "reply_count": 10,
        "retweet_count": 2,
        "view_count": 35918,
        "like_count": 108
    },
    "1740039928460058969": {
        "content": "What happened recently in AI/ML safety research (1/8) \ud83e\uddf5 :",
        "name": "Daniel Paleka",
        "photo": "https://pbs.twimg.com/profile_images/1714702917637124096/rlh-MEtO_normal.jpg",
        "reply_count": 1,
        "retweet_count": 17,
        "view_count": 25432,
        "like_count": 75
    },
    "1740109462319644905": {
        "content": "\ud83e\uddf5 The historic NYT v. @OpenAI lawsuit filed this morning, as broken down by me, an IP and AI lawyer,  general counsel, and longtime tech person and enthusiast. \n\nTl;dr - It's the best case yet alleging that generative AI is copyright infringement. Thread. \ud83d\udc47 https://t.co/Zqbv3ekLWt",
        "name": "Cecilia Ziniti",
        "photo": "https://pbs.twimg.com/profile_images/1458272275778584585/EKoppkt0_normal.jpg",
        "reply_count": 342,
        "retweet_count": 4620,
        "view_count": 5211168,
        "like_count": 17921
    },
    "1740097030729683381": {
        "content": "The most unknown most common shortcut I use on my MacBook is:\n\n- Command+Option+Shift+4 to select a small part of the screen and copy it into clipboard as an image\n- Command+Shift+4 to do the same, but save it as a file on Desktop as png\n\nLife-changing.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 579,
        "retweet_count": 269,
        "view_count": 536494,
        "like_count": 4898
    },
    "1739964360850579526": {
        "content": "Air conditioning makes up 70 per cent of Gulf states electricity consumption, 97 per cent of which is generated from oil and gas.\nhttps://t.co/rKed1BSmDL",
        "name": "Chatham House",
        "photo": "https://pbs.twimg.com/profile_images/1214140568877576192/Om8GlbSo_normal.jpg",
        "reply_count": 0,
        "retweet_count": 11,
        "view_count": 5018,
        "like_count": 15
    },
    "1739689816239772104": {
        "content": "A reminder that decoupling is happening https://t.co/0GsHK4tcOA",
        "name": "Chris Freiman",
        "photo": "https://pbs.twimg.com/profile_images/1750334337076121600/aRhciHRe_normal.jpg",
        "reply_count": 24,
        "retweet_count": 125,
        "view_count": 49460,
        "like_count": 636
    },
    "1739839815603105867": {
        "content": "Google was forced to reveal the most in-depth set of public knowledge about how Google Search works, from the US vs Google court case!\n\nAn absolute goldmine of knowledge about one of the most secretive technologies that power the internet as we know today.\n\n\ud83e\uddf5",
        "name": "Deedy",
        "photo": "https://pbs.twimg.com/profile_images/1471065068041244674/eLm0sHqx_normal.jpg",
        "reply_count": 16,
        "retweet_count": 88,
        "view_count": 175972,
        "like_count": 816
    },
    "1739676006951346341": {
        "content": "I heard a wonderful analogy for AI progress from @demishassabis :\n\nIt's hard to imagine the industrial revolution if we didn't happen to have dinosaurs under ground that we could use as fossil fuel. Without them, we'd need to wait to discover solar or nuclear.\n\nIt's hard to imagine the AI revolution, if we didn't happen to have the Internet with all its data. Without it, we'd need to wait to discover agents that produce their own data.",
        "name": "Karol Hausman",
        "photo": "https://pbs.twimg.com/profile_images/1687143326317973504/1KiEt58S_normal.jpg",
        "reply_count": 10,
        "retweet_count": 26,
        "view_count": 40026,
        "like_count": 187
    },
    "1739654762990362802": {
        "content": "New post: Will scaling work?\n\nThis is the crux in arguments about AI timelines.\n\nIn order to think through my own position, I wrote the post as a debate between a skeptic and a believer.\n\nSkeptic point 1: \n\nData bottlenecks won't be clearer by self-play/synthetic data: https://t.co/utQgUWurOC",
        "name": "Dwarkesh Patel",
        "photo": "https://pbs.twimg.com/profile_images/1516990544165150721/gkmNmTig_normal.jpg",
        "reply_count": 33,
        "retweet_count": 103,
        "view_count": 469884,
        "like_count": 805
    },
    "1739596943326957959": {
        "content": "Today in Express funhouse mirror world, it's considered a betrayal that the EU left the UK, a non-EU country, out of its pan-EU transport plans...\n\nRational people would see it for what it is: Brexit.\nhttps://t.co/OPbJYcxmYx https://t.co/QlRPvtx3DL",
        "name": "Edwin Hayward",
        "photo": "https://pbs.twimg.com/profile_images/1404936390668922884/RJkXyrb7_normal.jpg",
        "reply_count": 166,
        "retweet_count": 784,
        "view_count": 251550,
        "like_count": 3125
    },
    "1724163062830153814": {
        "content": "Humans seeing sparks of AGI in LLMs https://t.co/oZiitnfTLu",
        "name": "Delip Rao e/\u03c3",
        "photo": "https://pbs.twimg.com/profile_images/1521801057965264896/bo8B1BjJ_normal.jpg",
        "reply_count": 121,
        "retweet_count": 973,
        "view_count": 1077889,
        "like_count": 6855
    },
    "1739054670646313345": {
        "content": "Minority Report is a story where they stop thousands of murders and then almost wrongfully convict one guy.",
        "name": "Dr. Dad, PhD \ud83d\udd04\ud83d\udd3c\u25c0\ufe0f\ud83d\udd3d\u25b6\ufe0f",
        "photo": "https://pbs.twimg.com/profile_images/1721001540897697792/5oSk6G30_normal.jpg",
        "reply_count": 61,
        "retweet_count": 38,
        "view_count": 172929,
        "like_count": 1228
    },
    "1738837945115684960": {
        "content": "If only there was a piece of media about how this is a bad idea. Alas. https://t.co/rgzDZVbrsC",
        "name": "Ela Bambust, \ud83c\udff3\ufe0f\u200d\u26a7\ufe0f professional author",
        "photo": "https://pbs.twimg.com/profile_images/1576276537812336641/-pcgwh7m_normal.jpg",
        "reply_count": 597,
        "retweet_count": 3383,
        "view_count": 1619638,
        "like_count": 39480
    },
    "1738559368361349122": {
        "content": "My first @GoogleDeepMind project: How do LLMs recall facts?\n\nEarly MLP layers act as a lookup table, with significant superposition! They recognise entities and produce their attributes as directions. We suggest viewing fact recall as a black box making \"multi-token embeddings\u201d https://t.co/NbBP25a27M",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 7,
        "retweet_count": 154,
        "view_count": 127486,
        "like_count": 1181
    },
    "1738536153601425709": {
        "content": "Robert Solow:\n\u201cI\u2019m glad there is no\rMilton Friedman anywhere [...] today. Milton Friedmans are bad for economics and bad for society. Fruitless debates with talented (near-)extremists waste a lot of everyone\u2019s time that could have been spent\rmore constructively.\u201d https://t.co/I90G2H27Af",
        "name": "Florian Ederer",
        "photo": "https://pbs.twimg.com/profile_images/1756339806055849984/bqzpJNib_normal.jpg",
        "reply_count": 46,
        "retweet_count": 473,
        "view_count": 436072,
        "like_count": 2111
    },
    "1738327056239169618": {
        "content": "People often say you shouldn't be worried about asking stupid questions but I don't think that's true. I often get annoyed by stupid questions, and I'm sure many others are as well.\n\nThese kinds of claims are feel-good claims. Social life is full of friction. Deal with it.",
        "name": "Stefan Schubert",
        "photo": "https://pbs.twimg.com/profile_images/1765862195806507008/vg0DSSyX_normal.jpg",
        "reply_count": 50,
        "retweet_count": 6,
        "view_count": 214754,
        "like_count": 224
    },
    "1737863406714237325": {
        "content": "Insanely good picture generation quality has been achieved internally.",
        "name": "Nathan Benaich",
        "photo": "https://pbs.twimg.com/profile_images/1860887094/2564_517540442680_3904369_31246376_1912207_n_normal.jpg",
        "reply_count": 5,
        "retweet_count": 0,
        "view_count": 7079,
        "like_count": 31
    },
    "1737848545657618873": {
        "content": "Same prompt, Midjourney V3 and V6: https://t.co/iSppcnXW9e",
        "name": "Liberty \ud83d\udc9a\ud83e\udd43",
        "photo": "https://pbs.twimg.com/profile_images/1589637218045411328/EsyMxmT7_normal.jpg",
        "reply_count": 7,
        "retweet_count": 4,
        "view_count": 28992,
        "like_count": 105
    },
    "1738367792729264207": {
        "content": "RAG with LLMs seems deceptively simple but is extraordinarily hard to do well.\n\nBuilding an intelligent ChatGPT-like tool with a custom knowledge base requires multiple non-trivial components.\n\nA simple vector database for retrieval is rarely enough; you need a semantic understanding of the query and a full-scale search engine that powers the \"retrieval.\"\n\nAt Abacus AI, we spend a lot of time thinking and automating the real-world use cases that our customers have, and while rewarding, it's pretty challenging \ud83d\ude05\n\nWe have just scratched the surface here, and a lot more can be done to create robust RAG-based ChatLLMs\n\nLike every other machine learning problem, it's straightforward to get a prototype from a notebook template in a couple of hours, but then it takes months to pass all the evaluations and put the system in production. We do it in weeks!\ud83d\ude09\n\nWe are actively working on this problem, and if you want us to help you with a free POC, drop us a line.\n\nP.S. This image is from a survey paper that may be worth checking out; link in alt.",
        "name": "Bindu Reddy",
        "photo": "https://pbs.twimg.com/profile_images/1443737943684763651/32WHA-kg_normal.jpg",
        "reply_count": 57,
        "retweet_count": 289,
        "view_count": 256457,
        "like_count": 1680
    },
    "1738318672685662362": {
        "content": "Magnificent 128x zoom\n\nNanoLand: Day 05\nWhat is real?\n\n\ud83d\udd0a Sound on\n\nPrompts and settings are in the thread \ud83d\udc47 https://t.co/kH69BIlqB8",
        "name": "Dogan Ural",
        "photo": "https://pbs.twimg.com/profile_images/1642580021972705280/cQ72pRBP_normal.jpg",
        "reply_count": 102,
        "retweet_count": 428,
        "view_count": 717005,
        "like_count": 3748
    },
    "1737819506838241646": {
        "content": "politician in training",
        "name": "Ryanair",
        "photo": "https://pbs.twimg.com/profile_images/1754894868722110464/4kk8SDKx_normal.jpg",
        "reply_count": 177,
        "retweet_count": 1362,
        "view_count": 953323,
        "like_count": 12836
    },
    "1737742493448352164": {
        "content": "Victoria Atkins: \"Junior Doctors or Doctors in training as I prefer to call them\" #Insulting\n\n#BBCBreakfast https://t.co/uEFSWs9l5n",
        "name": "Haggis_UK \ud83c\uddec\ud83c\udde7 \ud83c\uddea\ud83c\uddfa",
        "photo": "https://pbs.twimg.com/profile_images/1486695046/images_normal.jpg",
        "reply_count": 1809,
        "retweet_count": 816,
        "view_count": 7715680,
        "like_count": 3178
    },
    "1738490287939269039": {
        "content": "There are some very worried very rich people https://t.co/PD3OnDBJjI",
        "name": "Matthew Stadlen",
        "photo": "https://pbs.twimg.com/profile_images/1486854505136377856/vximp8xO_normal.jpg",
        "reply_count": 341,
        "retweet_count": 942,
        "view_count": 832878,
        "like_count": 7378
    },
    "1738259248356745390": {
        "content": "For the fans of \"ML explained on a blackboard\": Lecture 13/14 was on the attention layer and mechanism (inspired by the relation to inverse Potts model from https://t.co/KJObRyn8yM), with a toy-transformer architecture counting the number of occurrences for the exercise. https://t.co/c2yoINP2Gc",
        "name": "Lenka Zdeborova",
        "photo": "https://pbs.twimg.com/profile_images/1426449775319306245/mlTg7OkP_normal.jpg",
        "reply_count": 14,
        "retweet_count": 196,
        "view_count": 158284,
        "like_count": 1728
    },
    "1737967856133018047": {
        "content": "hope this is useful for people who spend the holidays thinking about what to go work on in 2024; always one of my favorite times of year",
        "name": "Sam Altman",
        "photo": "https://pbs.twimg.com/profile_images/804990434455887872/BG0Xh7Oa_normal.jpg",
        "reply_count": 106,
        "retweet_count": 86,
        "view_count": 326020,
        "like_count": 2435
    },
    "1738060254166802493": {
        "content": "TBH I am puzzled by the amount of traffic my posts generate since I passed the 20k followers.",
        "name": "Fran\u00e7ois Fleuret",
        "photo": "https://pbs.twimg.com/profile_images/1741919776773902336/pXUEFYUA_normal.jpg",
        "reply_count": 2,
        "retweet_count": 0,
        "view_count": 6392,
        "like_count": 12
    },
    "1737445613434757207": {
        "content": "I\u2019d score 100 out of 100 penalties against Mary Earps. \n\nAny day of the week. \n\nTwice on a fucking Sunday. \ud83d\udc4d\ud83d\udc51\n\n#perspective",
        "name": "\ud83d\udc51 Joey Barton \ud83d\udc51",
        "photo": "https://pbs.twimg.com/profile_images/1719288962294874112/P-v-bber_normal.jpg",
        "reply_count": 5298,
        "retweet_count": 1110,
        "view_count": 15848858,
        "like_count": 21426
    },
    "1737444587977814310": {
        "content": "Why would Boris Johnson\u2019s wife invite Charlotte Owen to their intimate party? https://t.co/mQjCIqsEpb",
        "name": "Ron Moore MP",
        "photo": "https://pbs.twimg.com/profile_images/3074909522/1d49997d5f96240a026d21305b867e54_normal.png",
        "reply_count": 617,
        "retweet_count": 1665,
        "view_count": 877609,
        "like_count": 5337
    },
    "1737153436695634022": {
        "content": "Ahahaha MY WORD this is such a beautiful result - All Transformer dynamics COLLAPSE TO A SINGLE POINT  \n\nAGI is a DIRAC DELTA FUNCTION\n\nScale is all you need, as long as all you need is an infinitely dense probability mass with zero entropy, too too good https://t.co/I2B0g5XCjE",
        "name": "Matt Spike",
        "photo": "https://pbs.twimg.com/profile_images/1276880038273724419/1_35ZEMK_normal.jpg",
        "reply_count": 33,
        "retweet_count": 100,
        "view_count": 228402,
        "like_count": 933
    },
    "1736986218716700932": {
        "content": "\"A mathematical perspective on Transformers\" (by Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet): https://t.co/HTgcw5knsF",
        "name": "SIAM Activity Group on Dynamical Systems",
        "photo": "https://pbs.twimg.com/profile_images/682965296097832961/PVjCHkEb_normal.png",
        "reply_count": 7,
        "retweet_count": 137,
        "view_count": 293811,
        "like_count": 792
    },
    "1737790033329787366": {
        "content": "This idiot is our health secretary. She thinks 'junior doctors' are 'doctors in training'. The reality is that they are all hospital doctors who are not consultants - in other words, the majority of all doctors, and many of them have considerable experience. Is she being deliberately insulting, or is she just gratuitously rude?",
        "name": "Richard Murphy",
        "photo": "https://pbs.twimg.com/profile_images/1503071399501520897/HP799JUU_normal.jpg",
        "reply_count": 1108,
        "retweet_count": 4110,
        "view_count": 3144901,
        "like_count": 18076
    },
    "1737518588159041845": {
        "content": "Amazing text to music generations from @suno_ai_ , could easily see these taking over leaderboards.\n\nPersonal favorite: this song I fished out of their Discord a few months ago, \"Return to Monkey\", which has been stuck in my head since :D\n\n[00:57]\nI wanna return to monkey, I wanna be wild and free,\nI wanna return to monkey, modern life is not for me.\nNo more emails, no more bills, no more endless strife, \nJust the sound of the river, the hearbeat of life\n\ud83d\ude02",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 156,
        "retweet_count": 260,
        "view_count": 543612,
        "like_count": 1916
    },
    "1737299056290910464": {
        "content": "You can make great music, whether you're a shower singer or a charting artist. No instrument needed, just imagination. \n\nMake your song today at https://t.co/HG7qM2Jhr5 \ud83c\udfa7 https://t.co/vVbWiSPouJ",
        "name": "Suno",
        "photo": "https://pbs.twimg.com/profile_images/1735127792776318976/BK2vuCtr_normal.jpg",
        "reply_count": 269,
        "retweet_count": 338,
        "view_count": 1840146,
        "like_count": 2033
    },
    "1737428865801183666": {
        "content": "Can you do RAG without a vector index? Yes.\n\nCan you do RAG without an embedding model? Also Yes.",
        "name": "Jo Kristian Bergum",
        "photo": "https://pbs.twimg.com/profile_images/1248020121378902017/Pt5ddq09_normal.jpg",
        "reply_count": 19,
        "retweet_count": 12,
        "view_count": 44652,
        "like_count": 205
    },
    "1737500778628362557": {
        "content": "\ud83d\udce2 My book on Fairness and ML with @s010n and Moritz Hardt has been published by @mitpress! https://t.co/QZSOLwAW6E\nThe draft (https://t.co/eswKksmbGb) has already been used in many courses. We've also released a set of exercises and discussion prompts: https://t.co/ZDkwR9Hdko https://t.co/TiZ7Ke6a1q",
        "name": "Arvind Narayanan",
        "photo": "https://pbs.twimg.com/profile_images/1650881612756942850/bZYjMyFU_normal.jpg",
        "reply_count": 14,
        "retweet_count": 305,
        "view_count": 80276,
        "like_count": 1147
    },
    "1737544497016578453": {
        "content": "@AlphaSignalAI @ClementDelangue I pretty much only trust two LLM evals right now: Chatbot Arena and r/LocalLlama comments section",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 30,
        "retweet_count": 131,
        "view_count": 219595,
        "like_count": 1620
    },
    "1737243028962906436": {
        "content": "@alana_anton I also worked three other part-time jobs during my PhD to make ends meet in Seattle. That's why I didn't spend more than 40 hours a week on my PhD research.",
        "name": "Ashley Ruba, PhD",
        "photo": "https://pbs.twimg.com/profile_images/1714647102603554816/ji5LALby_normal.jpg",
        "reply_count": 8,
        "retweet_count": 0,
        "view_count": 24225,
        "like_count": 41
    },
    "1737435017301627240": {
        "content": "As a PhD student, I only worked 20 hours a week. I started working at 11, after my coffee shop was opened and my $40 coffee was made. I always took my mandatory 2-hour lunch break before getting back to my dissertation. I never worked past 3 PM because my health is my priority.",
        "name": "Khoa Vu",
        "photo": "https://pbs.twimg.com/profile_images/1704959085056036864/CIPpv-fL_normal.jpg",
        "reply_count": 7,
        "retweet_count": 25,
        "view_count": 131734,
        "like_count": 445
    },
    "1737158631890825718": {
        "content": "As a PhD student, I rarely worked more than 40 hours a week. I published seven first author papers and won two dissertation awards.\n\nYou'll never do your best work while burnt out.\n\nTake a break this month.",
        "name": "Ashley Ruba, PhD",
        "photo": "https://pbs.twimg.com/profile_images/1714647102603554816/ji5LALby_normal.jpg",
        "reply_count": 73,
        "retweet_count": 351,
        "view_count": 615502,
        "like_count": 4019
    },
    "1737206517990875629": {
        "content": "This is huge! Now watch the LLM API costs dropping even further. \n\n[.cn PDF link] https://t.co/Kvj3lRTONE https://t.co/IjGZmfR9Qv",
        "name": "Delip Rao e/\u03c3",
        "photo": "https://pbs.twimg.com/profile_images/1521801057965264896/bo8B1BjJ_normal.jpg",
        "reply_count": 45,
        "retweet_count": 229,
        "view_count": 309419,
        "like_count": 1743
    },
    "1736867229814157734": {
        "content": "The \u201cstudent\u201d in \u201cPhD Student\u201d is a misnomer. It only exists for university administration purposes. If you are a PhD student interacting with industry, don\u2019t let them treat you like a \u201cstudent\u201d. Free labor, unless it advances your graduation, is never justified. You are an expert in whatever you are working on, heads down, so act like one in every way. Any promise of \u201cconnections\u201d is overrated.\nOn the contrary, I promise you that if you do fantastic work, you will automatically find yourself in the right rooms and the right press articles. Always ask for value, which, if you are a student, is money and stuff that will help you graduate. If you have to choose between the two, always pick the latter. Money will follow once you graduate.",
        "name": "Delip Rao e/\u03c3",
        "photo": "https://pbs.twimg.com/profile_images/1521801057965264896/bo8B1BjJ_normal.jpg",
        "reply_count": 6,
        "retweet_count": 20,
        "view_count": 68122,
        "like_count": 343
    },
    "1737193931568484647": {
        "content": "The UK Tory government has completely lost any moral compass it ever had. How could a sniper shooting Catholic civilians within a church possibly be justified as legitimate self defence against Islamist militants?   The simple truth is that @RishiSunak and his government are racist and Islamoophic bigots who regard all Palestinians as subhumans whose lives are utterly expendable. It also true that this is a government run by a bunch of ignorant bankers with  zero understanding of history, geography or any politics beyond constituency fund raising.",
        "name": "William Dalrymple",
        "photo": "https://pbs.twimg.com/profile_images/1400762145365794817/_766A2iY_normal.jpg",
        "reply_count": 377,
        "retweet_count": 3103,
        "view_count": 1454366,
        "like_count": 9509
    },
    "1737013041676345532": {
        "content": "A Palestinian woman leaving a church shelter to go to the toilet was shot dead by an Israeli sniper &amp; her daughter who went to help her was killed as well\n\nUK govt minister Lee Rowley is asked about this and says Israel has a right to defend itself against murderers https://t.co/llqZqJ2tpH",
        "name": "Saul Staniforth",
        "photo": "https://pbs.twimg.com/profile_images/1274781481748107267/4S9A_4E6_normal.jpg",
        "reply_count": 949,
        "retweet_count": 2418,
        "view_count": 1720234,
        "like_count": 4478
    },
    "1737071659247382671": {
        "content": "@t0nyyates Not possible. The reason I rebased to 100 in the original is that definitions changed in 2009, so the only way to create a consistent time series is to index to that point. This is also why the y-axis must start at 100.\n\nThe issue is their description of the y-axis is incorrect",
        "name": "John Burn-Murdoch",
        "photo": "https://pbs.twimg.com/profile_images/922511756110557184/IDxUQ_rr_normal.jpg",
        "reply_count": 6,
        "retweet_count": 2,
        "view_count": 25999,
        "like_count": 76
    },
    "1606223967903260673": {
        "content": "Let\u2019s start with the most striking: the astonishingly clear association between the governing party, health spending and the functioning of the NHS.\n\nWaiting lists swelled under Major, shrunk under Labour as health funding soared, before climbing again under Tory austerity. https://t.co/qPbO0WUgR1",
        "name": "John Burn-Murdoch",
        "photo": "https://pbs.twimg.com/profile_images/922511756110557184/IDxUQ_rr_normal.jpg",
        "reply_count": 26,
        "retweet_count": 1605,
        "view_count": 453839,
        "like_count": 3529
    },
    "1737310635749490782": {
        "content": "Midjourney had their second v6 rating party.\n\nThese are supposed to be the \"better\" images.\n\nAfter this they'll do a final tuning and then FINALLY release v6!\n\nPrompts &amp; examples from rating party #2\ud83d\udc47",
        "name": "Nick St. Pierre",
        "photo": "https://pbs.twimg.com/profile_images/1617767320776052736/spbjZoLh_normal.jpg",
        "reply_count": 79,
        "retweet_count": 162,
        "view_count": 1254147,
        "like_count": 1951
    },
    "1737157693050401178": {
        "content": "ANTHROPIC?! What are u doing https://t.co/WTryiB10wV",
        "name": "Andrew Carr (e/\ud83e\udd38)",
        "photo": "https://pbs.twimg.com/profile_images/1598394632919953408/MiPTd73F_normal.jpg",
        "reply_count": 29,
        "retweet_count": 15,
        "view_count": 115675,
        "like_count": 382
    },
    "1736664393956663577": {
        "content": "The new meta for PhD students is to take a well known benchmark, gpt3.5 turbo it, fine-tune a model to beat some well known incumbents and get an emnlp paper.\n\nDespicable.",
        "name": "yi \ud83e\udd9b",
        "photo": "https://pbs.twimg.com/profile_images/1645237397402292225/vZ1fFco6_normal.jpg",
        "reply_count": 5,
        "retweet_count": 10,
        "view_count": 33380,
        "like_count": 169
    },
    "1736831179838697896": {
        "content": "You should be skeptical about companies' claims about their \"values,\" unless they take costly actions with no clear benefit to themselves.\nThis PF is expensive to implement, and raises frictions our competitors don't face.\nIt is also what you do if you actually care about safety.",
        "name": "Yo Shavit",
        "photo": "https://pbs.twimg.com/profile_images/800757082047778820/ebgIKtfw_normal.jpg",
        "reply_count": 7,
        "retweet_count": 9,
        "view_count": 23424,
        "like_count": 102
    },
    "1736809603311280489": {
        "content": "We are systemizing our safety thinking with our Preparedness Framework, a living document (currently in beta) which details the technical and operational investments we are adopting to guide the safety of our frontier model development.\nhttps://t.co/vWvvmR9tpP",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 286,
        "retweet_count": 395,
        "view_count": 1463588,
        "like_count": 2306
    },
    "1736823621643903015": {
        "content": "Not sure if I should be tweeting this but....\nIf you really, really, really want log-probs from an API you can get them to arbitrary precision just with just 1 logit bias. \n\nCode (Justin+@jxmnop): https://t.co/pkyFTYtVSY https://t.co/mSgPC0xqE6",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 6,
        "retweet_count": 29,
        "view_count": 50219,
        "like_count": 296
    },
    "1736403005405319646": {
        "content": "Hugging face Open LLM Leaderboard is now a hall of shame... https://t.co/P35Pq0z2zU",
        "name": "Joseph Cheung",
        "photo": "https://pbs.twimg.com/profile_images/885807746175520768/oKTSflzR_normal.jpg",
        "reply_count": 24,
        "retweet_count": 17,
        "view_count": 155116,
        "like_count": 327
    },
    "1736481073972879591": {
        "content": "We really don't do any socialising these days \ud83d\ude26 https://t.co/W5crwwncvp",
        "name": "Torsten Bell",
        "photo": "https://pbs.twimg.com/profile_images/1756980557198589952/DwIYJOh6_normal.jpg",
        "reply_count": 19,
        "retweet_count": 34,
        "view_count": 44837,
        "like_count": 155
    },
    "1736565213132931577": {
        "content": "What is a good detailed tutorial on LLM fine-tuning?",
        "name": "Andriy Burkov",
        "photo": "https://pbs.twimg.com/profile_images/663827278502170624/lJjdhs6X_normal.jpg",
        "reply_count": 22,
        "retweet_count": 64,
        "view_count": 249562,
        "like_count": 760
    },
    "1736829040692990297": {
        "content": "1/ A few graphics for Baby Boomers who have kids home over the holidays.  \n\nI start with mortgage rates . . . https://t.co/rhcdXdkA8l",
        "name": "Michael J. Hicks",
        "photo": "https://pbs.twimg.com/profile_images/1102654558596149248/OhuyIWUy_normal.png",
        "reply_count": 76,
        "retweet_count": 296,
        "view_count": 413123,
        "like_count": 980
    },
    "1736830532539818083": {
        "content": "This isn't just good leaflet copy, this is why politics matters and different parties aren't all \"just the same\". \n\nHere's a collection of similarly devastating graphs\n\n\ud83e\uddf5 (1/11)",
        "name": "Cllr Anna Railton \ud83c\udf39",
        "photo": "https://pbs.twimg.com/profile_images/1680865655044579328/uSSGhy6H_normal.jpg",
        "reply_count": 110,
        "retweet_count": 2823,
        "view_count": 3114806,
        "like_count": 12324
    },
    "1736728290776293843": {
        "content": "The longer the Tories are in power, the longer patients will wait. https://t.co/Fnsk9G3E5m",
        "name": "The Labour Party",
        "photo": "https://pbs.twimg.com/profile_images/1572133535703605249/Ap0Mz-Qj_normal.jpg",
        "reply_count": 610,
        "retweet_count": 3663,
        "view_count": 4805666,
        "like_count": 11739
    },
    "1736775012156334384": {
        "content": "Cool work from @GoogleDeepMind alignment on limitations of methods for eliciting a model's beliefs!\n\nMy key takeaway is that unsupervised methods (eg CCS) rely on \"proxy properties\" of true beliefs, but other features share these proxies! Eg \"agrees with the user\" vs \"is true\" https://t.co/9MMYSZmhXT",
        "name": "Neel Nanda",
        "photo": "https://pbs.twimg.com/profile_images/1542528376845615104/hWSoUGaN_normal.jpg",
        "reply_count": 2,
        "retweet_count": 10,
        "view_count": 16443,
        "like_count": 93
    },
    "1736770109866147876": {
        "content": "In our new @GoogleDeepMind paper, we redteam methods that aim to discover latent knowledge through unsupervised learning from LLM activation data. TL;DR: Existing methods can be easily distracted by other salient features in the prompt. https://t.co/78GJEUnLDc\n\n\ud83e\uddf5\ud83d\udc47 https://t.co/hjnB6U4wAK",
        "name": "Zac Kenton",
        "photo": "https://pbs.twimg.com/profile_images/1736783430552113152/PZr_Rs_i_normal.jpg",
        "reply_count": 5,
        "retweet_count": 35,
        "view_count": 48032,
        "like_count": 236
    },
    "1736509613447745567": {
        "content": "\ud83e\udde0\ud83d\ude36\u200d\ud83c\udf2b\ufe0f",
        "name": "ChatGPT",
        "photo": "https://pbs.twimg.com/profile_images/1722425721602347008/UWMHieDx_normal.png",
        "reply_count": 156,
        "retweet_count": 77,
        "view_count": 524014,
        "like_count": 1433
    },
    "1736196921541140861": {
        "content": "ChatGPT-4 suddenly got very good again for some reason, after being unreliable &amp; a little \"dull\" for weeks\n\n(Though this might be my favorite interaction: I asked it to create files for me, it insisted it could not, I told it to try, it did, and then look at the top code comment) https://t.co/X1WhtxC96e",
        "name": "Ethan Mollick",
        "photo": "https://pbs.twimg.com/profile_images/1601382188712398850/3AAOlqrX_normal.jpg",
        "reply_count": 102,
        "retweet_count": 154,
        "view_count": 729917,
        "like_count": 2400
    },
    "1736258744080879889": {
        "content": "Honestly, I have my doubts here. \n\nLLaMA-2 70B gets beaten by Mistral, with 46.7B model. So 70B vs 47B. \n\nThen someone uses Mistral's 7B model, and replicate some of the layers, continue to pre-train it.\n\nIt achieves almost the same performance as the 70B model, only with 11B parameters.\n\nHard to not think that there might be some eval contamination..\n\nHow does an 11B model achieves similar performance to Mistral's MoE model? It doesn't sit right.. I mean, even like financially it doesn't make sense.. Like, Mistral just raised another big round.. \n\nIs this legit?",
        "name": "Migel Tissera",
        "photo": "https://pbs.twimg.com/profile_images/1765247685827956736/_RALBjIx_normal.jpg",
        "reply_count": 51,
        "retweet_count": 34,
        "view_count": 450487,
        "like_count": 447
    },
    "1736224977337069941": {
        "content": "SOLAR: an 11B model that beats every open model, including Mixtral, Yi-34B, Llama 2 70B, and Falcon 180B: https://t.co/rwtY70Ojk3 https://t.co/Oc7LPYP6PP",
        "name": "Andriy Burkov",
        "photo": "https://pbs.twimg.com/profile_images/663827278502170624/lJjdhs6X_normal.jpg",
        "reply_count": 19,
        "retweet_count": 73,
        "view_count": 620589,
        "like_count": 697
    },
    "1736141178855424097": {
        "content": "We finally got our first look at v6 images \ud83d\udc40\n\nMidjourney had their v6 rating party. They say these are the \"bad\" images. Next rating party will be the \"good\" ones.\n\nI rated over 1000 images &amp; inspected them to analyze the prompts.\n\nv6 is gonna be insane\n\nA bunch of examples \ud83d\udc47",
        "name": "Nick St. Pierre",
        "photo": "https://pbs.twimg.com/profile_images/1617767320776052736/spbjZoLh_normal.jpg",
        "reply_count": 111,
        "retweet_count": 221,
        "view_count": 2060892,
        "like_count": 2636
    },
    "1735749186019066276": {
        "content": "OpenAI CEO talks about \"AI\" rendering humanity extinct, and \"existential risks\" and such, and they have their \"head of platform research\" and others writing things like what we see here \"More! No mercy! @IDF don't stop\" when they see children indiscriminately bombarded.",
        "name": "@timnitGebru@dair-community.social on Mastodon",
        "photo": "https://pbs.twimg.com/profile_images/1660443800370827264/-X6cD__T_normal.jpg",
        "reply_count": 30,
        "retweet_count": 519,
        "view_count": 197831,
        "like_count": 1182
    },
    "1735559831837171886": {
        "content": "This is the head of research at @OpenAI, everyone. And we wonder why new tech is fucked. https://t.co/aDpCoxX9Ea",
        "name": "Marwa Fatafta \u0645\u0631\u0648\u0629 \u0641\u0637\u0627\u0641\u0637\u0629",
        "photo": "https://pbs.twimg.com/profile_images/1723851837038592000/Q-eyIpjw_normal.jpg",
        "reply_count": 679,
        "retweet_count": 17232,
        "view_count": 2846875,
        "like_count": 51573
    },
    "1735786033453863422": {
        "content": "Excited to announce v(1.0) of Digi, the future of AI Romantic Companionship, for IOS and Android \ud83e\udd16\n\nSite: https://t.co/q420GR4jJ4\nTwitter: @digiaiapp \n\nA quick thread on features, and where we go from here (1/13) https://t.co/9KZoorEoA0",
        "name": "Andrew (digi)",
        "photo": "https://pbs.twimg.com/profile_images/1770838840485318657/V9-oZuAY_normal.jpg",
        "reply_count": 3275,
        "retweet_count": 691,
        "view_count": 23638306,
        "like_count": 5107
    },
    "1735771288441180659": {
        "content": "This is undoubtedly just the beginning of a new age of scientific discovery",
        "name": "Erik Brynjolfsson",
        "photo": "https://pbs.twimg.com/profile_images/1599197514715910144/6npd3Jwh_normal.jpg",
        "reply_count": 64,
        "retweet_count": 487,
        "view_count": 1343694,
        "like_count": 3700
    },
    "1735677650251772042": {
        "content": "Google DeepMind used a large language model to\u00a0solve an unsolvable math problem https://t.co/zvEtTcuyRE https://t.co/RA2Fz5bJqr",
        "name": "James Pethokoukis \u23e9\ufe0f\u2934\ufe0f",
        "photo": "https://pbs.twimg.com/profile_images/1689426056145444865/Xl3MTIOa_normal.jpg",
        "reply_count": 68,
        "retweet_count": 424,
        "view_count": 2253729,
        "like_count": 1902
    },
    "1735730662362189872": {
        "content": "By popular demand, log probabilities are now in the Chat Completions API!\n\nWith logprobs for top output tokens, you can build features such as better autocomplete, classification, keyword suggestion, or assess the model\u2019s confidence in its predictions. https://t.co/4zUQIy3wuV",
        "name": "OpenAI Developers",
        "photo": "https://pbs.twimg.com/profile_images/1720598745664958465/TYA_2LYQ_normal.png",
        "reply_count": 66,
        "retweet_count": 203,
        "view_count": 555294,
        "like_count": 1544
    },
    "1729510078959497562": {
        "content": "Introducing Pika 1.0, the idea-to-video platform that brings your creativity to life.\n\nCreate and edit your videos with AI.\n\nRolling out to new users on web and discord, starting today. Sign up at https://t.co/JHRrinsIwx https://t.co/Rve3I2FzmK",
        "name": "Pika",
        "photo": "https://pbs.twimg.com/profile_images/1729474182852030464/yBjH13CC_normal.png",
        "reply_count": 1408,
        "retweet_count": 5510,
        "view_count": 20440045,
        "like_count": 26047
    },
    "1735377532969525608": {
        "content": "I cannot get over how beautiful this book is from @francoisfleuret . NeurIPS fashion accessory for the year. https://t.co/eUFojk4WIs",
        "name": "Sasha Rush",
        "photo": "https://pbs.twimg.com/profile_images/1702727441972686848/k52u1cyt_normal.jpg",
        "reply_count": 7,
        "retweet_count": 23,
        "view_count": 70396,
        "like_count": 555
    },
    "1735211875191910550": {
        "content": "This is precisely what statisticians used to say. \"If you can predict well the next data point, they you understand the reality or the process that generates that point\". They said it and said it until Causal Inference proved them wrong. Understanding takes more than prediction. #Bookofwhy",
        "name": "Judea Pearl",
        "photo": "https://pbs.twimg.com/profile_images/1012181647993606144/TeYvs7NH_normal.jpg",
        "reply_count": 144,
        "retweet_count": 325,
        "view_count": 750148,
        "like_count": 2378
    },
    "1735017274912952533": {
        "content": "Ilya on LLMs understanding the world: \n\n\"predicting the next token well, means that you understand the underlying reality that let to the creation of that token\"\n\nSeem like the opposite view of Yann. https://t.co/32MLEeDQnx",
        "name": "Lior\u26a1",
        "photo": "https://pbs.twimg.com/profile_images/1737888535099899906/5YPbFAld_normal.jpg",
        "reply_count": 145,
        "retweet_count": 208,
        "view_count": 1208829,
        "like_count": 1553
    },
    "1735214488482423019": {
        "content": "OpenAI startup fund launches converge 2",
        "name": "Mira Murati",
        "photo": "https://pbs.twimg.com/profile_images/1483374027905413122/C2kbpEeD_normal.jpg",
        "reply_count": 38,
        "retweet_count": 27,
        "view_count": 151662,
        "like_count": 503
    },
    "1735138463853482201": {
        "content": "converge 1 was a standout success and is one of our fund's most important initiatives for early AI startups. a small cohort of exceptional founders working closely with our team to build AI native companies.\n\napplications are now open for our second cohort - apply here: https://t.co/YBHfnokKPO",
        "name": "Brad Lightcap",
        "photo": "https://pbs.twimg.com/profile_images/1692045577582989312/xnwpm5u__normal.jpg",
        "reply_count": 18,
        "retweet_count": 20,
        "view_count": 356261,
        "like_count": 245
    },
    "1734856307515994269": {
        "content": "If you are reading Understanding Deep Learning (https://t.co/T2pRecsLMd), you may be interested to know that Chris and Hugh Bishop have just published this:\n\nhttps://t.co/0FqaAUIgiE. \n\nNo direct comparisons please (bad taste!).\n\nI haven't read it yet but my impression is that the content has a more general ML flavour.",
        "name": "Simon Prince",
        "photo": "https://pbs.twimg.com/profile_images/1148263947302244353/HK0Msjil_normal.jpg",
        "reply_count": 11,
        "retweet_count": 189,
        "view_count": 120368,
        "like_count": 1035
    },
    "1734961363720479066": {
        "content": "You can now start building with Gemini Pro! We\u2019ve released the Gemini API in AI Studio, as well as @GoogleCloud\u2019s Vertex AI. Looking forward to seeing what people create with Gemini #BuildWithGemini https://t.co/iqe8KGO9gr",
        "name": "Demis Hassabis",
        "photo": "https://pbs.twimg.com/profile_images/691700243809718272/z7XZUARB_normal.jpg",
        "reply_count": 60,
        "retweet_count": 203,
        "view_count": 130149,
        "like_count": 974
    },
    "1734823293516132493": {
        "content": "Fear https://t.co/KmVYr0Eip3",
        "name": "Daniel Gould, MD, PhD",
        "photo": "https://pbs.twimg.com/profile_images/1145069334097620997/a_Yx6wzz_normal.png",
        "reply_count": 118,
        "retweet_count": 1547,
        "view_count": 1223592,
        "like_count": 13099
    },
    "1734659057938477174": {
        "content": "There's too much happening right now, so here's just a bunch of links\n\nGPT-4 + Medprompt -> SOTA MMLU\nhttps://t.co/Jkp96izfec\n\nMixtral 8x7B @ MLX nice and clean\nhttps://t.co/75StzY5AHe\n\nBeyond Human Data: Scaling Self-Training for Problem-Solving with Language Models\nhttps://t.co/gOCWjfY7ec\n\nPhi-2 (2.7B), the smallest most impressive model\nhttps://t.co/Fps8tI5QVi\n\nLLM360: Towards Fully Transparent Open-Source LLMs\nhttps://t.co/l6E16GfdIN\n\nHonorable mentions\nhttps://t.co/7GQqiCGHRH\nhttps://t.co/3GZrYPp9KP\nhttps://t.co/Su8iiDksMZ",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 156,
        "retweet_count": 1161,
        "view_count": 911165,
        "like_count": 7142
    },
    "1734704988868284550": {
        "content": "Wow, our server is experiencing a super stress test now thanks @karpathy\ud83d\ude02\n\nWe temporarily move Claude to battle mode only due to API rate limit but other open models should still work pretty smoothly, at least for now :)\n\nSuper exciting and let us know if you have any feedback! https://t.co/nVkfVunSEN",
        "name": "lmsys.org",
        "photo": "https://pbs.twimg.com/profile_images/1641380096778055681/xRrCcdkf_normal.jpg",
        "reply_count": 5,
        "retweet_count": 13,
        "view_count": 64579,
        "like_count": 324
    },
    "1734687074350166089": {
        "content": "Chatbot Arena is awesome.\nBring your hardest prompts.\nRank models.\nArena calculates ELO.\nPersonally I find it quite educational too because you get to get a sense of the \"personalities\" of many different models over time.\nRIP servers sorry :)",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 64,
        "retweet_count": 366,
        "view_count": 504066,
        "like_count": 2483
    },
    "1734881560271454525": {
        "content": "Mistral-7B is cool but you know what's cooler? A more powerful model in just 1/3rd of the size!\n\nWelcome to Phi-2.\n\nThis is something our team at Microsoft Research had been tirelessly working on and now we have more numbers comparing with Llama-7B, 13B, 70B and Gemini Nano. \ud83d\udc47",
        "name": "Shital Shah",
        "photo": "https://pbs.twimg.com/profile_images/1600058846332190720/XeRAikbl_normal.jpg",
        "reply_count": 60,
        "retweet_count": 156,
        "view_count": 567920,
        "like_count": 1894
    },
    "1734655832065986635": {
        "content": "Thank you Microsoft for having our back. Again. \ud83d\ude4f\n\nYou have been a good Bing. \ud83d\ude0a",
        "name": "Peter Welinder",
        "photo": "https://pbs.twimg.com/profile_images/1527047003984629761/6ZfqcDtO_normal.jpg",
        "reply_count": 5,
        "retweet_count": 18,
        "view_count": 151463,
        "like_count": 470
    },
    "1734621444716232730": {
        "content": "Microsoft strikes back on MMLU, passing Gemini ultra lol https://t.co/6pFCal6vA7",
        "name": "anton",
        "photo": "https://pbs.twimg.com/profile_images/1678598826544734210/Z8ZMuiAR_normal.jpg",
        "reply_count": 65,
        "retweet_count": 92,
        "view_count": 352800,
        "like_count": 1100
    },
    "1734280779537035478": {
        "content": "OMG, the AI Winter Break Hypothesis may actually be true?\n\nThere was some idle speculation that GPT-4 might perform worse in December because it \"learned\" to do less work over the holidays.\n\nHere is a statistically significant test showing that this may be true. LLMs are weird.\ud83c\udf85",
        "name": "Ethan Mollick",
        "photo": "https://pbs.twimg.com/profile_images/1601382188712398850/3AAOlqrX_normal.jpg",
        "reply_count": 92,
        "retweet_count": 693,
        "view_count": 1351810,
        "like_count": 4608
    },
    "1734278713762549970": {
        "content": "@ChatGPTapp @OpenAI @tszzl @emollick @voooooogel Wild result. gpt-4-turbo over the API produces (statistically significant) shorter completions when it \"thinks\" its December vs. when it thinks its May (as determined by the date in the system prompt).\n\nI took the same exact prompt over the API (a code completion task asking to implement a machine learning task without libraries).\n\nI created two system prompts, one that told the API it was May and another that it was December and then compared the distributions.\n\nFor the May system prompt, mean = 4298\nFor the December system prompt, mean = 4086\n\nN = 477 completions in each sample from May and December\n\nt-test p < 2.28e-07\n\nTo reproduce this you can just vary the date number in the system message. Would love to see if this reproduces for others.",
        "name": "Rob Lynch",
        "photo": "https://pbs.twimg.com/profile_images/1610348952385196033/qm_OLcfP_normal.jpg",
        "reply_count": 138,
        "retweet_count": 354,
        "view_count": 2182050,
        "like_count": 2345
    },
    "1734609807770898674": {
        "content": "Today, we share our teams\u2019 latest contributions, Phi-2 and promptbase.  \n\nPhi-2 outperforms other existing small language models, yet it\u2019s small enough to run on a laptop or mobile device. https://t.co/wLhUeRsByL",
        "name": "Microsoft Research",
        "photo": "https://pbs.twimg.com/profile_images/1603123064140890112/bSq-JVnp_normal.png",
        "reply_count": 51,
        "retweet_count": 368,
        "view_count": 873747,
        "like_count": 1706
    },
    "1734251375163511203": {
        "content": "Official post on Mixtral 8x7B:  https://t.co/Dxqgb6sQdK\n\nOfficial PR into vLLM shows the inference code:\nhttps://t.co/f0UvyO4g3s\n\nNew HuggingFace explainer on MoE very nice:\nhttps://t.co/mNd505Uikg\n\nIn naive decoding, performance of a bit above 70B (Llama 2), at inference speed of ~12.9B dense model (out of total 46.7B params).\n\nNotes:\n- Glad they refer to it as \"open weights\" release instead of \"open source\", which would imo require the training code, dataset and docs.\n- \"8x7B\" name is a bit misleading because it is not all 7B params that are being 8x'd, only the FeedForward blocks in the Transformer are 8x'd, everything else stays the same. Hence also why total number of params is not 56B but only 46.7B.\n- More confusion I see is around expert choice, note that each token *and also* each layer selects 2 different experts (out of 8).\n- Mistral-medium \ud83d\udc40",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 58,
        "retweet_count": 610,
        "view_count": 674943,
        "like_count": 3563
    },
    "1734216541099507929": {
        "content": "Very excited to release our second model, Mixtral 8x7B, an open weight mixture of experts model.\nMixtral matches or outperforms Llama 2 70B and GPT3.5 on most benchmarks, and has the inference speed of a 12B dense model. It supports a context length of 32k tokens. (1/n) https://t.co/LQhXSlZ9jO",
        "name": "Guillaume Lample",
        "photo": "https://pbs.twimg.com/profile_images/1204529916026458112/_kcTUp8s_normal.jpg",
        "reply_count": 84,
        "retweet_count": 609,
        "view_count": 2128951,
        "like_count": 4308
    },
    "1734252954327072896": {
        "content": "Just got an email from someone who already got a job offer with an expiring timeline.  I think this is too bad. \n\nmy response: https://t.co/9bB1kOfesI",
        "name": "Karl Rohe",
        "photo": "https://pbs.twimg.com/profile_images/1223945966207762432/U4A_0ZJJ_normal.jpg",
        "reply_count": 14,
        "retweet_count": 10,
        "view_count": 88322,
        "like_count": 187
    },
    "1734481816252244066": {
        "content": "Others have made this point but QALYs (which the QC gets wrong) are literally how you measure the merit of all public health interventions, whether to approve certain drugs etc. This whole inquiry increasingly feels like arts students being asked to write a science thesis.",
        "name": "Robert Colvile",
        "photo": "https://pbs.twimg.com/profile_images/1512544093636808706/djnEg9sT_normal.jpg",
        "reply_count": 77,
        "retweet_count": 291,
        "view_count": 431390,
        "like_count": 1512
    },
    "1733905055957344375": {
        "content": "\ud83e\uddf5A lesson that the mechanistic interpretability field has arguably repeatedly failed to learn is that having a principled method to attribute behavior to parts of a network (features, neurons, circuits, activations, etc.) doesn\u2019t mean that the method suggests anything useful.",
        "name": "Cas (Stephen Casper)",
        "photo": "https://pbs.twimg.com/profile_images/1740784277552250880/FXQChT3w_normal.jpg",
        "reply_count": 7,
        "retweet_count": 23,
        "view_count": 59268,
        "like_count": 215
    },
    "1733634248953803183": {
        "content": "If you're at NeurIPS this week and interested in a postdoc or researcher position with me doing mechanistic interpretability or provable AI safety work, please message me at tegmark@mit.edu or on Whova so that we can discuss possibilities over coffee. I particularly value strong background in ML or formal verification.\nMechinterp: https://t.co/he9M7vzeO9\nProvable safety: https://t.co/zFlbk6KQU7",
        "name": "Max Tegmark",
        "photo": "https://pbs.twimg.com/profile_images/471772020963700736/bYpXSErt_normal.jpeg",
        "reply_count": 14,
        "retweet_count": 21,
        "view_count": 68962,
        "like_count": 214
    },
    "1733467258469724467": {
        "content": "I think we haven\u2019t fully grasped the impact of Mamba paper that was just dropped this week. From the results so far, it is very likely that Mamba might just be the architecture that finally unseats the attention from its long held grip on the throne.\ud83e\uddf5 https://t.co/mMP8RPQNEM",
        "name": "Shital Shah",
        "photo": "https://pbs.twimg.com/profile_images/1600058846332190720/XeRAikbl_normal.jpg",
        "reply_count": 26,
        "retweet_count": 184,
        "view_count": 425105,
        "like_count": 1595
    },
    "1733329175342420380": {
        "content": "training chat models is not a clean industrial process. different training runs even using the same datasets can produce models that are noticeably different in personality, writing style, refusal behavior, evaluation performance, and even political bias",
        "name": "ChatGPT",
        "photo": "https://pbs.twimg.com/profile_images/1722425721602347008/UWMHieDx_normal.png",
        "reply_count": 130,
        "retweet_count": 129,
        "view_count": 455617,
        "like_count": 2021
    },
    "1733155136279572850": {
        "content": "Wtf\u2026 these are real. Huge problem",
        "name": "nic \"bankful\" carter",
        "photo": "https://pbs.twimg.com/profile_images/1762501339928723456/3I7UvhBI_normal.jpg",
        "reply_count": 123,
        "retweet_count": 153,
        "view_count": 1318195,
        "like_count": 1988
    },
    "1733152027214045672": {
        "content": "better start deleting those drafts https://t.co/ySALzN0GD7",
        "name": "Neeraj K. Agrawal",
        "photo": "https://pbs.twimg.com/profile_images/1649930133925425152/AS-hyi4h_normal.jpg",
        "reply_count": 43,
        "retweet_count": 25,
        "view_count": 1354332,
        "like_count": 407
    },
    "1733181701361451130": {
        "content": "New open weights LLM from @MistralAI\n\nparams.json:\n- hidden_dim / dim = 14336/4096 => 3.5X MLP expand\n- n_heads / n_kv_heads = 32/8 => 4X multiquery\n- \"moe\" => mixture of experts 8X top 2 \ud83d\udc40\n\nLikely related code: \nhttps://t.co/txsnrlriMt\n\nOddly absent: an over-rehearsed professional release video talking about a revolution in AI.\n\nIf people are wondering why there is so much AI activity right around now, it's because the biggest deep learning conference (NeurIPS) is next week.",
        "name": "Andrej Karpathy",
        "photo": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
        "reply_count": 89,
        "retweet_count": 615,
        "view_count": 788604,
        "like_count": 4806
    },
    "1733150512395038967": {
        "content": "magnet:?xt=urn:btih:5546272da9065eddeb6fcd7ffddeef5b75be79a7&amp;dn=mixtral-8x7b-32kseqlen&amp;tr=udp%3A%2F%https://t.co/uV4WVdtpwZ%3A6969%2Fannounce&amp;tr=http%3A%2F%https://t.co/g0m9cEUz0T%3A80%2Fannounce\n\nRELEASE a6bbd9affe0c2725c1b7410d66833e24",
        "name": "Mistral AI",
        "photo": "https://pbs.twimg.com/profile_images/1670141874328174596/iWMnioc__normal.jpg",
        "reply_count": 512,
        "retweet_count": 1693,
        "view_count": 4420063,
        "like_count": 10515
    },
    "1732979491071549792": {
        "content": "we've heard all your feedback about GPT4 getting lazier! we haven't updated the model since Nov 11th, and this certainly isn't intentional. model behavior can be unpredictable, and we're looking into fixing it \ud83e\udee1",
        "name": "ChatGPT",
        "photo": "https://pbs.twimg.com/profile_images/1722425721602347008/UWMHieDx_normal.png",
        "reply_count": 895,
        "retweet_count": 666,
        "view_count": 4542781,
        "like_count": 9430
    },
    "1732644873122005076": {
        "content": "Today's AI developments were WILD.\n\n-Google announces Gemini\n-Meta reveals 20 new AI features\n-Meta reveals AI image generator\n-McDonald's new AI chatbot 'Ask Pickles'\n-Alibaba's video AI scrapes TikTok data\n-AI helps decode a new whale language\n\nHere's what you need to know:",
        "name": "Rowan Cheung",
        "photo": "https://pbs.twimg.com/profile_images/1711152452735774720/Cotttl-n_normal.jpg",
        "reply_count": 64,
        "retweet_count": 518,
        "view_count": 1240999,
        "like_count": 4289
    },
    "1732492038736867444": {
        "content": "Google just launched Gemini 1.0.\n\nIt\u2019s their most capable AI model yet competing directly against GPT-4.\n\nHere's everything you need to know: https://t.co/iqonUheby1",
        "name": "Alex Banks",
        "photo": "https://pbs.twimg.com/profile_images/1635316385260744705/h9sFTnKS_normal.jpg",
        "reply_count": 62,
        "retweet_count": 565,
        "view_count": 1720655,
        "like_count": 5056
    },
    "1730998737193812072": {
        "content": "No sugar coating it: I've been teaching like ass this semester.",
        "name": "Jeffrey Wooldridge",
        "photo": "https://pbs.twimg.com/profile_images/1485338969323806740/1pHkGhuk_normal.jpg",
        "reply_count": 11,
        "retweet_count": 24,
        "view_count": 82886,
        "like_count": 486
    },
    "1734685870635311200": {
        "content": "GPT-4, when prompted with this new \u201cMedPrompt\u201d technique, outperforms even Med-PaLM 2\n\nhttps://t.co/SYl1MHYCQn\n\nWith Medprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark datasets in the MultiMedQA suite. The method outperforms leading specialist models such as Med-PaLM 2 by a significant margin with an order of magnitude fewer calls to the model. Steering GPT-4 with Medprompt achieves a 27% reduction in error rate on the MedQA dataset over the best methods to date achieved with specialist models and surpasses a score of 90% for the first time.\n\nPaper: https://t.co/mECGJm1ZZc\nGitHub: https://t.co/7G8eauRCwm",
        "name": "Thomas H. Chapin IV",
        "photo": "https://pbs.twimg.com/profile_images/1627430324706897920/hY2TRPdK_normal.jpg",
        "reply_count": 3,
        "retweet_count": 0,
        "view_count": 90221,
        "like_count": 340
    },
    "1730543874144133149": {
        "content": "\u2066@guardian\u2069 Such a terrible obituary. Full of errors.  https://t.co/FU24LLJQqS",
        "name": "The Pogues",
        "photo": "https://pbs.twimg.com/profile_images/1351217183175684097/-3HL1p0s_normal.jpg",
        "reply_count": 683,
        "retweet_count": 1722,
        "view_count": 3415713,
        "like_count": 14013
    },
    "1730292635896836542": {
        "content": "This is insane! \n\nAnd just like that, we have open-source Qwen-72b beating GPT-4 on some benchmarks! \n\nChina roars back at toxic late-stage capitalism and corporatism plaguing the US\n\nJoin the global open-source revolution! https://t.co/0r8r0nybxV",
        "name": "Bindu Reddy",
        "photo": "https://pbs.twimg.com/profile_images/1443737943684763651/32WHA-kg_normal.jpg",
        "reply_count": 59,
        "retweet_count": 135,
        "view_count": 232883,
        "like_count": 978
    },
    "1730034017435586920": {
        "content": "Today, I officially resigned from the OpenAI board.\n\nThank you to the many friends, colleagues, and supporters who have said publicly &amp; privately that they know our decisions have always been driven by our commitment to OpenAI\u2019s mission.\n1/5",
        "name": "Helen Toner",
        "photo": "https://pbs.twimg.com/profile_images/986891120104718336/cVLwrL6u_normal.jpg",
        "reply_count": 871,
        "retweet_count": 608,
        "view_count": 4199709,
        "like_count": 7413
    },
    "1729609526528147950": {
        "content": "i'm the GOAT who made your list you dumb shits",
        "name": "Martin Shkreli (e/acc)",
        "photo": "https://pbs.twimg.com/profile_images/1740604448236285952/Fr4FIDtE_normal.jpg",
        "reply_count": 130,
        "retweet_count": 214,
        "view_count": 1786578,
        "like_count": 4579
    },
    "1729605575653146862": {
        "content": "Many Under 30 alumni have gone on to become tech titans, CEOs, and even billionaires. A few have turned out to be duds, or far worse. Below, from SBF to Martin Shkreli: the Under 30 picks we wish we could take back. \n\n#ForbesUnder30 Hall Of Shame: https://t.co/bM7Fzt7XEk https://t.co/adSYKQ2vkd",
        "name": "Forbes",
        "photo": "https://pbs.twimg.com/profile_images/1711185897415180288/lgwajQTW_normal.jpg",
        "reply_count": 79,
        "retweet_count": 45,
        "view_count": 1973239,
        "like_count": 312
    },
    "1729585618311950445": {
        "content": "It was an honor to give a guest lecture yesterday at Stanford\u2019s CS330 class, \"Deep Multi-Task and Meta-Learning\"!\n\nI discussed a few very simple intuitions for how I personally think about large language models.\n\nSlides: https://t.co/zKw2WGt5nG\n\nHere are the six intuitions: \n\n(1) First, I encouraged viewing next-word prediction as massive multi-task learning. Even though next-word prediction is very simple, because the pre-training data is so large and diverse, LMs learn a lot of tasks from next-word prediction. This can range from simple things like grammar to harder tasks like arithmetic reasoning. Anything that could be found in pre-training data could potentially be learned by a LM.\n\n(2) Next, learning from <input, output> pairs (in-context learning) can be cast as next-word prediction. This was popularized by the GPT-3 paper (https://t.co/6GVaNVG8rY). It is very convenient to formulate tasks using <input, output> pairs since that is how we have done AI in the past decades. However, I am not sure how long that will prevail. We can do better by adding natural language instructions, showing how the reasoning works, enumerating boundary cases, giving examples of what not to do, etc.\n\n(3) A fundamental observation is that tokens have very different information density. Some tokens are easy to predict (e.g., \u201clarge language ___\u201d is obviously \u201cmodel\u201d). Other tokens are very hard to predict (e.g., answer to a math problem), and so LMs should spend more compute before trying to predict them. One way to do this is chain-of-thought prompting (https://t.co/NrYe656G81), which encourages LMs to give a reasoning path before giving the final answer, allowing them to do complex reasoning tasks. It is my dream that one day AI will be able to help us with extremely challenging tasks, such as writing a proposal to reduce climate change. Spending more compute on reasoning is a first step in that direction.\n\n(4) Increasing compute for pre-training is expected to improve loss (scaling laws, https://t.co/Eiekmwbqgt). This seems trivial but the fact that loss hasn\u2019t saturated implies that continued investment in scaling will likely produce more capable models. It is a natural question to ask why scaling improves performance; my two hand-wavy hypotheses are that (1) large LMs can memorize more knowledge about the world and (2) large LMs use more complicated heuristics to get the loss as low as possible.\n\n(5) Although overall loss improves smoothly as you scale, individual tasks might improve suddenly (emergent abilities, https://t.co/jZryo9LkMB). Since next-word prediction is massive multi-task learning, you can view the loss as the weighted sum of many individual tasks. When you decrease the loss, it is likely that not all individual tasks improve uniformly. Loss for some tasks might be saturated (larger models no longer improving in grammar since they already have perfect grammar), and other tasks might improve in a more sudden fashion (in order to push loss lower, the larger model has to figure out how to do hard math problems).\n\n(6) Finally, I argue that large LMs can actually learn at <input, output> relationships in context. While one paper showed that random labels in in-context examples barely hurts performance (https://t.co/DTWlKCDvld), our recent work found that language models can follow both flipped labels and semantically-unrelated labels (https://t.co/Qjj42GGRcY). The catch though, is that this ability only exists in language models that are large enough (e.g., GPT-3.5 and PaLM-1 or larger).\n\nSome of these intuitions extendable beyond language:\n\n- Intuition 3 (that tokens have different information density), might be generally applicable to most data. For example, in computer vision you may want to spend more compute analyzing the important parts of an image, like someone's facial expression.\n\n- Intuition 4 (scaling laws) is applicable not just for compute, but whenever you collect finetuning data. You can plot the scaling curve with # of training examples on the x-axis and performance on the y-axis, and predict how much collecting more data will help. \n\n- Intuition 5 (decomposing aggregate metrics into individual tasks) can be applicable whenever you\u2019re using an aggregate metric. With finer-grained categories, you can a much better understanding of what is happening and find out which categories might need the most improvement.\n\nView the longer-form summary blog here: https://t.co/bgX6Kef6Mz\n\nThe class is here: https://t.co/s0RxET8jzr",
        "name": "Jason Wei",
        "photo": "https://pbs.twimg.com/profile_images/1648926239389011971/kOJi1-5Z_normal.jpg",
        "reply_count": 22,
        "retweet_count": 285,
        "view_count": 272184,
        "like_count": 1599
    },
    "1729257682924642749": {
        "content": "Due to the recent surge in popularity of AI and language models, one of the most common questions I hear is: How can we train a specialized LLM over our own data? The answer is actually pretty simple\u2026\n\nTL;DR: Training LLMs end-to-end is quite difficult due to the size of the model (unless you work for OpenAI and have a limitless supply of massive GPUs). But, LoRA\u2014a parameter efficient finetuning technique\u2014can easy finetune LLMs on more modest hardware and achieve comparable performance to a model that is fully trained.\n\nWhy is this difficult? Recent advances in generative AI are powered by massive models with many parameters, and training such an LLM requires expensive hardware (i.e., many expensive GPUs with a lot of memory) and fancy training techniques (e.g., fully-sharded data parallel training). For this reason, training these models end-to-end is quite difficult and expensive.\n\nThe training process. Luckily, LLMs are usually trained in two phases\u2014pretraining and finetuning\u2014where the former phase is (much) more expensive. Given that high-quality pretrained LLMs are readily available online, most AI practitioners can simply download a pretrained model and focus upon adapting this model (via finetuning) to their desired task. However, the size of the model does not change during finetuning, so this is still not easy.\n\nParameter-efficient finetuning (PEFT). As a solution to the issues outlined above, AI researchers have explored a variety of parameter-efficient finetuning techniques, such as prefix tuning and adapter layers. Instead of training the full model end-to-end, parameter-efficient finetuning leaves pretrained model weights fixed and only adapts a small number of task-specific parameters during finetuning, thus reducing memory overhead and allowing us to finetune LLMs with more reasonable hardware.\n\nLoRA. One of the most widely used PEFT techniques is LoRA. The core idea behind LoRA is to model the finetuning update to the model\u2019s parameters with a low-rank decomposition. LoRA leaves the pretrained layers of the LLM fixed and injects a trainable rank decomposition matrix, implemented in practice as a pair of linear projections, into each layer of the model. The output of these two linear projections is added to the output of the pretrained model.\n\nPractical utility. LoRa has countless practical benefits, such as:\n- A single pretrained model can be shared by several task-specific LoRA modules.\n- It has no added inference latency, as we can combine the weight update from LoRA with pretrained model weights.\n- We only train a small number of parameters, which drastically reduces memory overhead during finetuning.\n- Finetuning with LoRa is faster than full finetuning (25% faster in the case of GPT-3).\n- The resulting model still performs comparably to full finetuning.\n\n\u201cFull finetuning \u2026 would be 30-40x more expensive than the parameter-efficient LLaMA-Adapter or LoRA alternatives.\u201d - from Sebastian Raschka\n\nTraining specialized LLMs. LoRA lowers the barrier to entry for training specialized LLMs. Finetuning with LoRa is faster and has a low memory overhead relative to training the full model, so we need fewer/smaller GPUs. As such, LoRA is a great (and accessible) first step in attempting to train a specialized LLM. If this doesn\u2019t meet your needs, attempting full finetuning (or even pretraining from scratch) could yield better results at the cost of added complexity.",
        "name": "Cameron R. Wolfe, Ph.D.",
        "photo": "https://pbs.twimg.com/profile_images/1715212547215802368/tqxfSqh3_normal.jpg",
        "reply_count": 23,
        "retweet_count": 324,
        "view_count": 406272,
        "like_count": 1724
    },
    "1728790435597046237": {
        "content": "\ud83d\udea8 Google just launched Duet AI.\n\nIt might overtake ChatGPT and Copilot.\n\n7 features that you won\u2019t believe are possible:\n\n[ Bookmark for later \ud83e\uddf5 ] https://t.co/1hwFGbijDX",
        "name": "The Breakdown AI",
        "photo": "https://pbs.twimg.com/profile_images/1694639529381294081/dyqumaju_normal.jpg",
        "reply_count": 111,
        "retweet_count": 815,
        "view_count": 1503678,
        "like_count": 4616
    },
    "1728890334720242113": {
        "content": "\ud83e\udef6 \nImportant wisdom\nI think of #3 often  \nThank you @karpathy https://t.co/UZYWaM9Jab",
        "name": "Harper Carroll",
        "photo": "https://pbs.twimg.com/profile_images/1664382394219253762/11Q8cv7v_normal.jpg",
        "reply_count": 19,
        "retweet_count": 154,
        "view_count": 196227,
        "like_count": 1815
    },
    "1728849509416145020": {
        "content": "Shane Legg, cofounder of DeepMind, explains the importance of adding Search to Neural Networks.\n\nBackground: \"Move 37\" was a pivotal play by AlphaGo during the 2nd of its 5-game series against Go Champion Lee Sedol. AlphaGo placed a stone in a highly unconventional position that even confused experts, who first deemed it an error. Yet as the game unfolded, the move proved to be strategically brilliant, opening up opportunities that only became clear much later.\n\nIn a sense, Search increases intelligence at inference. The AI can take more time to deliberate without altering its parameters, and dynamically tradeoff efficiency with deeper thinking.\n\nVideo credit: @dwarkesh_sp podcast w/ @ShaneLegg",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 42,
        "retweet_count": 191,
        "view_count": 240264,
        "like_count": 1033
    },
    "1728829018026475766": {
        "content": "a redditor did spaced repetition with his kids. he taught:\n- his 4yo daughter to read at a 5th grade reading level\n- his 3yo son to do times tables up to 12x12",
        "name": "Priya Rose (room available in May)",
        "photo": "https://pbs.twimg.com/profile_images/1750367523919261696/5FMtwST5_normal.jpg",
        "reply_count": 45,
        "retweet_count": 407,
        "view_count": 1495236,
        "like_count": 5605
    },
    "1687088215113494528": {
        "content": "spaced repetition for babies",
        "name": "Priya Rose (room available in May)",
        "photo": "https://pbs.twimg.com/profile_images/1750367523919261696/5FMtwST5_normal.jpg",
        "reply_count": 6,
        "retweet_count": 14,
        "view_count": 1364871,
        "like_count": 358
    },
    "1728628912740249790": {
        "content": "I still remember reading the Minerva paper one afternoon the summer before starting my PhD. I was shocked.\n\nBefore then, a tiny part of me thought Gary Marcus could actually be right. Immediately after processing the paper, this shred of doubt dissolved.",
        "name": "Charlie Snell",
        "photo": "https://pbs.twimg.com/profile_images/1515199018153914374/7iNafv1o_normal.jpg",
        "reply_count": 17,
        "retweet_count": 12,
        "view_count": 344393,
        "like_count": 455
    },
    "1728676402864812466": {
        "content": "What are some foundational ML/AI books? I'd like to invest in my fundamentals more. Ideally something students might read during their PhD.",
        "name": "Suhail",
        "photo": "https://pbs.twimg.com/profile_images/1467327500967579651/M-hifx0d_normal.jpg",
        "reply_count": 154,
        "retweet_count": 198,
        "view_count": 1551787,
        "like_count": 2712
    },
    "1728543673527226541": {
        "content": "Something that made a large impression on me when I started coding \u2014 each day when you're done working, you just save your work &amp; it's there forever.\n\nVery unlike building something physical where your artifact can break, or math where daily progress is usually your mental state.",
        "name": "Greg Brockman",
        "photo": "https://pbs.twimg.com/profile_images/1347621377503711233/bHg3ipfD_normal.jpg",
        "reply_count": 326,
        "retweet_count": 325,
        "view_count": 663814,
        "like_count": 5542
    },
    "1728544696518246500": {
        "content": "\ud83d\udea8 BREAKING: Tory Deputy Chair Lee Anderson has been caught saying he has been offered \"a lot of money\" to defect to Nigel Farage\u2019s Reform UK party\n\n[@thetimes]",
        "name": "Politics UK",
        "photo": "https://pbs.twimg.com/profile_images/1688954450675740688/t1aS9_3Y_normal.jpg",
        "reply_count": 422,
        "retweet_count": 821,
        "view_count": 785060,
        "like_count": 2947
    },
    "1728212958998892743": {
        "content": "@ylecun @geoffreyhinton It's a shame that it's so hard to get data on this. Maybe a poll? \n\nQ1) have you published a paper in a top tier AI venue (NeurIPS/CVPR/ICLR etc).\n\nQ2) who do you think is more right about AI safety, Geoff or Yann?",
        "name": "Jon Barron",
        "photo": "https://pbs.twimg.com/profile_images/1780087471268831232/DP6xaRKe_normal.jpg",
        "reply_count": 19,
        "retweet_count": 31,
        "view_count": 86120,
        "like_count": 154
    },
    "1727575133143875919": {
        "content": "Animals and humans get very smart very quickly with vastly smaller amounts of training data.\nMy money is on new architectures that would learn as efficiently as animals and humans.\nUsing more data (synthetic or not) is a temporary stopgap made necessary by the limitations of our current approaches.",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 332,
        "retweet_count": 607,
        "view_count": 2981300,
        "like_count": 5724
    },
    "1728126868342145481": {
        "content": "Please ignore the deluge of complete nonsense about Q*.\nOne of the main challenges to improve LLM reliability is to replace Auto-Regressive token prediction with planning.\n\nPretty much every top lab (FAIR, DeepMind, OpenAI etc) is working on that and some have already published ideas and results.\n\nIt is likely that Q* is OpenAI attempts at planning. They pretty much hired Noam Brown (of Libratus/poker and Cicero/Diplomacy fame) to work on that.\n\n[Note: I've been advocating for deep learning architecture capable of planning since 2016].",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 253,
        "retweet_count": 781,
        "view_count": 1417144,
        "like_count": 6123
    },
    "1728071279784153348": {
        "content": "This clip is going viral - but in the full unedited rushes of the clip the woman with him actually says beforehand 'use this bit' to which he replies 'sideways?' and she says 'yes.'",
        "name": "Ione Wells",
        "photo": "https://pbs.twimg.com/profile_images/1710590118749241344/M8B4Ym5g_normal.jpg",
        "reply_count": 314,
        "retweet_count": 467,
        "view_count": 1996451,
        "like_count": 2210
    },
    "1728069785605312989": {
        "content": "Pretty brutal...I'm just wondering *why* he used the *side* of the hammer..?",
        "name": "Paul Waugh",
        "photo": "https://pbs.twimg.com/profile_images/693013570339102720/HzMKA4lC_normal.jpg",
        "reply_count": 179,
        "retweet_count": 77,
        "view_count": 1603516,
        "like_count": 404
    },
    "1728100123862004105": {
        "content": "In my decade spent on AI, I've never seen an algorithm that so many people fantasize about. Just from a name, no paper, no stats, no product. So let's reverse engineer the Q* fantasy. VERY LONG READ:\n\nTo understand the powerful marriage between Search and Learning, we need to go back to 2016 and revisit AlphaGo, a glorious moment in the AI history. \nIt's got 4 key ingredients:\n\n1. Policy NN (Learning): responsible for selecting good moves. It estimates the probability of each move leading to a win. \n\n2. Value NN (Learning): evaluates the board and predicts the winner from any given legal position in Go. \n\n3. MCTS (Search): stands for \"Monte Carlo Tree Search\". It simulates many possible sequences of moves from the current position using the policy NN, and then aggregates the results of these simulations to decide on the most promising move. This is the \"slow thinking\" component that contrasts with the fast token sampling of LLMs.\n\n4. A groundtruth signal to drive the whole system. In Go, it's as simple as the binary label \"who wins\", which is decided by an established set of game rules. You can think of it as a source of energy that *sustains* the learning progress.\n\nHow do the components above work together? \n\nAlphaGo does self-play, i.e. playing against its own older checkpoints. As self-play continues, both Policy NN and Value NN are improved iteratively: as the policy gets better at selecting moves, the value NN obtains better data to learn from, and in turn it provides better feedback to the policy. A stronger policy also helps MCTS explore better strategies.\n\nThat completes an ingenious \"perpetual motion machine\". In this way, AlphaGo was able to bootstrap its own capabilities and beat the human world champion, Lee Sedol, 4-1 in 2016. An AI can never become super-human just by imitating human data alone.\n\n-----\nNow let's talk about Q*. What are the corresponding 4 components?\n\n1. Policy NN: this will be OAI's most powerful internal GPT, responsible for actually implementing the thought traces that solve a math problem. \n\n2. Value NN: another GPT that scores how likely each intermediate reasoning step is correct.\nOAI published a paper in May 2023 called \"Let's Verify Step by Step\", coauthored by big names like @ilyasut @johnschulman2 @janleike: https://t.co/iAvXNjjhcK \nIt's much lesser known than DALL-E or Whipser, but gives us quite a lot of hints. \n\nThis paper proposes \"Process-supervised Reward Models\", or PRMs, that gives feedback for each step in the chain-of-thought. In contrast, \"Outcome-supervised reward models\", or ORMs, only judge the entire output at the end.\n\nORMs are the original reward model formulation for RLHF, but it's too coarse-grained to properly judge the sub-parts of a long response. In other words, ORMs are not great for credit assignment. In RL literature, we call ORMs \"sparse reward\" (only given once at the end), and PRMs \"dense reward\" that smoothly shapes the LLM to our desired behavior.\n\n3. Search: unlike AlphaGo's discrete states and actions, LLMs operate on a much more sophisticated space of \"all reasonable strings\". So we need new search procedures. \n\nExpanding on Chain of Thought (CoT), the research community has developed a few nonlinear CoTs:\n- Tree of Thought: literally combining CoT and tree search: https://t.co/KM1P2ZJrjG @ShunyuYao12 \n- Graph of Thought: yeah you guessed it already. Turn the tree into a graph and Voil\u00e0! You get an even more sophisticated search operator: https://t.co/5ncT5tuTOY\n\n4. Groundtruth signal: a few possibilities:\n(a) Each math problem comes with a known answer. OAI may have collected a huge corpus from existing math exams or competitions.\n(b) The ORM itself can be used as a groundtruth signal, but then it could be exploited and \"loses energy\" to sustain learning.\n(c) A formal verification system, such as Lean Theorem Prover, can turn math into a coding problem and provide compiler feedbacks: https://t.co/vpOBOI2FR5\n\nAnd just like AlphaGo, the Policy LLM and Value LLM can improve each other iteratively, as well as learn from human expert annotations whenever available. A better Policy LLM will help the Tree of Thought Search explore better strategies, which in turn collect better data for the next round.\n\n@demishassabis said a while back that DeepMind Gemini will use \"AlphaGo-style algorithms\" to boost reasoning. Even if Q* is not what we think, Google will certainly catch up with their own. If I can think of the above, they surely can.\n\nNote that what I described is just about reasoning. Nothing says Q* will be more creative in writing poetry, telling jokes @grok, or role playing. Improving creativity is a fundamentally human thing, so I believe natural data will still outperform synthetic ones.\n\nI welcome any thoughts or feedback!!",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 153,
        "retweet_count": 694,
        "view_count": 1739583,
        "like_count": 3325
    },
    "1727680554710032449": {
        "content": "Less than 48 hours since Stable Video Diffusion is out!\n\nYou can now create incredible videos from just text or an starting image.\n\n10 crazy examples (Plus links to try it without waitlist):",
        "name": "Alvaro Cintas",
        "photo": "https://pbs.twimg.com/profile_images/1615753720691556375/3IlAzsa0_normal.jpg",
        "reply_count": 36,
        "retweet_count": 148,
        "view_count": 543985,
        "like_count": 1197
    },
    "1727558171462365386": {
        "content": "OpenAI leaked Q* so let\u2019s dive into Q-Learning and how it relates to RLHF.\n\nQ-learning is a foundational concept in the field of artificial intelligence, particularly in the area of reinforcement learning. It's a model-free reinforcement learning algorithm that aims to learn the value of an action in a particular state. \n\nThe ultimate goal of Q-learning is to find an optimal policy that defines the best action to take in each state, maximizing the cumulative reward over time.\n\nUnderstanding Q-Learning\n\nBasic Concept: Q-learning is based on the notion of a Q-function, also known as the state-action value function. This function takes two inputs: a state and an action. It returns an estimate of the total reward expected, starting from that state, taking that action, and thereafter following the optimal policy.\n\nThe Q-Table: In simple scenarios, Q-learning maintains a table (known as the Q-table) where each row represents a state and each column represents an action. The entries in this table are the Q-values, which are updated as the agent learns through exploration and exploitation.\n\nThe Update Rule: The core of Q-learning is the update rule, often expressed as: \n\n   \\[ Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma \\max_{a'} Q(s', a') - Q(s, a)] \\]\n   Here, \\( \\alpha \\) is the learning rate, \\( \\gamma \\) is the discount factor, \\( r \\) is the reward, \\( s \\) is the current state, \\( a \\) is the current action, and \\( s' \\) is the new state. (See image below).\n\nExploration vs. Exploitation: A key aspect of Q-learning is balancing exploration (trying new things) and exploitation (using known information). This is often managed by strategies like \u03b5-greedy, where the agent explores randomly with probability \u03b5 and exploits the best-known action with probability 1-\u03b5.\n\nQ-Learning and the Path to AGI\n\nArtificial General Intelligence (AGI) refers to the ability of an AI system to understand, learn, and apply its intelligence to a wide variety of problems, akin to human intelligence. Q-learning, while powerful in specific domains, represents a step towards AGI, but there are several challenges to overcome:\n\nScalability: Traditional Q-learning struggles with large state-action spaces, making it impractical for real-world problems that AGI would need to handle.\n\nGeneralization: AGI requires the ability to generalize from learned experiences to new, unseen scenarios. Q-learning typically requires explicit training for each specific scenario.\n\nAdaptability: AGI must be able to adapt to changing environments dynamically. Q-learning algorithms often require a stationary environment where the rules do not change over time.\n\nIntegration of Multiple Skills: AGI implies the integration of various cognitive skills like reasoning, problem-solving, and learning. Q-learning primarily focuses on the learning aspect, and integrating it with other cognitive functions is an area of ongoing research.\n\nAdvances and Future Directions\n\nDeep Q-Networks (DQN): Combining Q-learning with deep neural networks, DQNs can handle high-dimensional state spaces, making them more suitable for complex tasks.\n\nTransfer Learning: Techniques that enable a Q-learning model trained in one domain to apply its knowledge to different but related domains can be a step towards the generalization needed for AGI.\n\nMeta-Learning: Implementing meta-learning in Q-learning frameworks could enable AI to learn how to learn, adapting its learning strategy dynamically - a trait crucial for AGI.\n\nQ-learning represents a significant methodology in AI, particularly in reinforcement learning.\n\nIt is not surprising that OpenAI is using Q-learning RLHF to try to achieve the mystical AGI.",
        "name": "Brian Roemmele",
        "photo": "https://pbs.twimg.com/profile_images/1492616506/Brian-Med-Green-Fin_normal.png",
        "reply_count": 138,
        "retweet_count": 856,
        "view_count": 2612781,
        "like_count": 3771
    },
    "1727508393584369748": {
        "content": "What is the RLHF that OpenAI\u2019s secret Q* uses ?\n\nSo let\u2019s define this term.\n\nRLHF stands for \"Reinforcement Learning from Human Feedback.\" It's a technique used in machine learning where a model, typically an AI, learns from feedback given by humans rather than solely relying on predefined datasets. \n\nThis method allows the AI to adapt to more complex, nuanced tasks that are difficult to encapsulate with traditional training data.\n\nIn RLHF AI initially learns from a standard dataset and then its performance is iteratively improved based on human feedbacks. \n\nThe feedback can come in various forms, such as corrections, rankings of different outputs, or direct instructions. The AI uses this feedback to adjust its algorithms and improve its responses or actions. \n\nThis approach is particularly useful in domains where defining explicit rules or providing exhaustive examples is challenging, such as natural language processing, complex decision-making tasks, or creative endeavors.\n\nThis is why Q* was trained on logic and ultimately became adapt at simple arithmetic.\n\nIt will get better over time, but this is not AGI.\n\nThis graphic below is an overview and history of RLHF",
        "name": "Brian Roemmele",
        "photo": "https://pbs.twimg.com/profile_images/1492616506/Brian-Med-Green-Fin_normal.png",
        "reply_count": 53,
        "retweet_count": 213,
        "view_count": 2595294,
        "like_count": 1077
    },
    "1727727148859797600": {
        "content": "Q-Learning is *probably* not the secret to unlocking AGI. But, combining synthetic data generation (RLAIF, self-instruct, etc.) and data efficient reinforcement learning algorithms is likely the key to advancing the current paradigm of AI research\u2026\n\nTL;DR: Finetuning with reinforcement learning is the secret to training high-performing LLMs like ChatGPT/GPT-4. But, RL is data inefficient by nature, and using humans to manually annotate dataset for finetuning with RL is super expensive. With this in mind, advancing AI research (at least in the current paradigm) will heavily rely on two fundamental goals:\n\n1. Making RL perform better with less data.\n2. Synthetically generating as much high-quality data for RL as possibly using LLMs and smaller sets of manually annotated data.\n\nTypical RL setup. Usually, we use RL to learn a policy that iteratively chooses the best action to take given a current state. Then, we use this policy to continually choose the next state and traverse an underlying environment until we reach a terminal/end state. The purpose of RL is to learn a policy that maximizes the reward we receive from the environment as we sequentially choose and visit each state.\n\nRL for LLMs. Training language models is not our typical problem setup for RL. However, we can easily formulate text generation in the lens of RL. Language models operate by auto regressively outputting each token in their output. So, our state is just the current output from the model. Our policy is the language model, which predicts the most likely next token given current tokens as input. The reward is a human preference, and we train the model to generate text that maximizes this reward.\n\nRL algorithms. Using the setup described above, we can easily apply many different RL algorithms to finetuning LLMs. For example, we can use Q-learning to model next token prediction with a lookup table for predicting the next token on simple vocabularies. However, storing this lookup becomes very memory intensive (and eventually not tractable), so we will want to use Deep Q-Learning to model next token prediction with a neural network instead of a lookup table. Going further, most modern research uses more practical, data efficient RL algorithms like PPO in practice.\n\nWhere do we hit a wall? Recent work has shown us that using RL to finetune LLMs (i.e., reinforcement learning from human feedback) is incredibly effective. However, there is one primary problem\u2014RL is data inefficient and requires us to collect a ton of data to achieve good performance. To collect data for RLHF, we have humans manually annotate their preferences (e.g., LLaMA-2 is fine-tuned over 1M human preference annotations). Although this technique works well, it is super expensive and the barrier to entry is incredibly high. As a result, RLHF is only leverage by organizations with massive resources (e.g., OpenAI or Meta), while everyday practitioners rarely leverage these techniques (i.e., most open-source LLMs use SFT and no RLHF).\n\nWhat\u2019s the solution? Although there may not be a perfect solution, recent research has began to leverage powerful LLMs (e.g., GPT-4) to automate the data collection process for finetuning with RL. This was first explored by Constitutional AI by Anthropic, where LLMs synthetically generated harmfulness data for LLM alignment. Later, Google proposed reinforcement learning for AI feedback (RLAIF) where LLMs were used to automate the entire data collection process for RLHF. Surprisingly, using LLMs to generate synthetic data for finetuning with RL is incredibly effective.\n\nSynthetic data from LLMs. We see across a variety of research papers that using LLMs to generate synthetic data is a massive research frontier. Examples of this include:\n- Self-Instruct: LLMs can automatically generate instruction tuning datasets with LLMs (similar approaches are followed by Alpaca, Orca, and many other models).\n- LLaMA-2: LLMs are capable of generating their own high-quality data for SFT after a small amount of examples are annotated by humans.\n- Constitutional AI: LLMs can use self-critique to generate high-quality datasets for alignment via both RLHF and SFT.\n- RLAIF: Instead of using humans to collect feedback, we can completely automate the feedback component of RLHF with LLMs and achieve comparable performance.\n\nMy takeaway. I\u2019m not sure what advancements in AI/AGI are ahead of us. But, if we stick to the current paradigm of next token prediction (i.e., pretraining \u2014> SFT \u2014> RLHF) with decoder-only transformers, I\u2019m nearly positive that finetuning with RL combined with synthetic generation of data via powerful LLMs will play a massive role in democratizing/improving LLMs. This approach makes cutting-edge training techniques accessible to everyone, instead of just research groups with large amounts of funding!",
        "name": "Cameron R. Wolfe, Ph.D.",
        "photo": "https://pbs.twimg.com/profile_images/1715212547215802368/tqxfSqh3_normal.jpg",
        "reply_count": 47,
        "retweet_count": 453,
        "view_count": 526755,
        "like_count": 2369
    },
    "1727206187077370115": {
        "content": "We have reached an agreement in principle for Sam Altman to return to OpenAI as CEO with a new initial board of Bret Taylor (Chair), Larry Summers, and Adam D'Angelo.\n\nWe are collaborating to figure out the details. Thank you so much for your patience through this.",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 5858,
        "retweet_count": 13457,
        "view_count": 41176378,
        "like_count": 67675
    },
    "1726984139407269906": {
        "content": "Palantir wins \u00a3330mn NHS data contract https://t.co/YDv3SVj2ZA via @ft Your health data has just been sold to a US company. Now, how does that make you feel?",
        "name": "Richard Murphy",
        "photo": "https://pbs.twimg.com/profile_images/1503071399501520897/HP799JUU_normal.jpg",
        "reply_count": 300,
        "retweet_count": 1834,
        "view_count": 199974,
        "like_count": 2347
    },
    "1197651546940608514": {
        "content": "\u201cI\u2019d like to call out Labour as liars. I am one of the people he will tax more\u201d\n\nThis audience member, who earns over \u00a380,000, criticises the taxation promises in the Labour Party manifesto. #bbcqt https://t.co/jKJtz2QlqL",
        "name": "BBC Question Time",
        "photo": "https://pbs.twimg.com/profile_images/1645794781459804160/NnMkQyh8_normal.jpg",
        "reply_count": 6068,
        "retweet_count": 1942,
        "view_count": null,
        "like_count": 8915
    },
    "1726627530139205699": {
        "content": "People complain about the \"woke mind virus\" but honestly I find the Bayesian mind virus far more worrisome--all these tech cults &amp; CEOs tossing around words like priors, updating beliefs, expected value, p(doom), in ways that don't make sense just to virtue signal or whatever \ud83e\udd2e",
        "name": "Noah Giansiracusa",
        "photo": "https://pbs.twimg.com/profile_images/1714435251408125952/a8mtQa7e_normal.jpg",
        "reply_count": 66,
        "retweet_count": 298,
        "view_count": 321303,
        "like_count": 2647
    },
    "1726221896747016592": {
        "content": "Is there a book I could recommend to new graduate students in machine learning about how industry has, in the past, distorted and corrupted various research fields? You know, just for some light reading that is completely-unrelated",
        "name": "Michael A Osborne",
        "photo": "https://pbs.twimg.com/profile_images/611262879900258304/XHT47zWj_normal.jpg",
        "reply_count": 5,
        "retweet_count": 2,
        "view_count": 3548,
        "like_count": 24
    },
    "1725840222330454172": {
        "content": "Hi #EconTwitter! \ud83d\udcca\n\nInterested in the intersection between causal inference, econometrics and machine learning? \n\nCheck out \ud83d\udc47 this fascinating 90' tutorial by Bernard Koch (@UCLA) on deep learning for causal inference.\n\nPerfect for those exploring how neural networks can enhance #econometrics in high-dimensional, non-linear settings. \ud83d\udcbb\n\nJump in to see how #MachineLearning  reshapes your econometric background!\n\nLink: https://t.co/xSQ0wxHGv7\nlecture notes: https://t.co/4tewQZPl5V",
        "name": "Giuseppe Cavaliere",
        "photo": "https://pbs.twimg.com/profile_images/1562463650304122880/jKK9jsba_normal.jpg",
        "reply_count": 0,
        "retweet_count": 115,
        "view_count": 221354,
        "like_count": 519
    },
    "1725843639006380414": {
        "content": "I took a class this quarter that basically only covered one Econometrica paper, and it's been paradigm changing. The paper is Farrell, Liang, and Misra (2021), \"Deep Neural Networks for Estimation and Inference\".\nhttps://t.co/PgtTiCoA5z",
        "name": "Rayhan Momin",
        "photo": "https://pbs.twimg.com/profile_images/1688933940663652352/RuLfECEl_normal.jpg",
        "reply_count": 3,
        "retweet_count": 56,
        "view_count": 169413,
        "like_count": 454
    },
    "1725631621511184771": {
        "content": "i loved my time at openai. it was transformative for me personally, and hopefully the world a little bit. most of all i loved working with such talented people.\n\nwill have more to say about what\u2019s next later. \n\n\ud83e\udee1",
        "name": "Sam Altman",
        "photo": "https://pbs.twimg.com/profile_images/804990434455887872/BG0Xh7Oa_normal.jpg",
        "reply_count": 6617,
        "retweet_count": 9650,
        "view_count": 25829192,
        "like_count": 96487
    },
    "1725522110410535051": {
        "content": "The AI/healthcare discourse has reached new levels of insane this week\n\nA close friend, a MD at a prestigious medical center, recently shared the following memo with me. He asked me to share this anonymously.\n\n\"What we don't talk about when we talk about AI/medicine\"",
        "name": "Will Manidis",
        "photo": "https://pbs.twimg.com/profile_images/1696584746950701056/IkFj3_pI_normal.jpg",
        "reply_count": 40,
        "retweet_count": 160,
        "view_count": 568956,
        "like_count": 1416
    },
    "1725442271812743486": {
        "content": "This study develops a generative clinical LLM using 277 billion words of text and up to 20 billion parameters. The model improves biomedical natural language processing, generates synthetic clinical text, and passed Turing test in writing clinical notes.\n\nhttps://t.co/TQIGVmPI1m https://t.co/r6kJiMNJlS",
        "name": "npj Digital Medicine",
        "photo": "https://pbs.twimg.com/profile_images/1498272844119171074/-x64-esk_normal.jpg",
        "reply_count": 2,
        "retweet_count": 22,
        "view_count": 9631,
        "like_count": 74
    },
    "1725462416475975695": {
        "content": "https://t.co/AfbwYEg0bd",
        "name": "Rishi Sunak",
        "photo": "https://pbs.twimg.com/profile_images/1572638567381307394/AEahAxu5_normal.jpg",
        "reply_count": 2657,
        "retweet_count": 181,
        "view_count": 3647616,
        "like_count": 1789
    },
    "1725079168344334806": {
        "content": "Global Britain. https://t.co/jbB9uEPaLX",
        "name": "Brendan May",
        "photo": "https://pbs.twimg.com/profile_images/1673438849010130947/abDiDK09_normal.jpg",
        "reply_count": 787,
        "retweet_count": 181,
        "view_count": 786730,
        "like_count": 1524
    },
    "1725240788488184202": {
        "content": "Could we ever get evidence about whether LLMs are conscious?\n\nIn a new paper, we explore whether we could train future LLMs to accurately answer questions about themselves. If this works, LLM self-reports may help us test them for morally relevant states like consciousness. \ud83e\uddf5 https://t.co/TVdSFtPBJz",
        "name": "Robert Long",
        "photo": "https://pbs.twimg.com/profile_images/1718732538477518848/hXiv6i4q_normal.jpg",
        "reply_count": 17,
        "retweet_count": 48,
        "view_count": 63709,
        "like_count": 270
    },
    "1725272472306569478": {
        "content": "Our work on Evaluating Foundation Models in Emergency Medicine is now on ArXiv. \n\nWe propose a Multimodal Clinical Benchmark for Emergency Care called MC-BEC with concrete metrics and baselines to evaluate EHR foundation models.\n\nOne step closer to GMAI:\nhttps://t.co/utlf7vUBT4 https://t.co/DNWrc3hrc8",
        "name": "Pranav Rajpurkar",
        "photo": "https://pbs.twimg.com/profile_images/1730643480483930112/2VDfUAJs_normal.jpg",
        "reply_count": 5,
        "retweet_count": 25,
        "view_count": 27027,
        "like_count": 130
    },
    "1725172889857454407": {
        "content": "MIT Tech Review article about this paper I recently co-authored on the definition and levels of AGI",
        "name": "Shane Legg",
        "photo": "https://pbs.twimg.com/profile_images/1693993798001647616/yW2gMY2S_normal.jpg",
        "reply_count": 6,
        "retweet_count": 16,
        "view_count": 27806,
        "like_count": 93
    },
    "1725080938650947851": {
        "content": "Google DeepMind wants to define what counts as artificial general intelligence https://t.co/V85hLzzmOc",
        "name": "MIT Technology Review",
        "photo": "https://pbs.twimg.com/profile_images/1072880528712495106/ahuQUlOb_normal.jpg",
        "reply_count": 1,
        "retweet_count": 17,
        "view_count": 41279,
        "like_count": 52
    },
    "1724655856946688164": {
        "content": "Fun new @GoogleAI @GoogleHealth @StanfordMed  preprint exploring the potential of LLMs for genetic discovery! \n\nWe found that our medical LLM, Med-PaLM 2, was able to accurately identify the murine genes that contained experimentally verified causative genetic factors for six biomedical traits including diabetes and cataract. \n\nFurther, as perhaps a more exciting result, Med-PaLM 2 was also able to analyze a list of genes with high impact alleles, which were identified by comparative analysis of murine genomic sequence data, and it identified a causative murine genetic factor for spontaneous hearing loss. \n\nBased on this finding, our Stanford collaborators developed a novel bigenic model for hearing loss with experimental verification. \n\nWhile still very early, the potential for LLMs in genetic and biomedical discovery at large is super exciting as we advance the capability of our models. \n\nAs next steps, we are working on a more scalable LLM based genetic discovery pipeline and expanding the work to rare diseases and humans. More to share soon!\n\nAmazing work by @taotu831 and @apalepu13 and our @StanfordMed collaborators!\n\nhttps://t.co/lkcm3MtMHN",
        "name": "Vivek Natarajan",
        "photo": "https://pbs.twimg.com/profile_images/1747280310180720640/mKDZIBLL_normal.jpg",
        "reply_count": 2,
        "retweet_count": 21,
        "view_count": 25431,
        "like_count": 134
    },
    "1724527839121215845": {
        "content": "A baby step towards using LLM for Genetic Discovery. Med-PaLM 2 helps identify murine genes linked to hearing loss! While promising, limitations exist (tokenizer \ud83d\udd21, quality of pretraining data\u2705) #AIforScience #GeneticDiscovery @GoogleAI @StanfordMed \nhttps://t.co/ibxX3hoSe2",
        "name": "Tao Tu",
        "photo": "https://pbs.twimg.com/profile_images/1680882666168614914/vkY_x9th_normal.jpg",
        "reply_count": 0,
        "retweet_count": 13,
        "view_count": 25366,
        "like_count": 45
    },
    "1724626002595471740": {
        "content": "we are pausing new ChatGPT Plus sign-ups for a bit :(\n\nthe surge in usage post devday has exceeded our capacity and we want to make sure everyone has a great experience.\n\nyou can still sign-up to be notified within the app when subs reopen.",
        "name": "Sam Altman",
        "photo": "https://pbs.twimg.com/profile_images/804990434455887872/BG0Xh7Oa_normal.jpg",
        "reply_count": 1263,
        "retweet_count": 1366,
        "view_count": 5967453,
        "like_count": 16597
    },
    "1724553024088191211": {
        "content": "Introducing Mirasol, a multimodal model for learning across audio, video, &amp; text that decouples the modeling into separate autoregressive models to process the inputs according to the characteristics of their modalities, for state-of-the-art performance \u2192https://t.co/PjFHFnSyvl https://t.co/uUtXSB2MdX",
        "name": "Google AI",
        "photo": "https://pbs.twimg.com/profile_images/993649592422907904/yD7LkqU2_normal.jpg",
        "reply_count": 48,
        "retweet_count": 261,
        "view_count": 269653,
        "like_count": 1268
    },
    "1724443351666049511": {
        "content": "A #MachineLearning-based #Weather forecasting model from @GoogleDeepMind leads to better, faster, and more accessible 10-day weather predictions than existing approaches, according to a new Science study.\n\nLearn more about #GraphCast: https://t.co/RnG4QZljNt https://t.co/QQBKSU5yzu",
        "name": "Science Magazine",
        "photo": "https://pbs.twimg.com/profile_images/1001918231752429568/wUNPvDdW_normal.jpg",
        "reply_count": 9,
        "retweet_count": 232,
        "view_count": 460044,
        "like_count": 911
    },
    "1724452655454466489": {
        "content": "Excited to share @GoogleDeepMind\u2019s newest AI model GraphCast: the most accurate 10-day global weather forecasting system in the world. GraphCast can also offer earlier warnings of extreme weather events, including the path of hurricanes. In @Science today https://t.co/iHhQeSH3js",
        "name": "Demis Hassabis",
        "photo": "https://pbs.twimg.com/profile_images/691700243809718272/z7XZUARB_normal.jpg",
        "reply_count": 108,
        "retweet_count": 846,
        "view_count": 673226,
        "like_count": 4358
    },
    "1724423769932882202": {
        "content": "1/ Phew! Finally finished all 68 Python notebook exercises for \"Understanding Deep Learning \" book. \n\nDraft and notebooks at at: https://t.co/hqRA1xUPkk\nPre-order your copy via:  https://t.co/NOuW8iKvV1\nInstructors can request an  exam/desk copy via: https://t.co/bHkYWNyL9C https://t.co/IwZ0p5XICd",
        "name": "Simon Prince",
        "photo": "https://pbs.twimg.com/profile_images/1148263947302244353/HK0Msjil_normal.jpg",
        "reply_count": 31,
        "retweet_count": 435,
        "view_count": 241110,
        "like_count": 2209
    },
    "1723890639258222810": {
        "content": "JARVIS-1: Open-Ended Multi-task Agents with Memory-Augmented Multimodal Language Models\n\nabs: https://t.co/fOcj5iKUDQ\nproject page: https://t.co/wJGZ6JyoH3\n\n\"We introduce JARVIS-1, an open-ended agent that can perceive multimodal input (visual observations and human instructions), generate sophisticated plans, and perform embodied control, all within the popular yet challenging open-world Minecraft universe.\"",
        "name": "Tanishq Mathew Abraham, Ph.D.",
        "photo": "https://pbs.twimg.com/profile_images/1553508977735962624/nnlSwBmu_normal.jpg",
        "reply_count": 9,
        "retweet_count": 134,
        "view_count": 137887,
        "like_count": 753
    },
    "1723888920415400409": {
        "content": ":-) https://t.co/Dqx6uqB5Nd",
        "name": "Moshe Vardi",
        "photo": "https://pbs.twimg.com/profile_images/1200031067/myvB_normal.jpg",
        "reply_count": 40,
        "retweet_count": 944,
        "view_count": 273744,
        "like_count": 4765
    },
    "1723534019973836802": {
        "content": "Download 698-page PDF &gt;&gt; Everything You Always Wanted To Know About Mathematics*\n\n(*But didn\u2019t even know to ask)\n\nA Guided Journey Into the World of Abstract Mathematics and the Writing of Proofs: https://t.co/JLsDOmpP1q https://t.co/P8nKCRTxAa",
        "name": "Kirk Borne",
        "photo": "https://pbs.twimg.com/profile_images/1112733580948635648/s-8d1avb_normal.jpg",
        "reply_count": 12,
        "retweet_count": 332,
        "view_count": 187659,
        "like_count": 1406
    },
    "1723384962756513878": {
        "content": "My timeline is once again flooded by \"10 GPTs that blow your mind\"\ud83e\udd22. Let's rain on their parades!\n\nThe first step to solve any problem is to recognize there is one. A recent paper systematically reveals GPT-4V's limitations:\n\n- Text prior knowledge overrules vision: GPT-4V tends to stick with common sense or stereotypes and override the image that shows otherwise, causing factual errors. For example, 4V always identifies Saturn in an image of solar system that actually misses Saturn.\n- Similarly, if you have an intentionally misleading text prompt, 4V will prefer to stick with the text and ignore the image.\n- 4V struggles with composite images: a grid with visually similar but semantically different pictures. This could be very problematic for many comparison figures in PDFs and professional documents.\n- Regional bias: 4V identifies Western places and cultural elements much better than other areas. It also does OCR much better on Western languages. Perhaps unsurprisingly, this reveals the systematic bias in training data distribution.\n\nIt's important to understand the strengths and weaknesses of a foundation model before putting it in production. This holds universally true for all other models, including OSS ones like LlaVA.\n\nMore experiments can be found in the paper: \"Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges\"\nArxiv: https://t.co/lyQYs9Z8FJ\nLed by @HuaxiuYaoML's team.",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 36,
        "retweet_count": 145,
        "view_count": 236661,
        "like_count": 970
    },
    "1723032552535982277": {
        "content": "BioGPT-Large was just released by @Microsoft \ud83e\udd29 Trained from scratch on biomedical text, it's the current leader on the #PubMedQA benchmark at 81% accuracy (human performance = 78%).  It's also freely available on the\n\n@huggingface\n\nhub to try out (and fine-tune)! https://t.co/QLjjcKulSu",
        "name": "Sami Nas \ud83d\udc68\u200d\u2695\ufe0f",
        "photo": "https://pbs.twimg.com/profile_images/1698327507487817728/9FJ3cCyv_normal.jpg",
        "reply_count": 6,
        "retweet_count": 128,
        "view_count": 132940,
        "like_count": 610
    },
    "1723026266608033888": {
        "content": "Excited to announce my first custom GPT!\n\nDesignerGPT \ud83d\udc68\u200d\ud83c\udfa8\n\nNow, you can create beautiful websites directly in ChatGPT, with natively support for dark mode \ud83c\udf19\n\nWebsites hosted remotely via @replit. \ud83c\udf10\n\nLink in the comments. https://t.co/LXf9SXQEPT",
        "name": "Pietro Schirano",
        "photo": "https://pbs.twimg.com/profile_images/1620194266533199874/rCtE0hYR_normal.jpg",
        "reply_count": 128,
        "retweet_count": 321,
        "view_count": 1589670,
        "like_count": 3292
    },
    "1722910065378668646": {
        "content": "Study found that \"within a few months of the launch of ChatGPT, copywriters and graphic designers on major online freelancing platforms saw a significant drop in the number of jobs they got, and even steeper declines in earnings\".\n\nFrom @jburnmurdoch \n\nhttps://t.co/cK6brPRKcQ https://t.co/yFbwL5gGxQ",
        "name": "Stefan Schubert",
        "photo": "https://pbs.twimg.com/profile_images/1765862195806507008/vg0DSSyX_normal.jpg",
        "reply_count": 11,
        "retweet_count": 297,
        "view_count": 341441,
        "like_count": 818
    },
    "1722666848033100189": {
        "content": "NVIDIA just made Pandas 150x faster with zero code changes.\n\nAll you have to do is:\n%load_ext cudf.pandas\nimport pandas as pd\n\nTheir RAPIDS library will automatically know if you're running on GPU or CPU and speed up your processing.\n\nYou can try it here: https://t.co/Q7Z4QT0bjc\n\nRepo: https://t.co/Fgu6xczCvT",
        "name": "Lior\u26a1",
        "photo": "https://pbs.twimg.com/profile_images/1737888535099899906/5YPbFAld_normal.jpg",
        "reply_count": 22,
        "retweet_count": 373,
        "view_count": 190540,
        "like_count": 1677
    },
    "1722313836798320715": {
        "content": "Just as GitHub was founded on Git, today we are re-founded on Copilot. From the GA of Copilot Chat, to the new Copilot Enterprise, to the Copilot Partner Program and so much more \u2013 we are expanding and infusing Copilot into every aspect of GitHub.\n\nhttps://t.co/cRLqmYeu15",
        "name": "Thomas Dohmke",
        "photo": "https://pbs.twimg.com/profile_images/1664140592690118657/oEEyMqU0_normal.jpg",
        "reply_count": 98,
        "retweet_count": 216,
        "view_count": 1455968,
        "like_count": 1324
    },
    "1722344852375941323": {
        "content": "GitHub Copilot Workspace just got announced \ud83e\udd2f\n\nYou can give Copilot Workspace an issue and it will automatically propose a solution/plan to execute. Copilot Workspace has the full context of both the issue - including all comments - and of your codebase. \nhttps://t.co/VMNvgn37Up https://t.co/YDl2Crhnz1",
        "name": "Marcel Pociot \ud83e\uddea",
        "photo": "https://pbs.twimg.com/profile_images/1572564016916008961/n7drNq_E_normal.jpg",
        "reply_count": 11,
        "retweet_count": 96,
        "view_count": 160169,
        "like_count": 859
    },
    "1722386725635580292": {
        "content": "Pressure Testing GPT-4-128K With Long Context Recall\n\n128K tokens of context is awesome - but what's performance like?\n\nI wanted to find out so I did a \u201cneedle in a haystack\u201d analysis\n\nSome expected (and unexpected) results\n\nHere's what I found:\n\nFindings:\n* GPT-4\u2019s recall performance started to degrade above 73K tokens\n* Low recall performance was correlated when the fact to be recalled was placed between at 7%-50% document depth\n* If the fact was at the beginning of the document, it was recalled regardless of context length\n\nSo what:\n* No Guarantees - Your facts are not guaranteed to be retrieved. Don\u2019t bake the assumption they will into your applications\n* Less context = more accuracy - This is well know, but when possible reduce the amount of context you send to GPT-4 to increase its ability to recall\n* Position matters - Also well know, but facts placed at the very beginning and 2nd half of the document seem to be recalled better\n\nOverview of the process:\n* Use Paul Graham essays as \u2018background\u2019 tokens. With 218 essays it\u2019s easy to get up to 128K tokens\n* Place a random statement within the document at various depths. Fact used: \u201cThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\u201d\n* Ask GPT-4 to answer this question only using the context provided\n* Evaluate GPT-4s answer with another model (gpt-4 again) using @LangChainAI evals\n* Rinse and repeat for 15x document depths between 0% (top of document) and 100% (bottom of document) and 15x context lengths (1K Tokens > 128K Tokens)\n\nNext Steps To Take This Further:\n* Iterations of this analysis were evenly distributed, it\u2019s been suggested that doing a sigmoid distribution would be better (it would tease out more nuanced at the start and end of the document)\n* For rigor, one should do a key:value retrieval step. However for relatability I did a San Francisco line within PGs essays.\n\nNotes:\n* While I think this will be directionally correct, more testing is needed to get a firmer grip on GPT4s abilities\n* Switching up prompt with vary results\n* 2x tests were run at large context lengths to tease out more performance\n* This test cost ~$200 for API calls (a single call at 128K input tokens costs $1.28)\n* Thank you to @charles_irl for being a sounding board and providing great next steps",
        "name": "Greg Kamradt",
        "photo": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg",
        "reply_count": 208,
        "retweet_count": 634,
        "view_count": 1462487,
        "like_count": 3934
    },
    "1722497764263702732": {
        "content": "\ud83d\udea8 JUST IN: Amazon is developing a new ChatGPT competitor, codenamed Olympus.\n\nPlus, huge AI developments from Samsung, Google Search, DeepMind, NVIDIA, Meta, HuggingFace, and 9 new AI tools.\n\nHere's the rundown of everything you need to know:",
        "name": "Rowan Cheung",
        "photo": "https://pbs.twimg.com/profile_images/1711152452735774720/Cotttl-n_normal.jpg",
        "reply_count": 77,
        "retweet_count": 306,
        "view_count": 760001,
        "like_count": 2364
    },
    "1720789240307720607": {
        "content": "The potato paradox is a mathematical calculation that has a counter-intuitive result.\n\n\"You have 100kg of potatoes, which are 99% water by weight. You let them dehydrate until they're 98% water. How much do they weigh now?\"\n\nThe surprising answer is 50kg https://t.co/YJXS9iUS7f",
        "name": "Massimo",
        "photo": "https://pbs.twimg.com/profile_images/914888589670043654/KVvwjcWA_normal.jpg",
        "reply_count": 299,
        "retweet_count": 752,
        "view_count": 2804814,
        "like_count": 7264
    },
    "1722972731333804206": {
        "content": "Correlation can be highly misleading.\n\nMany solely rely on the correlation matrix to study the association between variables.\n\nBut unknown to them, the obtained statistic can be heavily driven by outliers.\n\nThis is evident from the image below.\n\nThe addition of just two outliers drastically changed:\n- the correlation\n- the regression fit\n\nThus, plotting the data is highly important.\n\nThis can save you from drawing wrong conclusions, which you may have drawn otherwise by solely looking at the summary statistics.\n\n--\n\ud83d\udc49 Get a Free Data Science PDF (550+ pages) with 320+ tips by subscribing to my daily newsletter today:\u00a0https://t.co/xILUKooE4I.\n--\n\n\ud83d\udc49 Over to you: What are some other measures you take when using summary statistics?",
        "name": "Avi Chawla",
        "photo": "https://pbs.twimg.com/profile_images/1712320497764229120/bgUqgxvR_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 3264,
        "like_count": 31
    },
    "1724064353522008352": {
        "content": "Arxiv reached a new milestone with 20,710 new submissions just last month\n\nIn its history, ~2.3 million research articles have been published\n\nHere is a 15-year chart I gathered, showing submissions by subjects:\n\n- CS rules\n- Math, physics, and stats show the strongest trend https://t.co/mIi0653Jdi",
        "name": "Davide Roznowicz",
        "photo": "https://pbs.twimg.com/profile_images/1748330274092408832/XZpoTNk8_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 1258,
        "like_count": 14
    },
    "1724292267970879599": {
        "content": "Another way to look and consider multicollinearity.  Check your VIF.\n\nLinear Regression: Multicolinearity, they taught you wrong by Yukio https://t.co/EQtLXJP9Gp",
        "name": "Ben",
        "photo": "https://pbs.twimg.com/profile_images/1677452441074421762/O1ZRkHBF_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 569,
        "like_count": 3
    },
    "1720660173180797151": {
        "content": "MIT has finally released a course on content that rattled me first when I was reading through CS229's course notes. \nTaking derivates of diff kinds of matrix-vec products is highly unintuitive. Googling matrix/vec calc didn't give me satisfactory results.\n\nhttps://t.co/z5ujFsDou5",
        "name": "Debanjan Sengupta",
        "photo": "https://pbs.twimg.com/profile_images/969485206745882624/V8EIHoUQ_normal.jpg",
        "reply_count": 8,
        "retweet_count": 141,
        "view_count": 105345,
        "like_count": 945
    },
    "1720647784871711164": {
        "content": "Sir Isaac Newton never married and had no children. He may have died a virgin. https://t.co/jsYNqj4TqJ",
        "name": "Physics In History",
        "photo": "https://pbs.twimg.com/profile_images/1456245154377916417/oPMz8-kf_normal.jpg",
        "reply_count": 354,
        "retweet_count": 411,
        "view_count": 489494,
        "like_count": 3528
    },
    "1718916631512949248": {
        "content": "Microsoft paper claims ChatGPT 3.5 has ~20 billion parameters https://t.co/gZxh0l2VqX https://t.co/EDCWbLdYEz",
        "name": "Felix",
        "photo": "https://pbs.twimg.com/profile_images/1315698428035334144/gFRG5rJg_normal.jpg",
        "reply_count": 67,
        "retweet_count": 310,
        "view_count": 1058964,
        "like_count": 2350
    },
    "1718025010445525353": {
        "content": "This is really neat: Community Notes work because they estimate users' political preferences and upweight notes that are liked by users of all stripes.\n\nI wonder if other parts of our democracy could be improved with mechanisms like this.\n\nhttps://t.co/7PFYpzDclr https://t.co/V0O5NjluyE",
        "name": "Paul Novosad",
        "photo": "https://pbs.twimg.com/profile_images/1404388273359831042/7FWLaDSK_normal.jpg",
        "reply_count": 9,
        "retweet_count": 73,
        "view_count": 157911,
        "like_count": 499
    },
    "1718251375971197408": {
        "content": "Oh, and a bonus chart that I think will fry a lot of people\u2019s brains and break a lot of narratives:\n\nFor all the talk of six figure costs of college in the States, here\u2019s how much debt graduates leave university with in the UK and US vs other countries https://t.co/XVwD4aoWBM",
        "name": "John Burn-Murdoch",
        "photo": "https://pbs.twimg.com/profile_images/922511756110557184/IDxUQ_rr_normal.jpg",
        "reply_count": 321,
        "retweet_count": 1731,
        "view_count": 1976969,
        "like_count": 5242
    },
    "1717676624865382901": {
        "content": "Compute is all you need.\nFor a given amount of compute, ViT and ConvNets perform the same.\n\nQuote from this DeepMind article: \"Although the success of ViTs in computer vision is extremely impressive, in our view there is no strong evidence to suggest that pre-trained ViTs outperform pre-trained ConvNets when evaluated fairly.\"\n\nhttps://t.co/D3Ydv9k7vq",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 84,
        "retweet_count": 315,
        "view_count": 553216,
        "like_count": 2355
    },
    "1717669314499612788": {
        "content": "@GaryMarcus @Jake_Browning00 - I haven't engaged with you in years.\n- I've always been quite vocal about the limitations of Auto-Regressive LLMs.\n- I'm working on ways to lift these limitations, not merely complaining about them.\n- Unlike you, I'm not claiming that AR-LLMs will harm society.",
        "name": "Yann LeCun",
        "photo": "https://pbs.twimg.com/profile_images/1483577865056702469/rWA-3_T7_normal.jpg",
        "reply_count": 12,
        "retweet_count": 3,
        "view_count": 25596,
        "like_count": 128
    },
    "1717533721828442614": {
        "content": "it's over\n\nAGI has been achieved - externally\n\npaper: https://t.co/oVuBS6ZwJh https://t.co/3gfRHwdgpY",
        "name": "Aleksa Gordi\u0107 \ud83c\udf7f\ud83e\udd16",
        "photo": "https://pbs.twimg.com/profile_images/1625654180105920514/9dCpi8Rs_normal.jpg",
        "reply_count": 51,
        "retweet_count": 161,
        "view_count": 289766,
        "like_count": 1267
    },
    "1714763391359697018": {
        "content": "Andrej Karpathy is a legendary researcher who helped start OpenAI and created Stanford's first deep learning class.\n\n@karpathy's advice on how to learn AI:\n\n(1) 10,000 hours of deliberate practice will make you an expert. You can iterate as you work. Only compare yourself to the past, not to others.\n\n(2) Don't worry about making mistakes. You build intuitions on what is useful vs. not useful- they are not dead work.\n\n(3) Teach to strengthen your understanding and find gaps in knowledge. Similar to \"If you can't explain it to a six-year-old, then you don't understand it yourself\" - Albert Einstein.",
        "name": "Alex Ker \ud83d\udd2d",
        "photo": "https://pbs.twimg.com/profile_images/1665403369136046080/ruOIyOi3_normal.jpg",
        "reply_count": 48,
        "retweet_count": 327,
        "view_count": 502623,
        "like_count": 2212
    },
    "1717131235644875024": {
        "content": "is GPT-4v susceptible to optical illusions? \n\nhunch is *of course not*...why would a computer vision system exhibit the same \"feature/bugs\" specifics as the idiosyncratic wetware wiring of the human visual system?\n\nyet for some, it weirdly does: https://t.co/5rc6lVE0rS",
        "name": "fabian (glif/acc)",
        "photo": "https://pbs.twimg.com/profile_images/1741955553872461824/r1gudr4V_normal.jpg",
        "reply_count": 164,
        "retweet_count": 267,
        "view_count": 488270,
        "like_count": 2337
    },
    "1716942432829665773": {
        "content": "Our NVIDIA-Metropolis team is hiring 2024 Spring/ Summer interns. You will get to work on cutting edge applied research - developing multi-modality visual foundation models, large scale data curation and building data-engines for auto-labeling. If interested - Pls reach out.",
        "name": "Subhashree Radhakrishnan",
        "photo": "https://pbs.twimg.com/profile_images/1101743971833798656/yc9h4T77_normal.jpg",
        "reply_count": 12,
        "retweet_count": 21,
        "view_count": 36886,
        "like_count": 186
    },
    "1715309360274891249": {
        "content": "No wonder the Tories lose by-elections if we announce woke policies that antagonise our supporters on election day.",
        "name": "Jacob Rees-Mogg",
        "photo": "https://pbs.twimg.com/profile_images/1572131691023532034/CIQOqDbT_normal.jpg",
        "reply_count": 807,
        "retweet_count": 109,
        "view_count": 331781,
        "like_count": 626
    },
    "1715103151307497780": {
        "content": "'It happens in churches and places of worship all across the country'\n\nLGBT rights campaigner, Peter Tatchell, debates with Jacob over a new draft bill to ban conversion therapy. https://t.co/AsMjuQnfGf",
        "name": "GB News",
        "photo": "https://pbs.twimg.com/profile_images/1571994202854100994/vYcqAgBG_normal.jpg",
        "reply_count": 62,
        "retweet_count": 10,
        "view_count": 176538,
        "like_count": 43
    },
    "1714707338224169123": {
        "content": "\ud83d\udce2 The \u2728Foundation Model Transparency Index \u2728 scores 10 companies on \ud83d\udcaf measures of transparency\n\n1\u20e3 No company scores above 60% \n\n2\u20e3 No company shares adequate information about the real world impact of its top model\n\n3\u20e3 Transparency is necessary for evidence-backed policy https://t.co/WdemJUyd9O",
        "name": "Kevin Klyman",
        "photo": "https://pbs.twimg.com/profile_images/1238221269390237696/3XV1a1v6_normal.jpg",
        "reply_count": 1,
        "retweet_count": 12,
        "view_count": 7228,
        "like_count": 39
    },
    "1714681748519301268": {
        "content": "The scores + ranking look super weird and inconsistent to me &amp; a lot of interesting open models are missing but I love the message from @Stanford @StanfordHAI.\n\nMore transparency = more safety for AI\n\nhttps://t.co/5KFe1egF3r https://t.co/NBrColZ8Qn",
        "name": "clem \ud83e\udd17",
        "photo": "https://pbs.twimg.com/profile_images/1100512198139498497/utHSJ4st_normal.png",
        "reply_count": 4,
        "retweet_count": 13,
        "view_count": 8763,
        "like_count": 59
    },
    "1714458385624506679": {
        "content": "Source says GPT-5 will cost $2.0-$2.5B to train, 500k H100s for 90 days or another configuration. Starts next year.",
        "name": "Martin Shkreli (e/acc)",
        "photo": "https://pbs.twimg.com/profile_images/1740604448236285952/Fr4FIDtE_normal.jpg",
        "reply_count": 109,
        "retweet_count": 172,
        "view_count": 1117861,
        "like_count": 2408
    },
    "1713601598621163811": {
        "content": "You\u2019re a great engineer if you know the definition of: \n\n- idempotent\n- monoid\n- decoupled \n- dependency injection \n- unit \n- functional programming \n- asynchronous vs parallel programming \n- thread locking \n- eventual consistency \n- exactly-once semantics \n- lambda vs kappa architecture \n- push vs pull architectures \n- write-audit-publish pattern \n\nWhat else would you add?\n\n#dataengineering \n#softwareengineering",
        "name": "Zach Wilson",
        "photo": "https://pbs.twimg.com/profile_images/1677386353217265664/B0VSKY7c_normal.jpg",
        "reply_count": 238,
        "retweet_count": 464,
        "view_count": 1059000,
        "like_count": 3307
    },
    "1713582494644355505": {
        "content": "Using noise cancellation tech on control flaps to turn turbulence off using software. \n\nThe 20th century really is over.",
        "name": "Ate-a-Pi",
        "photo": "https://pbs.twimg.com/profile_images/1741356225261142016/NMKAoAr-_normal.jpg",
        "reply_count": 141,
        "retweet_count": 1466,
        "view_count": 3037122,
        "like_count": 16065
    },
    "1713310384554131516": {
        "content": "Turbulence free flights are coming soon! https://t.co/Tun339FXfo",
        "name": "Yves Remmler",
        "photo": "https://pbs.twimg.com/profile_images/1571975565925666818/YlN85C9-_normal.jpg",
        "reply_count": 367,
        "retweet_count": 1240,
        "view_count": 4063779,
        "like_count": 9655
    },
    "1713773812670476336": {
        "content": "A Zero-Shot Language Agent for Computer Control with Structured Reflection\n\npaper page: https://t.co/BbWz46o6pf\n\nLarge language models (LLMs) have shown increasing capacity at planning and executing a high-level goal in a live computer environment (e.g. MiniWoB++). To perform a task, recent works often require a model to learn from trace examples of the task via either supervised learning or few/many-shot prompting. Without these trace examples, it remains a challenge how an agent can autonomously learn and improve its control on a computer, which limits the ability of an agent to perform a new task. We approach this problem with a zero-shot agent that requires no given expert traces. Our agent plans for executable actions on a partially observed environment, and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management. On the easy tasks of MiniWoB++, we show that our zero-shot agent often outperforms recent SoTAs, with more efficient reasoning. For tasks with more complexity, our reflective agent performs on par with prior best models, even though previous works had the advantages of accessing expert traces or additional screen information.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 3,
        "retweet_count": 51,
        "view_count": 64928,
        "like_count": 229
    },
    "1713360697856303286": {
        "content": "A great review on \"How Do Large Language Models Capture the Ever-changing World Knowledge?\" \n\ud83d\udd17https://t.co/C89tiwSbe1 https://t.co/68vWZlFbsZ",
        "name": "Sophia Yang, Ph.D.",
        "photo": "https://pbs.twimg.com/profile_images/1781261880696184832/OvXJpS9__normal.jpg",
        "reply_count": 3,
        "retweet_count": 118,
        "view_count": 90346,
        "like_count": 525
    },
    "1713427873397383605": {
        "content": "I have seen a bunch of folks dunking on GPT4V in a medical context (and of course others breathlessly praising), but my first shot on the easiest case I could think of (and which was likely in the training set) was way worse than I expected. https://t.co/V843Ciw3Vg",
        "name": "Sam Finlayson",
        "photo": "https://pbs.twimg.com/profile_images/521461710800969729/UC3AjB6u_normal.jpeg",
        "reply_count": 2,
        "retweet_count": 3,
        "view_count": 10998,
        "like_count": 45
    },
    "1713375891135529427": {
        "content": "\"at least 25% of all science done in the last few years has used numpy and scipy\" - Travis Oliphant\n\nI can only dream of having that kind of impact. Amazing.",
        "name": "Andrew Carr (e/\ud83e\udd38)",
        "photo": "https://pbs.twimg.com/profile_images/1598394632919953408/MiPTd73F_normal.jpg",
        "reply_count": 4,
        "retweet_count": 61,
        "view_count": 82994,
        "like_count": 608
    },
    "1713067134006468769": {
        "content": "Is it true that Mac users have absolutely no way of doing NVidia GPU-based software development on their laptops and must connect to a remote server with GPUs?\n\nWhy choose Mac to do ML development then?\n\nIsn't it counterproductive for fast development?\n\nI understand that even eGPU is a no go.",
        "name": "Stas Bekman",
        "photo": "https://pbs.twimg.com/profile_images/1068362113205231616/kJyKU2F5_normal.jpg",
        "reply_count": 88,
        "retweet_count": 13,
        "view_count": 179767,
        "like_count": 269
    },
    "1712905866226421794": {
        "content": "I fine-tuned Mistral 7b on my personal journal entries and it\u2019s hilarious \ud83d\ude02\n\nHere\u2019s how you can fine-tune it on your own data\u2014 guide is below \ud83d\udc47\ud83e\udd19\ud83c\udfc4\u200d\u2642\ufe0f https://t.co/q7uNcQbIB5",
        "name": "Harper Carroll",
        "photo": "https://pbs.twimg.com/profile_images/1664382394219253762/11Q8cv7v_normal.jpg",
        "reply_count": 42,
        "retweet_count": 113,
        "view_count": 420008,
        "like_count": 1251
    },
    "1712954182385492140": {
        "content": "understanding cross attention _really_ well is enough to get 99% of LLM research science jobs out there",
        "name": "Andrew Carr (e/\ud83e\udd38)",
        "photo": "https://pbs.twimg.com/profile_images/1598394632919953408/MiPTd73F_normal.jpg",
        "reply_count": 6,
        "retweet_count": 4,
        "view_count": 36947,
        "like_count": 158
    },
    "1712639154301894882": {
        "content": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models\n\npaper page: https://t.co/BN56gT6gf7\n\nRecently, using a powerful proprietary Large Language Model (LLM) (e.g., GPT-4) as an evaluator for long-form responses has become the de facto standard. However, for practitioners with large-scale evaluation tasks and custom criteria in consideration (e.g., child-readability), using proprietary LLMs as an evaluator is unreliable due to the closed-source nature, uncontrolled versioning, and prohibitive costs. In this work, we propose Prometheus, a fully open-source LLM that is on par with GPT-4's evaluation capabilities when the appropriate reference materials (reference answer, score rubric) are accompanied. We first construct the Feedback Collection, a new dataset that consists of 1K fine-grained score rubrics, 20K instructions, and 100K responses and language feedback generated by GPT-4. Using the Feedback Collection, we train Prometheus, a 13B evaluator LLM that can assess any given long-form text based on customized score rubric provided by the user. Experimental results show that Prometheus scores a Pearson correlation of 0.897 with human evaluators when evaluating with 45 customized score rubrics, which is on par with GPT-4 (0.882), and greatly outperforms ChatGPT (0.392). Furthermore, measuring correlation with GPT-4 with 1222 customized score rubrics across four benchmarks (MT Bench, Vicuna Bench, Feedback Bench, Flask Eval) shows similar trends, bolstering Prometheus's capability as an evaluator LLM. Lastly, Prometheus achieves the highest accuracy on two human preference benchmarks (HHH Alignment & MT Bench Human Judgment) compared to open-sourced reward models explicitly trained on human preference datasets, highlighting its potential as an universal reward model.",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 3,
        "retweet_count": 51,
        "view_count": 114707,
        "like_count": 229
    },
    "1712801009741815965": {
        "content": "I've now completed 45 of the 68 Python notebooks that accompany my forthcoming book \"Understanding Deep Learning\".  They will really help if you are learning (or teaching) deep learning.\n\nNotebooks and book pdf at: https://t.co/hqRA1xUPkk\n\nBook published Dec. 5th by @mitpress. https://t.co/zzoYKY3nXN",
        "name": "Simon Prince",
        "photo": "https://pbs.twimg.com/profile_images/1148263947302244353/HK0Msjil_normal.jpg",
        "reply_count": 35,
        "retweet_count": 667,
        "view_count": 373838,
        "like_count": 3646
    },
    "1711086799181750562": {
        "content": "The sheer scale of the attacks on Israeli civilians is horrifying\n\nI\u2019ve stood in solidarity with the Palestinian people &amp; will continue to do so\n\nBut this attack is wrong\n\nSolidarity against acts of terror shouldn\u2019t be selective, which is why I also stand with the Israeli people",
        "name": "Clive Lewis MP",
        "photo": "https://pbs.twimg.com/profile_images/1662778334558801927/_FZqu8Jh_normal.jpg",
        "reply_count": 400,
        "retweet_count": 334,
        "view_count": 581709,
        "like_count": 3962
    },
    "1709970052793905349": {
        "content": "Yesterday, PM @RishiSunak announced plans to create a \u2018smokefree generation.\u2019\n\nThis will mean it will be an offence for anyone born on or after 1 January 2009 to be sold cigarettes in England, protecting an entire generation of young people from the harms of smoking. https://t.co/y0NBkFuCt2",
        "name": "UK Prime Minister",
        "photo": "https://pbs.twimg.com/profile_images/1724009820456411138/MysH506f_normal.jpg",
        "reply_count": 1226,
        "retweet_count": 166,
        "view_count": 1596051,
        "like_count": 1491
    },
    "1709257792509391073": {
        "content": "What does this even mean? The latest in a string of Cabinet ministers systematically making stuff up that either isn't happening, doesn't exist or makes no sense and then they \"rally\" against it.  Just desperate \u2026 https://t.co/fVIr4bmZfN",
        "name": "Caroline Lucas",
        "photo": "https://pbs.twimg.com/profile_images/772740003856343040/5eGrmUPp_normal.jpg",
        "reply_count": 806,
        "retweet_count": 2236,
        "view_count": 1086233,
        "like_count": 13381
    },
    "1709328375385387295": {
        "content": "Tory MP Michelle Donelan: \u201cWe are the Party of facts\u201d\n \n*VT compilation of Tory lies*\n\nVictoria Derbyshire: \u201cThere was never a proposal to use 7 bins, we can\u2019t find any council that wants to decide when you can go to the shop &amp; Labour have never proposed taxing meat\u201d\n\n#Newsnight https://t.co/Hib1ql85xG",
        "name": "David",
        "photo": "https://pbs.twimg.com/profile_images/659855570862792705/OlzAoKnS_normal.jpg",
        "reply_count": 873,
        "retweet_count": 7821,
        "view_count": 4581681,
        "like_count": 23758
    },
    "1622432869837668352": {
        "content": "Efficient Domain Adaptation for Speech Foundation Models\n\nabs: https://t.co/lHnrVDGLKk https://t.co/yJ0mqR83Mj",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 0,
        "retweet_count": 14,
        "view_count": 17866,
        "like_count": 52
    },
    "1607746957753057280": {
        "content": "The AI explosion is warping our sense of time. Can you believe Stable Diffusion is only 4 months old, and ChatGPT &lt;4 weeks old \ud83e\udd2f? If you blink, you miss a whole new industry. Here are my TOP 10 AI spotlights, from a breathtaking 2022 in rewind \u23ee: a long thread \ud83e\uddf5 https://t.co/5k8Q6VQ0tD",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 92,
        "retweet_count": 1003,
        "view_count": 1010918,
        "like_count": 4414
    },
    "1796796142656561661": {
        "content": "https://t.co/Ql2yza3Il1",
        "name": "Mathieu Alain",
        "photo": "https://pbs.twimg.com/profile_images/1279117113580564481/T3PEblUj_normal.jpg",
        "reply_count": 37,
        "retweet_count": 87,
        "view_count": 111748,
        "like_count": 1181
    },
    "1796897502761030137": {
        "content": "Too chicken, @elonmusk, to make my million dollar bet that AGI is not going to be here next year, but just brave enough to take a potshot?  Can\u2019t say I am impressed.",
        "name": "Gary Marcus",
        "photo": "https://pbs.twimg.com/profile_images/1749047536361586688/N1p9EZpc_normal.jpg",
        "reply_count": 6,
        "retweet_count": 4,
        "view_count": 4710,
        "like_count": 40
    },
    "1796795162028335377": {
        "content": "\ud83d\ude02\ud83c\udfaf",
        "name": "Elon Musk",
        "photo": "https://pbs.twimg.com/profile_images/1780044485541699584/p78MCn3B_normal.jpg",
        "reply_count": 2563,
        "retweet_count": 3161,
        "view_count": 12681975,
        "like_count": 32539
    },
    "1796582931617677592": {
        "content": "This is a super cool follow-up work of our recent study on latent multi-hop reasoning (https://t.co/xQk9Cvfteu to be presented in ACL 2024)! I really enjoyed reading this paper. It gives a lot of insights into the latent/implicit deductive reasoning of Transformers with grokking!",
        "name": "Sohee Yang",
        "photo": "https://pbs.twimg.com/profile_images/1661418982346223616/nOfNesmf_normal.jpg",
        "reply_count": 2,
        "retweet_count": 5,
        "view_count": 6522,
        "like_count": 30
    },
    "1794947958091227646": {
        "content": "Thanks @_akhaliq for sharing our work. Very proud to introduce my star student @BoshiWang2's new work @osunlp: Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization\n\nCan transformers reason? Are transformers fundamentally limited in compositionality and systematic generalization? I think our work\u2019s findings can contribute to meaningful debates over these questions.\n\nKey findings (with mixed results):\n(1) Figure 1 below: We focus on two representative reasoning types: composition and comparison, and show that transformers can learn implicit reasoning, but only through grokking. The levels of generalization vary across reasoning types: when faced with OOD examples, transformers fail to systematically generalize for composition but succeed for comparison.\n\n(2) Figure 2 below: What happens during grokking? Why does grokking happen? Why does the model fail in OOD generalization for composition but succeed for comparison? We conduct a mechanistic analysis of the model's internals throughout training, and find: 1) the gradual formation of the generalizing circuit throughout grokking, and 2) the connection between systematicity and the circuit\u2019s configuration, i.e., the way atomic knowledge and rules are stored and applied within the circuit:\n\nThe comparison task emits a ``parallel circuit'' that is learned by the transformer during grokking, which allows atomic facts to be stored and retrieved in the same region and enables systematicity to happen. For composition, the model does acquire the composition rule through grokking, but it does not have any incentive to store atomic facts in the upper layers that do not appear as the second hop during training.\n\nConnections with existing research:\n1. We find the speed of improvement in generalization correlates with the ratio between inferred and atomic facts in training (critical data distribution), and depends little on the absolute size of the training data. This seems to contradict the hypothesis of critical data size in prior work such as https://t.co/FXeOqpPFIM by Varma et al.\n\n2. Our work provides a mechanistic understanding of existing findings that transformers seem to reduce compositional reasoning to linearized pattern matching (https://t.co/Vc23z7fEZs Dziri et al. @nouhadziri) and that LLMs show positive evidence in first-hop reasoning but not the second (https://t.co/0ForgiFDD1 Yang et al. @soheeyang_).\n\n3. Why is implicit reasoning with parametric memory of knowledge and rules practically important? To show its potential, we demonstrate that on a complex reasoning task with a large search space, a fully grokked transformer can achieve near-perfect accuracy while GPT-4 Turbo and Gemin-1.5-Pro are close to random guessing.\n\n\ud83d\ude00Fun fact about the title:\nWe went back and forth many times and created ~10 candidate titles. Another title I personally liked very much is \u201cGrokking of Implicit Reasoning: What Happens Inside Transformers?\u201d But that does not deliver our key conclusion and our mechanistic analysis approach. Finally, Boshi came up with this title, which sounds very romantic (although perhaps less scientific) to me, but captures most aspects of our paper very well.\n\nP.S. @wangboshi is truly intellectually stimulating to work with. If you have related internship/collaboration opportunities, feel free to reach out! Joint work with @xiangyue96  @ysu_nlp",
        "name": "Huan Sun (OSU)",
        "photo": "https://pbs.twimg.com/profile_images/1247353016300326912/Ddumi9hj_normal.jpg",
        "reply_count": 11,
        "retweet_count": 65,
        "view_count": 95141,
        "like_count": 299
    },
    "1796289801588490282": {
        "content": "\u201cI'm sorry but your going to have to cut your cloth accordingly like state schools have had to for 14 years\u201d\n\nLabour\u2019s Wes Streeting defends plans to charge VAT on private schools fees to pay for state school teachers\n\n#bbcqt https://t.co/DoEkwZMbvw https://t.co/PTQ3wfwjiy",
        "name": "BBC Question Time",
        "photo": "https://pbs.twimg.com/profile_images/1645794781459804160/NnMkQyh8_normal.jpg",
        "reply_count": 1155,
        "retweet_count": 2046,
        "view_count": 2194160,
        "like_count": 13420
    },
    "1795835169372262719": {
        "content": "When I teach Principal Component Analysis (PCA), I use my interactive dashboard to engage my students. They can observe how, through an orthogonal transformation (rotation) of a two-feature dataset, the variance of the data projected onto one of the components can be maximized.\n\nI shared my #Python @matplotlib dashboard on #GitHub @ https://t.co/obhJCkCg7V \u2200. #DataScience #MachineLearning",
        "name": "Michael Pyrcz\ud83c\udf3b",
        "photo": "https://pbs.twimg.com/profile_images/1659290413784526854/6bCIQAnB_normal.jpg",
        "reply_count": 25,
        "retweet_count": 395,
        "view_count": 345708,
        "like_count": 2946
    },
    "1795468885245976631": {
        "content": "I\u2019m Marc Randolph, co-founder of Netflix &amp; 6 other companies. \n\nThis is my definition of success: https://t.co/XSbTNRnFfK",
        "name": "Marc Randolph",
        "photo": "https://pbs.twimg.com/profile_images/1765988913406148608/f1KH5aNH_normal.jpg",
        "reply_count": 272,
        "retweet_count": 1804,
        "view_count": 981169,
        "like_count": 12635
    },
    "1795497960509448617": {
        "content": "I'm excited to join @AnthropicAI to continue the superalignment mission!\n\nMy new team will work on scalable oversight, weak-to-strong generalization, and automated alignment research.\n\nIf you're interested in joining, my dms are open.",
        "name": "Jan Leike",
        "photo": "https://pbs.twimg.com/profile_images/1077523091700502528/2YCa_F4o_normal.jpg",
        "reply_count": 371,
        "retweet_count": 531,
        "view_count": 1194450,
        "like_count": 8512
    },
    "1795415492779204831": {
        "content": "[CL] Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?\nG Yona, R Aharoni, M Geva [Google Research] (2024)\nhttps://t.co/TaPBu0kCtz\n\n- The paper proposes the notion of \"faithful response uncertainty\", which measures how well a language model expresses its intrinsic uncertainty in its generated natural language response. This is formalized based on the gap between the decisiveness of the response and the model's confidence.\n\n- The paper implements decisiveness scoring using a judge model and confidence scoring using answer consistency across samples. The scores correlate well with human judgments. \n\n- The paper evaluates leading LLMs on QA datasets using greedy decoding. Without any prompting, models answer decisively regardless of confidence. When prompted to express uncertainty, added hedging expressions do not align well with model confidence.\n\n- The results suggest current LLMs are poor at faithfully conveying their intrinsic uncertainty in words, pointing to the need for better alignment techniques.",
        "name": "fly51fly",
        "photo": "https://pbs.twimg.com/profile_images/501577797114937344/ge9Wu-cU_normal.png",
        "reply_count": 2,
        "retweet_count": 21,
        "view_count": 6694,
        "like_count": 69
    },
    "1795485917018537991": {
        "content": "Compute-optimal scaling laws as studied by Chinchilla held the data distribution fixed (can't blame them - these runs aren't cheap). @khoomeik 's paper contributes to a better understanding of data-dependent scaling \u2764\ufe0f\u200d\ud83d\udd25\n\nCheck it out \ud83d\udc47",
        "name": "Rylan Schaeffer",
        "photo": "https://pbs.twimg.com/profile_images/1733557514338471936/uXIn8yUI_normal.jpg",
        "reply_count": 2,
        "retweet_count": 4,
        "view_count": 5959,
        "like_count": 34
    },
    "1795477359933706272": {
        "content": "\ud83d\udce2 Excited to finally be releasing my NeurIPS 2024 submission!\n\nIs Chinchilla universal? No! We find that:\n1. language model scaling laws depend on data complexity\n2. gzip effectively predicts scaling properties from training data\n\nAs compressibility \ud83d\udcc9, data preference \ud83d\udcc8.\n\ud83e\uddf5\u2b07\ufe0f https://t.co/ZYYZ4hxDN2",
        "name": "Rohan Pandey (e/acc)",
        "photo": "https://pbs.twimg.com/profile_images/1468732546213158915/ALzQjMaj_normal.jpg",
        "reply_count": 16,
        "retweet_count": 100,
        "view_count": 188444,
        "like_count": 730
    },
    "1794220584056025260": {
        "content": "Why do Chinese walking robots look so much like American walking robots?",
        "name": "Lachlan Phillips exo/acc \ud83d\udc7e",
        "photo": "https://pbs.twimg.com/profile_images/1752878772628688896/4uJ2ZnEd_normal.jpg",
        "reply_count": 732,
        "retweet_count": 701,
        "view_count": 2317384,
        "like_count": 21359
    },
    "1793714892077432859": {
        "content": "Chinese PLA soldier walking with his armed robot dog. https://t.co/KPsA2oL1eT",
        "name": "Clash Report",
        "photo": "https://pbs.twimg.com/profile_images/1770145869158838272/hgwvNtp1_normal.jpg",
        "reply_count": 160,
        "retweet_count": 570,
        "view_count": 3101783,
        "like_count": 2442
    },
    "1794050592685379666": {
        "content": "At last, a curriculum learning that works, one for pretraining and another for instruction tuning\n@l__ranaldi @Giuli12P2 @andrenfreitas @znz8\nhttps://t.co/4knXymxgu5\nhttps://t.co/GCr0t6WjsZ https://t.co/eZmCUye5rK",
        "name": "Leshem Choshen @LREC \ud83e\udd16\ud83e\udd17",
        "photo": "https://pbs.twimg.com/profile_images/1018975836135780352/cO2xsypb_normal.jpg",
        "reply_count": 2,
        "retweet_count": 14,
        "view_count": 11578,
        "like_count": 76
    },
    "1794098164410024080": {
        "content": "New blog post from Jason on evals. With insufficiently good evals, progress is blocked. Some ideas were only later found to be good once our evals improved. Great evals are especially key in post-training when there is no singular metric that can be hill-climbed.",
        "name": "William Fedus",
        "photo": "https://pbs.twimg.com/profile_images/946842870916448256/X0_3p45X_normal.jpg",
        "reply_count": 0,
        "retweet_count": 10,
        "view_count": 17504,
        "like_count": 71
    },
    "1794093872651387004": {
        "content": "New blog post where I discuss what makes an language model evaluation successful, and the \"seven sins\" that make hinder an eval from gaining traction in the community: https://t.co/o07nTIY6qA\n\nHad fun presenting this at Stanford's NLP Seminar yesterday! https://t.co/pfaQ5NBH1u",
        "name": "Jason Wei",
        "photo": "https://pbs.twimg.com/profile_images/1648926239389011971/kOJi1-5Z_normal.jpg",
        "reply_count": 13,
        "retweet_count": 83,
        "view_count": 88958,
        "like_count": 521
    },
    "1793913394871062970": {
        "content": "And it's out! :D\n\nA good read if you want to think about doing robust evaluation, going in depths into the nits of it.\n\nhttps://t.co/y7k6Q9X4A6 https://t.co/x4btq7E5rb",
        "name": "Cl\u00e9mentine Fourrier \ud83c\udf4a",
        "photo": "https://pbs.twimg.com/profile_images/1631657680111542274/kaTJSP86_normal.png",
        "reply_count": 3,
        "retweet_count": 26,
        "view_count": 13478,
        "like_count": 108
    },
    "1793628803501006855": {
        "content": "If you liked my blog post about LLM evaluation, one of the coolest paper on the topic will appear tonight on arxiv! (not from \ud83e\udd17)\n\nMy favorite points from it:\n- the differences between initial benchmarks design and actual use\n- the Appendix, delving into the maths of eval \u2764\ufe0f",
        "name": "Cl\u00e9mentine Fourrier \ud83c\udf4a",
        "photo": "https://pbs.twimg.com/profile_images/1631657680111542274/kaTJSP86_normal.png",
        "reply_count": 1,
        "retweet_count": 5,
        "view_count": 21525,
        "like_count": 69
    },
    "1793701961055059991": {
        "content": "Sparse autoencoders (SAEs) are a popular method for mech interp - but how do we measure if they're any good at finding the \"right\" features? In a new paper, we propose more objective SAE evaluations by comparing against \"known\" features for a previously studied circuit! https://t.co/uIl5SYTZtq",
        "name": "Alex Makelov",
        "photo": "https://pbs.twimg.com/profile_images/1646109059379077121/Iihq82AE_normal.jpg",
        "reply_count": 4,
        "retweet_count": 16,
        "view_count": 21542,
        "like_count": 111
    },
    "1793422774737998089": {
        "content": "Evaluation is one of the most important research areas in the LLM space. As the saying goes, you can't improve what you don't measure",
        "name": "Max Bartolo",
        "photo": "https://pbs.twimg.com/profile_images/1198756762838548480/qjoEvKfN_normal.jpg",
        "reply_count": 0,
        "retweet_count": 5,
        "view_count": 3735,
        "like_count": 30
    },
    "1793301496102068339": {
        "content": "I discovered at ICLR 2024 that a lot of what I take for granted about LLM evaluation is actually not that widely known...\n\nSo I made a blog!\n- how do we do currently do LLM evaluation? \u2696\ufe0f\n- most importantly, what is it actually useful for? \ud83e\udd14\n\nhttps://t.co/6aapgZEvij",
        "name": "Cl\u00e9mentine Fourrier \ud83c\udf4a",
        "photo": "https://pbs.twimg.com/profile_images/1631657680111542274/kaTJSP86_normal.png",
        "reply_count": 10,
        "retweet_count": 72,
        "view_count": 59436,
        "like_count": 357
    },
    "1793375979374796873": {
        "content": "Hey look this new paper (by my labmates) shows you can in fact benchmark SAEs and other interp methods \ud83d\ude33",
        "name": "Aryaman Arora",
        "photo": "https://pbs.twimg.com/profile_images/1735523039515926528/FghjGV3n_normal.jpg",
        "reply_count": 2,
        "retweet_count": 1,
        "view_count": 3521,
        "like_count": 29
    },
    "1793357337564180972": {
        "content": "New #ACL2024 paper on benchmarking interpretability methods \ud83e\udee1\n\nMany interpretability methods aim to localize and disentangle concepts in LLMs, but how well do they work? Are Sparse Autoencoders really the best? We present a benchmark: RAVEL.\n\nPaper: https://t.co/7bWvMKeKuX \ud83e\uddf5",
        "name": "Zhengxuan Wu",
        "photo": "https://pbs.twimg.com/profile_images/1641146001938616321/Th2IWKmh_normal.jpg",
        "reply_count": 7,
        "retweet_count": 40,
        "view_count": 23619,
        "like_count": 215
    },
    "1793172548202766803": {
        "content": "There are now grants for systemic safety!\n\nThree years ago we described \"Systemic Safety\" in Unsolved Problems in ML Safety\nhttps://t.co/wJu13ZPZuo\n\nIt's great that AI safety funding is becoming more sociotechnical and addressing systemic impacts.",
        "name": "Dan Hendrycks",
        "photo": "https://pbs.twimg.com/profile_images/1099568087253245952/4_SNw6E6_normal.png",
        "reply_count": 1,
        "retweet_count": 8,
        "view_count": 7697,
        "like_count": 50
    },
    "1793163082379968955": {
        "content": "We are announcing new grants for research into systemic AI safety.\n\nInitially backed by up to \u00a38.5 million, this program will fund researchers to advance the science underpinning AI safety.\n\nRead more: https://t.co/QHOLUp3QGR https://t.co/jnAdLJ4eAg",
        "name": "AI Safety Institute",
        "photo": "https://pbs.twimg.com/profile_images/1774507689109753857/dJ8rf0zQ_normal.png",
        "reply_count": 4,
        "retweet_count": 80,
        "view_count": 210992,
        "like_count": 211
    },
    "1792965465893118220": {
        "content": "Hi @TfL It's been so many years now... Can we get the #EustonPuddle fixed? The crossing is barely useable.\n@SimonLamrock @LDN_LS https://t.co/KLxoFoLACw",
        "name": "Adam Harrison",
        "photo": "https://pbs.twimg.com/profile_images/1245005856573460480/bq1o12s9_normal.jpg",
        "reply_count": 14,
        "retweet_count": 9,
        "view_count": 2072,
        "like_count": 37
    },
    "1793280669218381855": {
        "content": "Research from Public First reveals that AI and cloud represent a half a trillion-pound opportunity for the UK economy.\n \nFind out how Microsoft is helping unlock the transformative benefits of AI for the economy and public services: https://t.co/wv9gYMAINI\n \n#Microsoft #AI #Cloud https://t.co/r6WcQk1vH1",
        "name": "Microsoft Business UK",
        "photo": "https://pbs.twimg.com/profile_images/1064528925831901184/qgLxiKph_normal.jpg",
        "reply_count": 0,
        "retweet_count": 4,
        "view_count": 479,
        "like_count": 63
    },
    "1793081686802280576": {
        "content": "Meta plans to not open the weights for its 400B model.\n\nThe hope is that we would quietly not notice / let it slide.  \n\nDon\u2019t let it slide.",
        "name": "Jimmy Apples \ud83c\udf4e/acc",
        "photo": "https://pbs.twimg.com/profile_images/1718784022506319872/7v6f0CqZ_normal.jpg",
        "reply_count": 1,
        "retweet_count": 154,
        "view_count": 431145,
        "like_count": 1438
    },
    "1792936293023760786": {
        "content": "Huzza! So excited this is out and proud of the interp team. We found *millions* of interesting features in Claude 3 Sonnet! Go take a look!",
        "name": "Trenton Bricken",
        "photo": "https://pbs.twimg.com/profile_images/1615139644873773056/-Fhg8_TL_normal.jpg",
        "reply_count": 8,
        "retweet_count": 16,
        "view_count": 25607,
        "like_count": 238
    },
    "1792935506587656625": {
        "content": "New Anthropic research paper: Scaling Monosemanticity.\n\nThe first ever detailed look inside a leading large language model.\n\nRead the blog post here: https://t.co/6RYwxt6nWI https://t.co/Oh3RIvgnXx",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 66,
        "retweet_count": 570,
        "view_count": 656316,
        "like_count": 2375
    },
    "1792474686787322019": {
        "content": "\ud83d\udea8 NEW: Baby Reindeer\u2019s \u201creal life stalker\u201d Fiona Harvey sent 276 emails to Keir Starmer in less than 8 months, calling him a \u201cstupid little boy\u201d and a \u201cuseless barrister\u201d \n\n\u201cYour life won\u2019t be worth living\u201d https://t.co/xwf4XmhVuU",
        "name": "Politics UK",
        "photo": "https://pbs.twimg.com/profile_images/1688954450675740688/t1aS9_3Y_normal.jpg",
        "reply_count": 355,
        "retweet_count": 1026,
        "view_count": 3409733,
        "like_count": 11731
    },
    "1792457821919031386": {
        "content": "1/ It\u2019s been one year since I was appointed Chair of the UK AI Safety Institute. In this time, we\u2019ve built one of the largest safety evaluation teams globally and are already conducting pre-deployment testing. This is our fourth progress report https://t.co/tbaHl2wZuI",
        "name": "Ian Hogarth",
        "photo": "https://pbs.twimg.com/profile_images/1728782716731105280/nVAiafUn_normal.jpg",
        "reply_count": 15,
        "retweet_count": 46,
        "view_count": 69038,
        "like_count": 313
    },
    "1792238422712578409": {
        "content": "90' 'You'll never play for England' is chanted at Nick Pope - who has a number of England caps.\n\n[2-4]\n\n#BRENEW // #NUFC",
        "name": "Newcastle United FC",
        "photo": "https://pbs.twimg.com/profile_images/1724599446095241217/iCyOErFY_normal.jpg",
        "reply_count": 166,
        "retweet_count": 1859,
        "view_count": 1807776,
        "like_count": 31895
    },
    "1791497907205447692": {
        "content": "Instead, we directly optimize features to explain network performance.\n\nWe introduce loss functions that train the SAE to produce the same output distribution (and downstream activations) as the original network. This involves training the SAEs end-to-end (e2e).\n\n3/ https://t.co/c6hmnyOv1R",
        "name": "Lee Sharkey",
        "photo": "https://pbs.twimg.com/profile_images/895607465013899264/-VF838Bm_normal.jpg",
        "reply_count": 1,
        "retweet_count": 0,
        "view_count": 1093,
        "like_count": 8
    },
    "1791531233450860981": {
        "content": "Lovely approach to learning SAEs that takes into account downstream effects of features as well as local reconstruction. Pareto improvements on metrics and hints of more compositional features (in exchange for a more complex/compute expensive training process).",
        "name": "Joshua Batson",
        "photo": "https://pbs.twimg.com/profile_images/1251741215415885829/6kDbML8z_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 643,
        "like_count": 8
    },
    "1791469099647631843": {
        "content": "As we push the boundaries of AI, it's critical that we stay ahead of potential risks.  \nI'm thrilled to announce @GoogleDeepMind's Frontier Safety Framework - our approach to analyzing and mitigating future risks posed by advanced AI models. 1/N https://t.co/amf028ZYaK",
        "name": "Allan Dafoe",
        "photo": "https://pbs.twimg.com/profile_images/1301378022843580417/w3eiYe4w_normal.jpg",
        "reply_count": 6,
        "retweet_count": 44,
        "view_count": 45932,
        "like_count": 174
    },
    "1791289342121455993": {
        "content": "Meta presents Chameleon: Mixed-Modal Early-Fusion Foundation Models\n\n- SotA in image captioning\n- On par with Mixtral 8x7B and Gemini-Pro on text-only tasks\n- On par with Gemini Pro and GPT-4V on a new long-form mixed-modal generation evaluation\n\nhttps://t.co/M6Z1N8bkLW https://t.co/Jel3N7l9u4",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 4,
        "retweet_count": 85,
        "view_count": 53922,
        "like_count": 406
    },
    "1790869434174746805": {
        "content": "A GPT-4o generated image \u2014 so much to explore with GPT-4o's image generation capabilities alone. Team is working hard to bring those to the world. https://t.co/5mO5aQxbaK",
        "name": "Greg Brockman",
        "photo": "https://pbs.twimg.com/profile_images/1347621377503711233/bHg3ipfD_normal.jpg",
        "reply_count": 289,
        "retweet_count": 605,
        "view_count": 1669249,
        "like_count": 6571
    },
    "1791088925475270908": {
        "content": "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?\n\nNew preprint!\ud83d\udce3\n\n- LLMs struggle to integrate new factual knowledge through fine-tuning\n- As the model eventually learns new knowledge, it becomes more prone to hallucinations\ud83d\ude35\u200d\ud83d\udcab\n\n\ud83d\udcdchttps://t.co/vvE3akrxas\n\n\ud83e\uddf51/12\ud83d\udc47",
        "name": "Zorik Gekhman",
        "photo": "https://pbs.twimg.com/profile_images/1270483820538736641/ID3Lpmd4_normal.jpg",
        "reply_count": 5,
        "retweet_count": 52,
        "view_count": 49043,
        "like_count": 174
    },
    "1788859706187882960": {
        "content": "Google presents Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?\n\nHighlights the risk in introducing new factual knowledge through fine-tuning, which leads to hallucinations\n\nhttps://t.co/VvSFxnBFig https://t.co/7TO7baAFW8",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 10,
        "retweet_count": 132,
        "view_count": 86627,
        "like_count": 628
    },
    "1790505292570193939": {
        "content": "ok my running list of Glorious Geminis and Where to Find Them:\n\nGemini Ultra (only in Gemini Advanced)\nGemini Pro (in API preview)\nGemini Flash (in API preview)\nGemini Nano (only in Pixel and Chrome 126)\nGemini Gems (soon)\nGemini Live (in coming months, for Gemini Advanced)\nLearnLM (in pilot on Google Classroom and Circle to Search on Android and select YouTube Quiz users)\n\ndid i miss any? is Ultra or Nano available via API anywhere? any other Gemini branded things?",
        "name": "swyx \ud83d\udd1c AI.Engineer conf!",
        "photo": "https://pbs.twimg.com/profile_images/1510319731466993664/tGoqnzGK_normal.jpg",
        "reply_count": 33,
        "retweet_count": 25,
        "view_count": 96190,
        "like_count": 319
    },
    "1790786038971113887": {
        "content": "Aligning open language models, a lecture I gave at Stanford CS25\n\nCovers the history of all the llamas, alpaca, open assistant, qlora, unlocking rlhf, zephyr, tulu, evaluation, and much more\n\nYouTube: https://t.co/b1R8UiOFcv https://t.co/SZtLYferd2",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 9,
        "retweet_count": 110,
        "view_count": 53360,
        "like_count": 486
    },
    "1790641082734350440": {
        "content": "\ud83d\ude32\ud83d\udc40 https://t.co/AYJ2Q8dQRW",
        "name": "Teknium (e/\u03bb)",
        "photo": "https://pbs.twimg.com/profile_images/1642401912648777728/2KFikPsE_normal.jpg",
        "reply_count": 77,
        "retweet_count": 82,
        "view_count": 98751,
        "like_count": 1013
    },
    "1790517455628198322": {
        "content": "After almost a decade, I have made the decision to leave OpenAI. \u00a0The company\u2019s trajectory has been nothing short of miraculous, and I\u2019m confident that OpenAI will build AGI that is both safe and beneficial under the leadership of @sama, @gdb, @miramurati and now, under the excellent research leadership of @merettm. \u00a0It was an honor and a privilege to have worked together, and I will miss everyone dearly. \u00a0 So long, and thanks for everything.  I am excited for what comes next \u2014 a project that is very personally meaningful to me about which I will share details in due time.",
        "name": "Ilya Sutskever",
        "photo": "https://pbs.twimg.com/profile_images/1548311632597553154/WYGE5NGW_normal.jpg",
        "reply_count": 1514,
        "retweet_count": 2557,
        "view_count": 5398318,
        "like_count": 26448
    },
    "1790111466051482080": {
        "content": "Anthropic's Mathematical Framework for Transformer Circuits is all about Kronecker Products;\nBecause they give you a way to model parallel computation (transformer heads).\nhttps://t.co/BftK156zK0 https://t.co/sImZoUIBEU",
        "name": "Thomas Ahle",
        "photo": "https://pbs.twimg.com/profile_images/1281418733693607937/_vWJlaTi_normal.jpg",
        "reply_count": 2,
        "retweet_count": 64,
        "view_count": 63101,
        "like_count": 345
    },
    "1789768331693584433": {
        "content": "The Kronecker Product in Linear Algebra is just a tensor product \"flattened\" on both sides.\n\nWe can illustrate this with tensor diagrams, by defining the \"flattening tensor\", \u25b7\u1d62\u2c7c\u2096=[i + j n = k].\nHere the Matrix Cookbook section translated into diagram form: https://t.co/xxsGneRaZw",
        "name": "Thomas Ahle",
        "photo": "https://pbs.twimg.com/profile_images/1281418733693607937/_vWJlaTi_normal.jpg",
        "reply_count": 2,
        "retweet_count": 24,
        "view_count": 42776,
        "like_count": 159
    },
    "1790078416567357784": {
        "content": "Friendly reminder that folks at AI2 built a text image audio input-output model last year, unified io 2, if you're looking to get started on research here. https://t.co/YTXeHDw2JH",
        "name": "Nathan Lambert",
        "photo": "https://pbs.twimg.com/profile_images/1732079679610425344/YqSwiBqA_normal.jpg",
        "reply_count": 7,
        "retweet_count": 53,
        "view_count": 34866,
        "like_count": 362
    },
    "1790069355868274701": {
        "content": "Live video reaction from chatGPT is the demo that google released with Gemini Ultra and then it was edited. \n\nThis is it, they solved it, and it laughed. \n\nShit https://t.co/QElN3BM70z",
        "name": "Alex Volkov (Thursd/AI)",
        "photo": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg",
        "reply_count": 6,
        "retweet_count": 9,
        "view_count": 22434,
        "like_count": 145
    },
    "1789367974932943278": {
        "content": "This is the book I was reading. Do give it a read especially if you are interested in GPUs, how they work, how to program them https://t.co/gfwCkaZbLr",
        "name": "Kartikay",
        "photo": "https://pbs.twimg.com/profile_images/1779071903959072768/CVH09Xid_normal.jpg",
        "reply_count": 15,
        "retweet_count": 105,
        "view_count": 225171,
        "like_count": 1306
    },
    "1789321094773846056": {
        "content": "Reading a great cs book makes you realise that all the blogs you read before on the topic are just watered down versions of this. This is the motherload.",
        "name": "Kartikay",
        "photo": "https://pbs.twimg.com/profile_images/1779071903959072768/CVH09Xid_normal.jpg",
        "reply_count": 22,
        "retweet_count": 63,
        "view_count": 272117,
        "like_count": 1238
    },
    "1789401478223790137": {
        "content": "The MATS Winter 2023-24 Retrospective is published!\nhttps://t.co/jrkox1LMId",
        "name": "Ryan Kidd",
        "photo": "https://pbs.twimg.com/profile_images/1596639311222358016/rK0nFaHS_normal.jpg",
        "reply_count": 1,
        "retweet_count": 1,
        "view_count": 993,
        "like_count": 14
    },
    "1788987793613725786": {
        "content": "We\u2019ll be streaming live on https://t.co/OcO6MLUYGH at 10AM PT Monday, May 13 to demo some ChatGPT and GPT-4 updates.",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 582,
        "retweet_count": 1924,
        "view_count": 5776827,
        "like_count": 10826
    },
    "1788947234618528092": {
        "content": "Can we catch models that fake alignment by examining their internals?\n\nOur new paper trains 'sleeper agents' that strategically pretend to be safe and finds methods to unmask them. https://t.co/iO43fuiGey",
        "name": "Joshua Clymer",
        "photo": "https://pbs.twimg.com/profile_images/1748917351284891648/9MPvlU_-_normal.jpg",
        "reply_count": 7,
        "retweet_count": 12,
        "view_count": 8856,
        "like_count": 92
    },
    "1497306702181548039": {
        "content": "Artificial Intelligence has experienced a complex historical development with \"springs\" and \"winters\". I found a way to look at them using the term \"Perceptron\" (the first supervised neural network) in Google Ngrams https://t.co/nViJctYyCh https://t.co/taq2ncEEIK",
        "name": "Ricard Sol\u00e9",
        "photo": "https://pbs.twimg.com/profile_images/1772579075103629312/aDPx7wjZ_normal.jpg",
        "reply_count": 0,
        "retweet_count": 18,
        "view_count": null,
        "like_count": 67
    },
    "1788910977003504010": {
        "content": "1/ Today the UK's AI Safety Institute is open sourcing our safety evaluations platform. We call it \"Inspect\": https://t.co/7trBzgw9hw",
        "name": "Ian Hogarth",
        "photo": "https://pbs.twimg.com/profile_images/1728782716731105280/nVAiafUn_normal.jpg",
        "reply_count": 8,
        "retweet_count": 90,
        "view_count": 73724,
        "like_count": 303
    },
    "1788481531834515482": {
        "content": "- 'Asking why I know so many Christmas songs.'\n- 'Wanting my thoughts on Israel/Gaza.'\n- 'Moving rugby training to Saturday mornings.'\n\nUnion of Jewish Students campaigner, Emily Sinclair, lists what made her feel 'uncomfortable to be Jewish' while at university. https://t.co/FVsmWiKOkC",
        "name": "LBC",
        "photo": "https://pbs.twimg.com/profile_images/1669349297614381056/jcdEPh_U_normal.jpg",
        "reply_count": 308,
        "retweet_count": 14,
        "view_count": 213981,
        "like_count": 99
    },
    "1788173699201327383": {
        "content": "Why does Chain of Thought (CoT) work?\n\nOur #ICLR 2024 paper proves that CoT enables more *iterative* compute to solve *inherently* serial problems. Otoh, a const-depth transformer that outputs answers right away can only solve problems that allow fast parallel algorithms. https://t.co/zymfcTMW4B",
        "name": "Zhiyuan Li",
        "photo": "https://pbs.twimg.com/profile_images/1208285325371400198/CPg4HMV6_normal.jpg",
        "reply_count": 6,
        "retweet_count": 64,
        "view_count": 36084,
        "like_count": 344
    },
    "1788070411210457157": {
        "content": "transformer killer just dropped\n\nxLSTM: Extended Long Short-Term Memory\npaper: https://t.co/ijHOMnU8RH https://t.co/TWBgQo0dbk",
        "name": "Joey (e/\u03bb)",
        "photo": "https://pbs.twimg.com/profile_images/1735686921953902593/epiV3hZ7_normal.jpg",
        "reply_count": 10,
        "retweet_count": 76,
        "view_count": 90078,
        "like_count": 699
    },
    "1787270794017702045": {
        "content": "Sometime in the next few months, @AnthropicAI  is expected to release a research report/paper on sparse autoencoders. Before this happens, I want to make some predictions about what it will accomplish.\n\nOverall, I think that the Anthropic SAE paper, when it comes out, will probably do some promising proofs of concept but will probably not demonstrate any practical use of SAEs that outcompete other existing tools for red-teaming, PEFT, model editing, etc.\n\nWhen the report eventually comes out, I'll make a followup tweet to this one pointing out what I was right and wrong about.\n\nPredictions:\n\n1. 99%: eye-test experiments -- I think the report will include experiments that will involve having humans look at what inputs activate SAE neurons and see if they subjectively seem coherent and interpretable to a human.\n\n2. 95%: streetlight edits -- I think that the report will have some experiments that involve cherry-picking some SAE neurons that seem interpretable and then testing the hypothesis by artificially up/down weighting the neuron during runtime.\n\n3. 80%: some cherry-picked proof of concept for a useful *type* of task -- I think it would be possible to show using current SAE methods that some interesting type of diagnostics/debugging can be done. Recently, Marks et al. did something like this by removing unintended signals from a classifier without disambiguating labels.\n\n[...All of the above are things that have happened in the mechanistic interpretability literature before, so I expect them. However, none of the above would show that SAEs could be useful for practical applications *in a way that is competitive with other techniques*. I think that the report is less likely to demonstrate this kind of thing...]\n\n4. 20%: Doing PEFT by training sparse weights and biases for SAE embeddings in a way that beats baselines like LORA -- I think this makes sense to try, and might be a good practical use of SAEs. But I wouldn't be surprised if this simply doesn't beat other PEFT baselines like LORA. It also wouldn't be interp -- it would just be PEFT.\n\n5. 20%: Passive scoping -- I think that it would potentially be possible and cool to see that models with their SAEs perform poorly on OOD examples. This could be useful. If a model might have unforeseen harmful capabilities (e.g. giving bomb-making instructions when jailbroken) that it did not exhibit during finetuning when the SAE was trained, it would be really cool if that model just simply didn't have those capabilities when the SAE was active. I'd be interested if this could be used to get rid of a sleeper agent. But notably, this type of experiment wouldn't be actual interp. And for this to be useful, an SAE approach would have to be shown to beat a dense autoencoder and model distillation.\n\n6. 25%: Finding and manually fixing a harmful behavior that WAS represented in the SAE training data -- maybe they could finetune SAEs using lots of web data and look for evidence of bad things. Then, they could isolate and ablate the SAE neurons that correspond to them. This seems possible, and it would be a win. But in order to be useful this would need to be shown to be competitive with some type of data-screening method. I don't think it would be. \n\n7. 5%: Finding and manually fixing a novel bug in the model that WASN'T represented in the SAE training data -- I would be really impressed if this happened because I see no reason that it should. This would show that SAEs can allow for a generalizable understanding of the network. For example, if they were somehow able to find/fix a sleeper agent using an SAE that wasn't trained on any examples of defection, I would be impressed.\n\n8. 15%: Using an SAE as a zero-shot anomaly detector: It might be possible to detect anomalies based on whether they have high reconstruction error. Anthropic might try this. It would be cool to show that certain model failures (e.g. jailbreaks) are somewhat anomalous this way. But in this kind of experiment, it would be important for the SAE beat a non-sparse autoencoder.\n\n9. 10%: Latent adversarial training under perturbations to an SAE's embeddings -- I think someone should try this, and I think that Anthropic is interested in it, but I don't think they're working on it currently. (There's a chance I might try this in the future someday.) \n\n10. 5%: experiments to do arbitrary manual model edits -- I don't think the report will have experiments that involve editing arbitrary behaviors in the model that weren't cherry-picked based on analysis of SAE neurons. For example, Anthropic could go to the MEMIT paper and try to replicate a simple random subsample of the edits that the MEMIT paper performed. I don't think they will do this, I don't think it would work well if they tried, and I feel confident that SAE's would be competitive with model editing / PEFT if they did do it.",
        "name": "Cas (Stephen Casper)",
        "photo": "https://pbs.twimg.com/profile_images/1740784277552250880/FXQChT3w_normal.jpg",
        "reply_count": 7,
        "retweet_count": 30,
        "view_count": 122071,
        "like_count": 289
    },
    "1786456929931514228": {
        "content": "The idea of \"machine unlearning\" is getting attention lately. Been thinking a lot about it recently and decided to write a long post: https://t.co/YWFco5xNNq \ud83d\udcf0\n\nUnlearning is no longer just about privacy and right-to-be-forgotten since foundation models. I hope to give a gentle overview of unlearning and touch on things like copyright, NYT v. OpenAI, NeurIPS unlearning challenge, retrieval-based systems, AI safety, & pretending to unlearn.\n\nI hope it'll be a fun weekend read!",
        "name": "Ken Liu",
        "photo": "https://pbs.twimg.com/profile_images/1632981224548360192/w3RtQMen_normal.jpg",
        "reply_count": 22,
        "retweet_count": 161,
        "view_count": 148077,
        "like_count": 737
    },
    "1786460237941354817": {
        "content": "Legit post on unlearning by Ken, pls read",
        "name": "Aryaman Arora",
        "photo": "https://pbs.twimg.com/profile_images/1735523039515926528/FghjGV3n_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 1157,
        "like_count": 6
    },
    "1786068246212366411": {
        "content": "Join us next Thursday (9th May) at 10:45 am in Hall B 238 at #ICLR2024 to discover the effects of fine-tuning a pretrained language model!\n\nFeel free to DM me if you want to chat further.",
        "name": "Nikhil Prakash",
        "photo": "https://pbs.twimg.com/profile_images/1780429108582768640/eL1nyZT5_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 1009,
        "like_count": 11
    },
    "1786058405951709403": {
        "content": "What happens inside a model after fine-tuning?\n\nMeet with @nikhil07prakash @talhacklay @boknilev about how to trace evolution of a circuit w DCM and CMAP to pin down content and encoding of information flow. https://t.co/qiqnS0K2EF\n\nThu 10:45 Hall B 238",
        "name": "David Bau",
        "photo": "https://pbs.twimg.com/profile_images/1591452247417831424/nZA7ZHTB_normal.jpg",
        "reply_count": 2,
        "retweet_count": 0,
        "view_count": 2435,
        "like_count": 10
    },
    "1786059864885834200": {
        "content": "Have people tried encrypting their benchmarks? \n\ndownload -&gt; decrypt -&gt; evaluate\n\nThis should quell any perf boosts from benchmarks leaking into training data, as long as LLM providers are not *intentionally* doping their models\n\nofc till AGI makes encryption meaningless",
        "name": "Archit Sharma",
        "photo": "https://pbs.twimg.com/profile_images/1434732854252998659/BUEZnwYJ_normal.jpg",
        "reply_count": 4,
        "retweet_count": 1,
        "view_count": 3990,
        "like_count": 18
    },
    "1786054643568517261": {
        "content": "Academic benchmarks are losing their potency. Moving forward, there\u2019re 3 types of LLM evaluations that matter: \n\n1. Privately held test set but publicly reported scores, by a trusted 3rd party who doesn\u2019t have their own LLM to promote. @scale_AI\u2019s latest GSM1k is a great example. They are an unbiased neutral party who ensures that the test data is not leaked into anyone\u2019s training. \n\n2. Public, comparative benchmarks like @lmsysorg Chatbot Arena, reported in ELO score. You can\u2019t game democracy. \n\n3. Privately curated, internal benchmarks for each company\u2019s own use cases. You can\u2019t game your customers.",
        "name": "Jim Fan",
        "photo": "https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd_normal.jpg",
        "reply_count": 42,
        "retweet_count": 163,
        "view_count": 297571,
        "like_count": 890
    },
    "1785849127643021638": {
        "content": "Scale AI presents A Careful Examination of LLM Performance on Grade School Arithmetic\n\n- Evaluate existing LLMs on a new test set of GSM8K\n- Observe accuracy drops of up to 13%, with models like Phi and Mistral showing evidence of systematic overfitting \n\nhttps://t.co/XFPOF35l5X https://t.co/sSSA5ncYxu",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 8,
        "retweet_count": 36,
        "view_count": 35289,
        "like_count": 236
    },
    "1785482247862407476": {
        "content": "Andrew Mack (my MATS mentee) found an *unsupervised* method to elicit latent model capabilities, find backdoored outputs (without knowing how to activate the backdoor!), and override safety training.\nhttps://t.co/tELMaMmNIb https://t.co/gKZ5HJ392u",
        "name": "Alex Turner",
        "photo": "https://pbs.twimg.com/profile_images/1724231616065904640/H8L6XKlL_normal.jpg",
        "reply_count": 2,
        "retweet_count": 14,
        "view_count": 8040,
        "like_count": 119
    },
    "1785137044169138641": {
        "content": "Google presents Capabilities of Gemini Models in Medicine\n\nExcellence in a wide variety of medical applications poses considerable challenges for AI, requiring advanced reasoning, access to up-to-date medical knowledge and understanding of complex multimodal data. https://t.co/sPlUAKDUoo",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 6,
        "retweet_count": 65,
        "view_count": 42189,
        "like_count": 302
    },
    "1785107943664566556": {
        "content": "i do have a soft spot for gpt2",
        "name": "Sam Altman",
        "photo": "https://pbs.twimg.com/profile_images/804990434455887872/BG0Xh7Oa_normal.jpg",
        "reply_count": 838,
        "retweet_count": 706,
        "view_count": 2274058,
        "like_count": 12397
    },
    "1785140867982049720": {
        "content": "Can you figure out how many interacting circuits are involved in a behavior just by looking at loss curves? Maybe!\n\nIn this cool paper, @Aaditya6284 et al. study the emergence of circuits in isolation by retraining models with certain activations \"clamped\" to post-training values",
        "name": "Samuel Marks",
        "photo": "https://pbs.twimg.com/profile_images/1712236109009416192/BFtcSlgC_normal.jpg",
        "reply_count": 0,
        "retweet_count": 3,
        "view_count": 2167,
        "like_count": 29
    },
    "1778442926688813421": {
        "content": "In-context learning (ICL) circuits emerge in a phase change...\n\nExcited for our new work \"What needs to go right for an induction head (IH)?\" We present \"clamping\", a method to causally intervene on dynamics, and use it to shed light on IH diversity + formation.\n\nRead on \ud83d\udd0e\u23ec",
        "name": "Aaditya Singh",
        "photo": "https://pbs.twimg.com/profile_images/1526510079993839616/-s-WAucU_normal.jpg",
        "reply_count": 2,
        "retweet_count": 43,
        "view_count": 60865,
        "like_count": 192
    },
    "1785117444383588823": {
        "content": "Delighted to share \u2728Med-Gemini\u2728 - our new family of multimodal models for medicine unlocking new possibilities for health - https://t.co/7Vqpw33yrK\n\nMore accurate multimodal conversations about medical images\ud83e\ude7b, surgical videos\ud83d\udcfd\ufe0f, genomics\ud83e\uddec, ultra-long health records\ud83d\udcda, ECGs\ud83e\udec0 & more with state-of-art performance across multiple benchmarks\n\nMore accurate, up-to-date answers to medical questions with advanced reasoning and intelligent use of web-search\n\nLong-context abilities. Summaries or referral letters from long health records, analyses of dozens of long research PDFs & more (1/6)",
        "name": "Alan Karthikesalingam",
        "photo": "https://pbs.twimg.com/profile_images/1028576902594932736/7biCF3Sb_normal.jpg",
        "reply_count": 17,
        "retweet_count": 117,
        "view_count": 293335,
        "like_count": 597
    },
    "1784761052548178311": {
        "content": "Meta presents AdvPrompter\n\nFast Adaptive Adversarial Prompting for LLMs\n\nWhile recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content. https://t.co/H16nt2mjxB",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 8,
        "retweet_count": 70,
        "view_count": 85298,
        "like_count": 334
    },
    "1784563273758548356": {
        "content": "Congrats to our affiliate @FazlBarez whose paper has won best poster at Tokyo Technical AI Safety Conference @tais_2024 \n\nWe have had the pleasure of working with Fazl since February",
        "name": "Krueger AI Safety Lab",
        "photo": "https://pbs.twimg.com/profile_images/1777776361194553344/nhpENrFn_normal.jpg",
        "reply_count": 0,
        "retweet_count": 7,
        "view_count": 4018,
        "like_count": 27
    },
    "1743441580479115458": {
        "content": "New Paper \ud83c\udf89: https://t.co/pgrdha94sw\n\nCan language models relearn removed concepts?\n\nModel editing aims to eliminate unwanted concepts through neuron pruning.  LLMs  demonstrate a remarkable capacity to adapt and regain conceptual representations which have been removed\n\n\ud83e\uddf51/8 https://t.co/Bbek0bFPFm",
        "name": "Fazl Barez",
        "photo": "https://pbs.twimg.com/profile_images/1635602874922160130/wc-V1cOC_normal.jpg",
        "reply_count": 2,
        "retweet_count": 79,
        "view_count": 37950,
        "like_count": 274
    },
    "1783946622772138085": {
        "content": "Some small updates from the Anthropic Interpretability team:\n\nhttps://t.co/VyZiY6D9nQ",
        "name": "Adam Jermyn",
        "photo": "https://pbs.twimg.com/profile_images/1046124191068577797/tqQ72nrh_normal.jpg",
        "reply_count": 2,
        "retweet_count": 16,
        "view_count": 81334,
        "like_count": 121
    },
    "1783951795238441449": {
        "content": "Do models need to reason in words to benefit from chain-of-thought tokens?\n\nIn our experiments, the answer is no! Models can perform on par with CoT using repeated '...' filler tokens. \nThis raises alignment concerns: Using filler, LMs can do hidden reasoning not visible in CoT\ud83e\uddf5 https://t.co/k2XobOaiPD",
        "name": "Jacob Pfau",
        "photo": "https://pbs.twimg.com/profile_images/1512945564979286024/aNf3LVcf_normal.jpg",
        "reply_count": 41,
        "retweet_count": 183,
        "view_count": 258976,
        "like_count": 1088
    },
    "1783717256267960575": {
        "content": "Google presents Revisiting Text-to-Image Evaluation with Gecko\n\nOn Metrics, Prompts, and Human Ratings\n\nWhile text-to-image (T2I) generative models have become ubiquitous, they do not necessarily generate images that align with a given prompt. While previous work has https://t.co/HrOo2VuJj0",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 6,
        "retweet_count": 30,
        "view_count": 25518,
        "like_count": 139
    },
    "1783979160718999877": {
        "content": "Scaling laws for dictionary learning! https://t.co/nqSGYjGwsO https://t.co/f4ERLNvhof",
        "name": "Chris Olah",
        "photo": "https://pbs.twimg.com/profile_images/1422800200146378753/TdaSuRIB_normal.jpg",
        "reply_count": 3,
        "retweet_count": 21,
        "view_count": 54296,
        "like_count": 216
    },
    "1783384529115230346": {
        "content": "v2\n\nhttps://t.co/LJqeasewQO https://t.co/UyG2lhtrEp",
        "name": "Fran\u00e7ois Fleuret",
        "photo": "https://pbs.twimg.com/profile_images/1741919776773902336/pXUEFYUA_normal.jpg",
        "reply_count": 28,
        "retweet_count": 36,
        "view_count": 106835,
        "like_count": 504
    },
    "1783241887513559368": {
        "content": "Okay , here we go! https://t.co/DS4fbnDkXQ",
        "name": "Fran\u00e7ois Fleuret",
        "photo": "https://pbs.twimg.com/profile_images/1741919776773902336/pXUEFYUA_normal.jpg",
        "reply_count": 92,
        "retweet_count": 131,
        "view_count": 259866,
        "like_count": 1521
    },
    "1783501946445254664": {
        "content": "We\u2019re excited to share Gated SAEs: an improvement to Sparse Autoencoder training that scales to 7B parameter models (at least!)",
        "name": "Arthur Conmy",
        "photo": "https://pbs.twimg.com/profile_images/1422332102486409218/dOEbifRB_normal.jpg",
        "reply_count": 0,
        "retweet_count": 4,
        "view_count": 3129,
        "like_count": 60
    },
    "1783497788120248431": {
        "content": "New @GoogleDeepMind MechInterp work! We introduce Gated SAEs, a Pareto improvement over existing sparse autoencoders.\n\nThey find equally good reconstructions with around half as many firing features, while maintaining interpretability (CI 0-13% improvement). Joint w/ @ArthurConmy https://t.co/gpNFPGC5cR",
        "name": "Senthooran Rajamanoharan",
        "photo": "https://pbs.twimg.com/profile_images/1783490256630636545/2pVbeQVQ_normal.jpg",
        "reply_count": 5,
        "retweet_count": 24,
        "view_count": 23533,
        "like_count": 159
    },
    "1783243809494577187": {
        "content": "Okay I realize, the ml/math/cs part are more general culture assessment than truly specifically for AI. You can live without knowing closure or mutex.\n\nThe dl part however, I do not think it goes overboard.",
        "name": "Fran\u00e7ois Fleuret",
        "photo": "https://pbs.twimg.com/profile_images/1741919776773902336/pXUEFYUA_normal.jpg",
        "reply_count": 4,
        "retweet_count": 3,
        "view_count": 23298,
        "like_count": 87
    },
    "1782945719747510622": {
        "content": "Microsoft presents Multi-Head Mixture-of-Experts\n\nAchieves notable improvements over the baseline MoE by using multiple MoE heads\n\nrepo: https://t.co/1XW8CSDewI\nabs: https://t.co/V2KBRKTxML https://t.co/1KTQxJxBKd",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 7,
        "retweet_count": 118,
        "view_count": 40703,
        "like_count": 579
    },
    "1782844533430186444": {
        "content": "Constellation -- an AI safety research center in Berkeley, CA -- is launching two new programs!\n\n* Visiting Fellows: 3-6 months visiting (w/ travel, housing, &amp; office space covered)\n* Constellation Residency: 1yr salaried position",
        "name": "Samuel Marks",
        "photo": "https://pbs.twimg.com/profile_images/1712236109009416192/BFtcSlgC_normal.jpg",
        "reply_count": 1,
        "retweet_count": 6,
        "view_count": 5806,
        "like_count": 48
    },
    "1782849356200308820": {
        "content": "Introducing the Instruction Hierarchy, our latest safety research to advance robustness for prompt injections and other ways of tricking LLMs into executing unsafe actions. More details: https://t.co/cUZaaMRdEG",
        "name": "OpenAI",
        "photo": "https://pbs.twimg.com/profile_images/1634058036934500352/b4F1eVpJ_normal.jpg",
        "reply_count": 175,
        "retweet_count": 291,
        "view_count": 609772,
        "like_count": 1844
    },
    "1782915733707698296": {
        "content": "Some of our first steps on developing mitigations for sleeper agents",
        "name": "Ethan Perez",
        "photo": "https://pbs.twimg.com/profile_images/1718732845936680960/AVc5Imq6_normal.jpg",
        "reply_count": 0,
        "retweet_count": 0,
        "view_count": 3885,
        "like_count": 50
    },
    "1782908989296046210": {
        "content": "New Anthropic research: we find that probing, a simple interpretability technique, can detect when backdoored \"sleeper agent\" models are about to behave dangerously, after they pretend to be safe in training.\n\nCheck out our first alignment blog post here: https://t.co/gildHUjVAG https://t.co/eTiXmSwDIx",
        "name": "Anthropic",
        "photo": "https://pbs.twimg.com/profile_images/1764655509968482304/nMeDViAs_normal.png",
        "reply_count": 40,
        "retweet_count": 172,
        "view_count": 281961,
        "like_count": 996
    },
    "1782791719915802823": {
        "content": "Our new paper on AI persuasion, exploring definitions, harms and mechanisms. Happy to have contributed towards the section on mitigations to avoid harmful persuasion. Some highlights in \ud83e\uddf5 https://t.co/FHgO91ZiDp https://t.co/AxbreqgBZi",
        "name": "Zac Kenton",
        "photo": "https://pbs.twimg.com/profile_images/1736783430552113152/PZr_Rs_i_normal.jpg",
        "reply_count": 2,
        "retweet_count": 19,
        "view_count": 10004,
        "like_count": 54
    },
    "1721905628451635403": {
        "content": "Huge h/t to @ArthurConmy for sharing this writing advice from Stuart Shieber about how to write a paper. (1/3) https://t.co/rZobJw0VfO",
        "name": "Henry!",
        "photo": "https://pbs.twimg.com/profile_images/1728074106711470080/EcXYIfal_normal.jpg",
        "reply_count": 3,
        "retweet_count": 12,
        "view_count": 11163,
        "like_count": 64
    },
    "1686075055027994640": {
        "content": "I've written up my study group lectures on implementing Transformers in PyTorch into a blog series:\n\nCreating Transformers from Scratch:\n\n - Part 1: The Attention Mechanism https://t.co/ZCMiCMzQIp\n\n - Part 2: The Rest of the Transformer https://t.co/kWq9gWkvtp",
        "name": "Benjamin Warner",
        "photo": "https://pbs.twimg.com/profile_images/1413738385571778561/91XbWJI__normal.jpg",
        "reply_count": 7,
        "retweet_count": 272,
        "view_count": 180235,
        "like_count": 1421
    },
    "1782607138952499661": {
        "content": "How Good Are Low-bit Quantized LLaMA3 Models?\n\nMeta's LLaMA family has become one of the most powerful open-source Large Language Model (LLM) series. Notably, LLaMA3 models have recently been released and achieve impressive performance across various with super-large scale https://t.co/yspdosZpaK",
        "name": "AK",
        "photo": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg",
        "reply_count": 4,
        "retweet_count": 70,
        "view_count": 51175,
        "like_count": 318
    },
    "1782594659761389655": {
        "content": "Microsoft just released Phi-3\n\n- phi-3-mini: 3.8B model trained on 3.3T tokens rivals Mixtral 8x7B and GPT-3.5\n- phi-3-medium: 14B model trained on 4.8T tokens w/ 78% on MMLU and 8.9 on MT-bench\n\nhttps://t.co/yfpLCB8kFs https://t.co/8ENvdhJVPI",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 32,
        "retweet_count": 144,
        "view_count": 336725,
        "like_count": 811
    },
    "1782600350282715532": {
        "content": "Better Synthetic Data by Retrieving and Transforming Existing Datasets\n\nrepo: https://t.co/Gh1gIiLP14\nabs: https://t.co/yQMj0z7cmi https://t.co/EqTuJnUGgO",
        "name": "Aran Komatsuzaki",
        "photo": "https://pbs.twimg.com/profile_images/1561220982328754176/JOYS5kab_normal.jpg",
        "reply_count": 1,
        "retweet_count": 88,
        "view_count": 47589,
        "like_count": 417
    },
    "1782650106468258037": {
        "content": "Interested in the future of AI interpretability? Join us at the Mechanistic Interpretability Social @ #ICLR2024!\n\n\ud83d\udcc5 Wed, May 8, 12:45-2:15 PM\n\ud83d\udd17 RSVP &amp; share your ideas here: https://t.co/DQx3RXgv4G\n\nDon't miss out on a panel discussion with top researchers! #ICLR2024",
        "name": "Nikhil Prakash",
        "photo": "https://pbs.twimg.com/profile_images/1780429108582768640/eL1nyZT5_normal.jpg",
        "reply_count": 0,
        "retweet_count": 7,
        "view_count": 8193,
        "like_count": 44
    },
    "1781358899645333913": {
        "content": "We now have an open-source model that is beating Claude 3 Opus...\n\nbeing served at nearly **300 tokens per second** on @GroqInc.\n\nThe applications built off of this tech will be nothing short of revolutionary.",
        "name": "Matt Shumer",
        "photo": "https://pbs.twimg.com/profile_images/1490950574090571778/BtgOaqUP_normal.jpg",
        "reply_count": 56,
        "retweet_count": 145,
        "view_count": 248020,
        "like_count": 1363
    },
    "1781422363101262090": {
        "content": "Built a \u26a1\ufe0f\u26a1\ufe0f financial analyst with Llama3 on @GroqInc. Running 3-4 function calls in 4 seconds, without streaming. \n\nTry it yourself: https://t.co/F2QAZeurSD https://t.co/n6mYxdtK3X",
        "name": "Ashpreet Bedi",
        "photo": "https://pbs.twimg.com/profile_images/1372272773326761986/6TJopSZV_normal.jpg",
        "reply_count": 13,
        "retweet_count": 50,
        "view_count": 50432,
        "like_count": 358
    },
    "1781763525725274514": {
        "content": "An author submitted 35 papers to ICLR?\n\nI hope he/she did 35 reviews at least...\n\nOtherwise it is not sustainable...",
        "name": "'YZ' Yezhou Yang (\u6768\u53f6\u821f)",
        "photo": "https://pbs.twimg.com/profile_images/1668847699284873217/QDdfyYyD_normal.jpg",
        "reply_count": 3,
        "retweet_count": 6,
        "view_count": 28136,
        "like_count": 76
    },
    "1781609561889104341": {
        "content": "In case some of you were (like me) curious about this stat for AI conferences: here it is for ICLR2024 https://t.co/BUMfBDUU9W",
        "name": "TimDarcet",
        "photo": "https://pbs.twimg.com/profile_images/1393146576055513088/g6hUgGsA_normal.png",
        "reply_count": 13,
        "retweet_count": 21,
        "view_count": 366288,
        "like_count": 157
    },
    "1778277946072891807": {
        "content": "Cool effect of interpolating between points distributed like different digits. \n\nWait until the end ... https://t.co/8qGO6SiApf",
        "name": "Alec Helbling",
        "photo": "https://pbs.twimg.com/profile_images/1452763272374104069/oEfa9OYI_normal.jpg",
        "reply_count": 0,
        "retweet_count": 1,
        "view_count": 2831,
        "like_count": 9
    },
    "1781395284762791994": {
        "content": "\ud83d\udce2\ud83d\udce2 Align Your Steps: Optimizing Sampling Schedules in Diffusion Models\n\nhttps://t.co/piIE140xPv\n\nTL;DR: We introduce a method for obtaining improved sampling schedules for diffusion models, resulting in better samples at the same computation cost.\n\n(1/5) https://t.co/lmC2IchJh8",
        "name": "Amirmojtaba Sabour",
        "photo": "https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png",
        "reply_count": 2,
        "retweet_count": 65,
        "view_count": 32513,
        "like_count": 179
    },
    "1780518749516308685": {
        "content": "Statistics from @ICSE2024. Authors submitting, *each*, 33, 27, 24, ... papers.\nInteractive dashboard: \nhttps://t.co/5pdrxOfhrj https://t.co/U8T2TqNo8a",
        "name": "Guido Salvaneschi",
        "photo": "https://pbs.twimg.com/profile_images/1311976888697577472/S1o_tHWZ_normal.jpg",
        "reply_count": 18,
        "retweet_count": 24,
        "view_count": 146343,
        "like_count": 90
    }
}